<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 83]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.LG](#cs.LG) [Total: 86]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SkyCap: Bitemporal VHR Optical-SAR Quartets for Amplitude Change Detection and Foundation-Model Evaluation](https://arxiv.org/abs/2512.14755)
*Paul Weinmann,Ferdinand Schenck,Martin Šiklar*

Main category: cs.CV

TL;DR: SkyCap is a new dataset combining VHR optical-SAR data for change detection, using optical-to-SAR label transfer. Optical models surpassed SAR-specific ones in performance, highlighting preprocessing alignment importance.


<details>
  <summary>Details</summary>
Motivation: Monitoring linear infrastructure demands reliable, high-resolution data. Optical imagery is interpretable but cloud-dependent, while SAR is all-weather but hard to annotate. SkyCap bridges this gap.

Method: SkyCap pairs SkySat (optical) and Capella Space (SAR) data via archive matching. Optical-to-SAR label transfer avoids SAR-expert annotations. Pretraining SARATR-X and benchmarking optical/SAR FMs with varied preprocessing.

Result: Optical FM MTP(ViT-B+RVSA) with dB+Z-score preprocessing achieved top F1$_c$=45.06, beating SAR-specific FMs pretrained on Capella data. Preprocessing alignment critically impacted performance.

Conclusion: Optical models can outperform SAR-specific ones in SAR ACD, emphasizing preprocessing alignment. SkyCap enables future VHR SAR ACD research without expert annotations.

Abstract: Change detection for linear infrastructure monitoring requires reliable high-resolution data and regular acquisition cadence. Optical very-high-resolution (VHR) imagery is interpretable and straightforward to label, but clouds break this cadence. Synthetic Aperture Radar (SAR) enables all-weather acquisitions, yet is difficult to annotate. We introduce SkyCap, a bitemporal VHR optical-SAR dataset constructed by archive matching and co-registration of (optical) SkySat and Capella Space (SAR) scenes. We utilize optical-to-SAR label transfer to obtain SAR amplitude change detection (ACD) labels without requiring SAR-expert annotations. We perform continued pretraining of SARATR-X on our SAR data and benchmark the resulting SAR-specific foundation models (FMs) together with SARATR-X against optical FMs on SkyCap under different preprocessing choices. Among evaluated models, MTP(ViT-B+RVSA), an optical FM, with dB+Z-score preprocessing attains the best result (F1$_c$ = 45.06), outperforming SAR-specific FMs further pretrained directly on Capella data. We observe strong sensitivity to preprocessing alignment with pretraining statistics, and the ranking of optical models on optical change detection does not transfer one-to-one to SAR ACD. To our knowledge, this is the first evaluation of foundation models on VHR SAR ACD.

</details>


### [2] [SocialNav-MoE: A Mixture-of-Experts Vision Language Model for Socially Compliant Navigation with Reinforcement Fine-Tuning](https://arxiv.org/abs/2512.14757)
*Tomohito Kawabata,Xinyu Zhang,Ling Xiao*

Main category: cs.CV

TL;DR: SocialNav-MoE, an efficient Mixture-of-Experts VLM, addresses socially compliant navigation with reinforcement fine-tuning and semantic similarity rewards, achieving a balance between accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Prior work focuses on safety but neglects social compliance in robot navigation. Small VLMs are explored to overcome computational limitations of large models.

Method: Proposes SocialNav-MoE with reinforcement fine-tuning (RFT) and semantic similarity reward (SSR). Evaluates small language models, routing strategies, and vision encoders.

Result: Achieves excellent balance between navigation accuracy and efficiency on SNEI dataset; SSR outperforms hard-level and character-level rewards.

Conclusion: SocialNav-MoE proves effective for socially compliant navigation, offering a practical solution for resource-constrained robotic platforms.

Abstract: For robots navigating in human-populated environments, safety and social compliance are equally critical, yet prior work has mostly emphasized safety. Socially compliant navigation that accounts for human comfort, social norms, and contextual appropriateness remains underexplored. Vision language models (VLMs) show promise for this task; however, large-scale models incur substantial computational overhead, leading to higher inference latency and energy consumption, which makes them unsuitable for real-time deployment on resource-constrained robotic platforms. To address this issue, we investigate the effectiveness of small VLM and propose SocialNav-MoE, an efficient Mixture-of-Experts vision language model for socially compliant navigation with reinforcement fine-tuning (RFT). We further introduce a semantic similarity reward (SSR) to effectively leverage RFT for enhancing the decision-making capabilities. Additionally, we study the effectiveness of different small language model types (Phi, Qwen, and StableLM), routing strategies, and vision encoders (CLIP vs. SigLIP, frozen vs. fine-tuned). Experiments on the SNEI dataset demonstrate that SocialNav-MoE achieves an excellent balance between navigation accuracy and efficiency. The proposed SSR function is more effective than hard-level and character-level rewards. Source code will be released upon acceptance.

</details>


### [3] [The Renaissance of Expert Systems: Optical Recognition of Printed Chinese Jianpu Musical Scores with Lyrics](https://arxiv.org/abs/2512.14758)
*Fan Bu,Rongfeng Li,Zijin Li,Ya Li,Linfeng Fan,Pei Huang*

Main category: cs.CV

TL;DR: A hybrid expert-system pipeline digitizes Chinese Jianpu scores with lyrics into MusicXML and MIDI, achieving high accuracy without large training datasets.


<details>
  <summary>Details</summary>
Motivation: To address the underexploration of Chinese Jianpu notation and its lyric resources in large-scale OMR research.

Method: A top-down expert-system design combining traditional computer-vision techniques (phrase correlation, skeleton analysis) with unsupervised deep-learning modules for image feature embeddings.

Result: Digitized over 5,000 melody-only songs (~300,000 notes) and 1,400 lyric-aligned songs (~100,000 notes) with high precision (note-wise F1 = 0.951, character-wise F1 = 0.931).

Conclusion: The hybrid approach balances interpretability and accuracy, successfully digitizing Jianpu scores and lyrics.

Abstract: Large-scale optical music recognition (OMR) research has focused mainly on Western staff notation, leaving Chinese Jianpu (numbered notation) and its rich lyric resources underexplored. We present a modular expert-system pipeline that converts printed Jianpu scores with lyrics into machine-readable MusicXML and MIDI, without requiring massive annotated training data. Our approach adopts a top-down expert-system design, leveraging traditional computer-vision techniques (e.g., phrase correlation, skeleton analysis) to capitalize on prior knowledge, while integrating unsupervised deep-learning modules for image feature embeddings. This hybrid strategy strikes a balance between interpretability and accuracy. Evaluated on The Anthology of Chinese Folk Songs, our system massively digitizes (i) a melody-only collection of more than 5,000 songs (> 300,000 notes) and (ii) a curated subset with lyrics comprising over 1,400 songs (> 100,000 notes). The system achieves high-precision recognition on both melody (note-wise F1 = 0.951) and aligned lyrics (character-wise F1 = 0.931).

</details>


### [4] [AquaDiff: Diffusion-Based Underwater Image Enhancement for Addressing Color Distortion](https://arxiv.org/abs/2512.14760)
*Afrah Shaahid,Muzammil Behzad*

Main category: cs.CV

TL;DR: AquaDiff is a diffusion-based framework for enhancing underwater images by correcting color distortions and preserving structural details, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Underwater images suffer from color distortion, low contrast, and detail loss due to light absorption and scattering, hindering vision-based applications.

Method: AquaDiff combines chromatic prior-guided color compensation with conditional diffusion, using cross-attention and residual dense blocks for detail preservation. A cross-domain consistency loss ensures accuracy, perceptual similarity, and structural integrity.

Result: AquaDiff achieves superior color correction and competitive image quality across diverse underwater conditions compared to state-of-the-art methods.

Conclusion: AquaDiff effectively addresses underwater image degradation, offering improved enhancement capabilities for practical applications.

Abstract: Underwater images are severely degraded by wavelength-dependent light absorption and scattering, resulting in color distortion, low contrast, and loss of fine details that hinder vision-based underwater applications. To address these challenges, we propose AquaDiff, a diffusion-based underwater image enhancement framework designed to correct chromatic distortions while preserving structural and perceptual fidelity. AquaDiff integrates a chromatic prior-guided color compensation strategy with a conditional diffusion process, where cross-attention dynamically fuses degraded inputs and noisy latent states at each denoising step. An enhanced denoising backbone with residual dense blocks and multi-resolution attention captures both global color context and local details. Furthermore, a novel cross-domain consistency loss jointly enforces pixel-level accuracy, perceptual similarity, structural integrity, and frequency-domain fidelity. Extensive experiments on multiple challenging underwater benchmarks demonstrate that AquaDiff provides good results as compared to the state-of-the-art traditional, CNN-, GAN-, and diffusion-based methods, achieving superior color correction and competitive overall image quality across diverse underwater conditions.

</details>


### [5] [Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification](https://arxiv.org/abs/2512.14770)
*Xixian Wu,Yang Ou,Pengchao Tian,Zian Yang,Jielei Zhang,Peiyi Li,Longwen Gao*

Main category: cs.CV

TL;DR: DAVR enhances VLM reliability by integrating Self-Reflection and Cross-Model Verification, achieving top scores in reliability metrics.


<details>
  <summary>Details</summary>
Motivation: Address VLM susceptibility to hallucinations and overconfidence in VQA tasks to improve answer reliability.

Method: Introduces DAVR, a dual-pathway framework combining Self-Reflection (fusing VLM features with QA embeddings) and Cross-Model Verification (external models for factual checks).

Result: Achieves a Φ₁₀₀ score of 39.64 and 100-AUC of 97.22, ranking first in the Reliable VQA Challenge.

Conclusion: DAVR effectively improves VLM response trustworthiness by mitigating hallucinations through dual reliability assessments.

Abstract: Vision-language models (VLMs) have demonstrated significant potential in Visual Question Answering (VQA). However, the susceptibility of VLMs to hallucinations can lead to overconfident yet incorrect answers, severely undermining answer reliability. To address this, we propose Dual-Assessment for VLM Reliability (DAVR), a novel framework that integrates Self-Reflection and Cross-Model Verification for comprehensive uncertainty estimation. The DAVR framework features a dual-pathway architecture: one pathway leverages dual selector modules to assess response reliability by fusing VLM latent features with QA embeddings, while the other deploys external reference models for factual cross-checking to mitigate hallucinations. Evaluated in the Reliable VQA Challenge at ICCV-CLVL 2025, DAVR achieves a leading $Φ_{100}$ score of 39.64 and a 100-AUC of 97.22, securing first place and demonstrating its effectiveness in enhancing the trustworthiness of VLM responses.

</details>


### [6] [HERBench: A Benchmark for Multi-Evidence Integration in Video Question Answering](https://arxiv.org/abs/2512.14870)
*Dan Ben-Ami,Gabriele Serussi,Kobi Cohen,Chaim Baskin*

Main category: cs.CV

TL;DR: HERBench is a VideoQA benchmark designed to test multi-evidence integration across time, requiring aggregation of at least three visual cues. Current Video-LLMs struggle with retrieval and fusion deficits, achieving only marginally better than random-guess accuracy.


<details>
  <summary>Details</summary>
Motivation: Current VideoQA benchmarks often allow questions to be answered from single cues, under-testing reasoning that requires aggregating multiple, temporally separated visual evidence. HERBench addresses this gap by ensuring questions demand multi-evidence integration.

Method: HERBench comprises 26K five-way multiple-choice questions requiring aggregation of three non-overlapping cues across distinct video segments. It introduces Minimum Required Frame-Set (MRFS) to quantify evidential demand.

Result: Evaluation of 13 Video-LLMs shows low accuracies (31-42%), slightly above the 20% random-guess baseline. The main bottlenecks are retrieval deficits (missing key evidence) and fusion deficits (failing to integrate provided evidence).

Conclusion: HERBench provides a principled benchmark for advancing robust, compositional video understanding by making cross-time evidence unavoidable and quantifiable, highlighting critical deficits in current Video-LLMs.

Abstract: Video Large Language Models (Video-LLMs) are rapidly improving, yet current Video Question Answering (VideoQA) benchmarks often allow questions to be answered from a single salient cue, under-testing reasoning that must aggregate multiple, temporally separated visual evidence. We present HERBench, a VideoQA benchmark purpose-built to assess multi-evidence integration across time. Each question requires aggregating at least three non-overlapping evidential cues across distinct video segments, so neither language priors nor a single snapshot can suffice. HERBench comprises 26K five-way multiple-choice questions organized into twelve compositional tasks that probe identity binding, cross-entity relations, temporal ordering, co-occurrence verification, and counting. To make evidential demand measurable, we introduce the Minimum Required Frame-Set (MRFS), the smallest number of frames a model must fuse to answer correctly, and show that HERBench imposes substantially higher demand than prior datasets (mean MRFS 5.5 vs. 2.6-4.2). Evaluating 13 state-of-the-art Video-LLMs on HERBench reveals pervasive failures: accuracies of 31-42% are only slightly above the 20% random-guess baseline. We disentangle this failure into two critical bottlenecks: (1) a retrieval deficit, where frame selectors overlook key evidence, and (2) a fusion deficit, where models fail to integrate information even when all necessary evidence is provided. By making cross-time evidence both unavoidable and quantifiable, HERBench establishes a principled target for advancing robust, compositional video understanding.

</details>


### [7] [Isolated Sign Language Recognition with Segmentation and Pose Estimation](https://arxiv.org/abs/2512.14876)
*Daniel Perkins,Davis Hunter,Dhrumil Patel,Galen Flanagan*

Main category: cs.CV

TL;DR: The paper proposes a model for isolated sign language recognition (ISLR) to address challenges like scarce data and high computational costs, using pose estimation, segmentation, and a ResNet-Transformer backbone.


<details>
  <summary>Details</summary>
Motivation: Current large language models for automated translations are inaccessible to ASL users due to the visual complexity of sign language. ISLR can bridge this gap but faces challenges like limited data and high signer variability.

Method: The model combines pose estimation (for hand and face joint coordinates), a segmentation module to isolate relevant information, and a ResNet-Transformer backbone to model spatial and temporal dependencies.

Result: The proposed model reduces computational requirements while maintaining robustness to signer variation, making ISLR more feasible.

Conclusion: The approach effectively addresses key ISLR challenges, paving the way for more accessible ASL communication tools.

Abstract: The recent surge in large language models has automated translations of spoken and written languages. However, these advances remain largely inaccessible to American Sign Language (ASL) users, whose language relies on complex visual cues. Isolated sign language recognition (ISLR) - the task of classifying videos of individual signs - can help bridge this gap but is currently limited by scarce per-sign data, high signer variability, and substantial computational costs. We propose a model for ISLR that reduces computational requirements while maintaining robustness to signer variation. Our approach integrates (i) a pose estimation pipeline to extract hand and face joint coordinates, (ii) a segmentation module that isolates relevant information, and (iii) a ResNet-Transformer backbone to jointly model spatial and temporal dependencies.

</details>


### [8] [Visual-textual Dermatoglyphic Animal Biometrics: A First Case Study on Panthera tigris](https://arxiv.org/abs/2512.14878)
*Wenshuo Li,Majid Mirmehdi,Tilo Burghardt*

Main category: cs.CV

TL;DR: The paper introduces a novel method combining dermatoglyphic textual descriptors with visuals for animal re-identification, enhancing AI accuracy and explainability.


<details>
  <summary>Details</summary>
Motivation: Current AI tools for animal Re-ID rely mainly on images, lacking integration with textual descriptors. The study aims to bridge this gap by incorporating forensic-like dermatoglyphic text.

Method: Used 84,264 labelled minutiae from 3,355 images of 185 tigers to develop a text-image co-synthesis pipeline, generating virtual individuals with paired visuals and dermatoglyphic text.

Result: The method significantly improves AI accuracy in cross-modal retrieval and addresses data scarcity issues.

Conclusion: Dermatoglyphic language-guided biometrics enhance Re-ID by enabling textual-to-visual matches, advancing explainability and unifying descriptive modalities in ecology.

Abstract: Biologists have long combined visuals with textual field notes to re-identify (Re-ID) animals. Contemporary AI tools automate this for species with distinctive morphological features but remain largely image-based. Here, we extend Re-ID methodologies by incorporating precise dermatoglyphic textual descriptors-an approach used in forensics but new to ecology. We demonstrate that these specialist semantics abstract and encode animal coat topology using human-interpretable language tags. Drawing on 84,264 manually labelled minutiae across 3,355 images of 185 tigers (Panthera tigris), we evaluate this visual-textual methodology, revealing novel capabilities for cross-modal identity retrieval. To optimise performance, we developed a text-image co-synthesis pipeline to generate 'virtual individuals', each comprising dozens of life-like visuals paired with dermatoglyphic text. Benchmarking against real-world scenarios shows this augmentation significantly boosts AI accuracy in cross-modal retrieval while alleviating data scarcity. We conclude that dermatoglyphic language-guided biometrics can overcome vision-only limitations, enabling textual-to-visual identity recovery underpinned by human-verifiable matchings. This represents a significant advance towards explainability in Re-ID and a language-driven unification of descriptive modalities in ecological monitoring.

</details>


### [9] [Vibe Spaces for Creatively Connecting and Expressing Visual Concepts](https://arxiv.org/abs/2512.14884)
*Huzheng Yang,Katherine Xu,Andrew Lu,Michael D. Grossberg,Yutong Bai,Jianbo Shi*

Main category: cs.CV

TL;DR: The paper introduces Vibe Blending and Vibe Space, a method for generating meaningful visual hybrids by identifying shared attributes between images, outperforming current methods in creativity and coherence.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of creating meaningful visual hybrids by connecting distinct ideas through shared attributes (vibes), which current methods struggle with.

Method: Proposes Vibe Space, a hierarchical graph manifold that learns low-dimensional geodesics in feature spaces (e.g., CLIP) for smooth, semantically consistent transitions between concepts.

Result: Vibe Space produces blends rated as more creative and coherent by humans compared to current methods, validated through a cognitively inspired evaluation framework.

Conclusion: Vibe Space effectively enables the generation of creative and coherent visual hybrids by identifying and traversing shared attributes between images.

Abstract: Creating new visual concepts often requires connecting distinct ideas through their most relevant shared attributes -- their vibe. We introduce Vibe Blending, a novel task for generating coherent and meaningful hybrids that reveals these shared attributes between images. Achieving such blends is challenging for current methods, which struggle to identify and traverse nonlinear paths linking distant concepts in latent space. We propose Vibe Space, a hierarchical graph manifold that learns low-dimensional geodesics in feature spaces like CLIP, enabling smooth and semantically consistent transitions between concepts. To evaluate creative quality, we design a cognitively inspired framework combining human judgments, LLM reasoning, and a geometric path-based difficulty score. We find that Vibe Space produces blends that humans consistently rate as more creative and coherent than current methods.

</details>


### [10] [PANDA-PLUS-Bench: A Clinical Benchmark for Evaluating Robustness of AI Foundation Models in Prostate Cancer Diagnosis](https://arxiv.org/abs/2512.14922)
*Joshua L. Ebbert,Dennis Della Corte*

Main category: cs.CV

TL;DR: PANDA-PLUS-Bench is a curated benchmark dataset for evaluating foundation models' robustness in Gleason grading, revealing variability in performance and highlighting the benefits of tissue-specific training.


<details>
  <summary>Details</summary>
Motivation: Artificial intelligence models for Gleason grading may learn specimen-specific artifacts instead of generalizable biological features, limiting clinical utility. PANDA-PLUS-Bench aims to quantify this issue and improve model evaluation.

Method: The benchmark includes nine diverse whole slide images with non-overlapping patches at two resolutions and eight augmentation conditions. Seven foundation models were evaluated for biological signal separation from slide-level confounders.

Result: Models showed significant variation in robustness: Virchow2 had low slide-level encoding (81.0%) and cross-slide accuracy (47.2%), while HistoEncoder excelled (59.7% cross-slide accuracy, 90.3% slide-level encoding). All models had accuracy gaps (19.9-26.9 percentage points).

Conclusion: PANDA-PLUS-Bench fills a critical gap in foundation model evaluation for Gleason grading, showing tissue-specific training enhances performance and providing a standardized tool for future research.

Abstract: Artificial intelligence foundation models are increasingly deployed for prostate cancer Gleason grading, where GP3/GP4 distinction directly impacts treatment decisions. However, these models may achieve high validation accuracy by learning specimen-specific artifacts rather than generalizable biological features, limiting real-world clinical utility. We introduce PANDA-PLUS-Bench, a curated benchmark dataset derived from expert-annotated prostate biopsies designed specifically to quantify this failure mode. The benchmark comprises nine carefully selected whole slide images from nine unique patients containing diverse Gleason patterns, with non-overlapping tissue patches extracted at both 512x512 and 224x224 pixel resolutions across eight augmentation conditions. Using this benchmark, we evaluate seven foundation models on their ability to separate biological signal from slide-level confounders. Our results reveal substantial variation in robustness across models: Virchow2 achieved the lowest slide-level encoding among large-scale models (81.0%) yet exhibited the second-lowest cross-slide accuracy (47.2%). HistoEncoder, trained specifically on prostate tissue, demonstrated the highest cross-slide accuracy (59.7%) and the strongest slide-level encoding (90.3%), suggesting tissue-specific training may enhance both biological feature capture and slide-specific signatures. All models exhibited measurable within-slide vs. cross-slide accuracy gaps, though the magnitude varied from 19.9 percentage points to 26.9 percentage points. We provide an open-source Google Colab notebook enabling researchers to evaluate additional foundation models against our benchmark using standardized metrics. PANDA-PLUS-Bench addresses a critical gap in foundation model evaluation by providing a purpose-built resource for robustness assessment in the clinically important context of Gleason grading.

</details>


### [11] [Improving Pre-trained Segmentation Models using Post-Processing](https://arxiv.org/abs/2512.14937)
*Abhijeet Parida,Daniel Capellán-Martín,Zhifan Jiang,Nishad Kulkarni,Krithika Iyer,Austin Tapp,Syed Muhammad Anwar,María J. Ledesma-Carbayo,Marius George Linguraru*

Main category: cs.CV

TL;DR: Proposes adaptive post-processing techniques to improve glioma segmentation quality from large-scale pre-trained models, achieving better metrics in BraTS challenges.


<details>
  <summary>Details</summary>
Motivation: Gliomas are lethal brain tumors requiring accurate mpMRI segmentation for treatment. Current deep learning models generalize poorly and have high computational costs.

Method: Introduces adaptive post-processing techniques to refine segmentations from pre-trained models, tested in BraTS 2025 tasks.

Result: Improved ranking metrics by 14.9% for sub-Saharan Africa challenge and 0.9% for adult glioma challenge.

Conclusion: Shifts focus from complex architectures to efficient, precise post-processing strategies for sustainable brain tumor segmentation.

Abstract: Gliomas are the most common malignant brain tumors in adults and are among the most lethal. Despite aggressive treatment, the median survival rate is less than 15 months. Accurate multiparametric MRI (mpMRI) tumor segmentation is critical for surgical planning, radiotherapy, and disease monitoring. While deep learning models have improved the accuracy of automated segmentation, large-scale pre-trained models generalize poorly and often underperform, producing systematic errors such as false positives, label swaps, and slice discontinuities in slices. These limitations are further compounded by unequal access to GPU resources and the growing environmental cost of large-scale model training. In this work, we propose adaptive post-processing techniques to refine the quality of glioma segmentations produced by large-scale pretrained models developed for various types of tumors. We demonstrated the techniques in multiple BraTS 2025 segmentation challenge tasks, with the ranking metric improving by 14.9 % for the sub-Saharan Africa challenge and 0.9% for the adult glioma challenge. This approach promotes a shift in brain tumor segmentation research from increasingly complex model architectures to efficient, clinically aligned post-processing strategies that are precise, computationally fair, and sustainable.

</details>


### [12] [TalkVerse: Democratizing Minute-Long Audio-Driven Video Generation](https://arxiv.org/abs/2512.14938)
*Zhenzhi Wang,Jian Wang,Ke Ma,Dahua Lin,Bing Zhou*

Main category: cs.CV

TL;DR: TalkVerse introduces a large-scale open corpus for audio-driven talking video generation, offering 2.3M high-res clips and a reproducible 5B DiT baseline model with efficient inference and storytelling enhancements.


<details>
  <summary>Details</summary>
Motivation: To enable fair, reproducible comparisons in audio-driven video generation, addressing limitations of closed data and compute-heavy models.

Method: Curates 6.3k hours of audio-video clips via a transparent pipeline, trains a 5B DiT model with a video VAE and sliding window mechanism, and integrates an MLLM director for storytelling.

Result: Achieves minute-long generation with low drift, comparable quality to a 14B model at 10x lower cost, and supports zero-shot dubbing.

Conclusion: TalkVerse lowers research barriers by open-sourcing data, recipes, and checkpoints for audio-driven human video generation.

Abstract: We introduce TalkVerse, a large-scale, open corpus for single-person, audio-driven talking video generation designed to enable fair, reproducible comparison across methods. While current state-of-the-art systems rely on closed data or compute-heavy models, TalkVerse offers 2.3 million high-resolution (720p/1080p) audio-video synchronized clips totaling 6.3k hours. These are curated from over 60k hours of video via a transparent pipeline that includes scene-cut detection, aesthetic assessment, strict audio-visual synchronization checks, and comprehensive annotations including 2D skeletons and structured visual/audio-style captions. Leveraging TalkVerse, we present a reproducible 5B DiT baseline built on Wan2.2-5B. By utilizing a video VAE with a high downsampling ratio and a sliding window mechanism with motion-frame context, our model achieves minute-long generation with low drift. It delivers comparable lip-sync and visual quality to the 14B Wan-S2V model but with 10$\times$ lower inference cost. To enhance storytelling in long videos, we integrate an MLLM director to rewrite prompts based on audio and visual cues. Furthermore, our model supports zero-shot video dubbing via controlled latent noise injection. We open-source the dataset, training recipes, and 5B checkpoints to lower barriers for research in audio-driven human video generation. Project Page: https://zhenzhiwang.github.io/talkverse/

</details>


### [13] [Puzzle Curriculum GRPO for Vision-Centric Reasoning](https://arxiv.org/abs/2512.14944)
*Ahmadreza Jeddi,Hakki Can Karaimer,Hue Nguyen,Zhongling Wang,Ke Zhao,Javad Rajabi,Ran Zhang,Raghav Goyal,Babak Taati,Radek Grzeszczuk*

Main category: cs.CV

TL;DR: PC-GRPO is a supervision-free reinforcement learning method for VLMs that uses self-supervised puzzles and a dynamic curriculum to improve reasoning quality and training stability.


<details>
  <summary>Details</summary>
Motivation: Addresses issues in prior RL approaches like reliance on costly annotations, flat rewards, and logical inconsistencies in reasoning.

Method: Introduces Puzzle Curriculum GRPO with self-supervised puzzle environments (PatchFit, Rotation, Jigsaw), a difficulty-aware curriculum, and reasoning-answer consistency monitoring.

Result: Improves reasoning quality, training stability, and downstream accuracy across benchmarks using Qwen-7B and Qwen-3B models.

Conclusion: PC-GRPO offers a scalable, verifiable, and interpretable solution for RL post-training in VLMs.

Abstract: Recent reinforcement learning (RL) approaches like outcome-supervised GRPO have advanced chain-of-thought reasoning in Vision Language Models (VLMs), yet key issues linger: (i) reliance on costly and noisy hand-curated annotations or external verifiers; (ii) flat and sparse reward schemes in GRPO; and (iii) logical inconsistency between a chain's reasoning and its final answer. We present Puzzle Curriculum GRPO (PC-GRPO), a supervision-free recipe for RL with Verifiable Rewards (RLVR) that strengthens visual reasoning in VLMs without annotations or external verifiers. PC-GRPO replaces labels with three self-supervised puzzle environments: PatchFit, Rotation (with binary rewards) and Jigsaw (with graded partial credit mitigating reward sparsity). To counter flat rewards and vanishing group-relative advantages, we introduce a difficulty-aware curriculum that dynamically weights samples and peaks at medium difficulty. We further monitor Reasoning-Answer Consistency (RAC) during post-training: mirroring reports for vanilla GRPO in LLMs, RAC typically rises early then degrades; our curriculum delays this decline, and consistency-enforcing reward schemes further boost RAC. RAC correlates with downstream accuracy. Across diverse benchmarks and on Qwen-7B and Qwen-3B backbones, PC-GRPO improves reasoning quality, training stability, and end-task accuracy, offering a practical path to scalable, verifiable, and interpretable RL post-training for VLMs.

</details>


### [14] [Adaptive Multimodal Person Recognition: A Robust Framework for Handling Missing Modalities](https://arxiv.org/abs/2512.14961)
*Aref Farhadipour,Teodora Vukovic,Volker Dellwo,Petr Motlicek,Srikanth Madikeri*

Main category: cs.CV

TL;DR: A Trimodal person identification framework integrating voice, face, and gesture modalities, robust to missing data. Uses multi-task learning, cross-attention, and confidence-weighted fusion, achieving high accuracy.


<details>
  <summary>Details</summary>
Motivation: Real-world conditions often degrade or remove modalities in person recognition systems, necessitating a robust solution.

Method: Multi-task learning for independent modality processing, cross-attention for interaction, and confidence-weighted fusion for missing data.

Result: 99.18% Top-1 accuracy on CANDOR, 99.92% on VoxCeleb1 in Bimodal mode; robust to missing modalities.

Conclusion: The Trimodal framework is highly effective and robust for real-world person recognition, outperforming traditional methods.

Abstract: Person recognition systems often rely on audio, visual, or behavioral cues, but real-world conditions frequently result in missing or degraded modalities. To address this challenge, we propose a Trimodal person identification framework that integrates voice, face, and gesture modalities, while remaining robust to modality loss. Our approach leverages multi-task learning to process each modality independently, followed by a cross-attention and gated fusion mechanisms to facilitate interaction across modalities. Moreover, a confidence-weighted fusion strategy dynamically adapts to missing and low-quality data, ensuring optimal classification even in Unimodal or Bimodal scenarios. We evaluate our method on CANDOR, a newly introduced interview-based multimodal dataset, which we benchmark for the first time. Our results demonstrate that the proposed Trimodal system achieves 99.18% Top-1 accuracy on person identification tasks, outperforming conventional Unimodal and late-fusion approaches. In addition, we evaluate our model on the VoxCeleb1 dataset as a benchmark and reach 99.92% accuracy in Bimodal mode. Moreover, we show that our system maintains high accuracy even when one or two modalities are unavailable, making it a robust solution for real-world person recognition applications. The code and data for this work are publicly available.

</details>


### [15] [Where is the Watermark? Interpretable Watermark Detection at the Block Level](https://arxiv.org/abs/2512.14994)
*Maria Bulychev,Neil G. Marchant,Benjamin I. P. Rubinstein*

Main category: cs.CV

TL;DR: The paper introduces a post-hoc image watermarking method that provides localized embedding and interpretability, achieving robustness and imperceptibility.


<details>
  <summary>Details</summary>
Motivation: Address concerns around authenticity, ownership, and misuse of AI-generated content by improving transparency and interpretability in watermarking.

Method: Embeds watermark signals in the discrete wavelet transform domain using a statistical block-wise strategy, generating detection maps.

Result: Achieves strong robustness against common image transformations, sensitivity to semantic manipulations, and remains highly imperceptible.

Conclusion: The method offers interpretable detection and competitive robustness, outperforming prior post-hoc approaches.

Abstract: Recent advances in generative AI have enabled the creation of highly realistic digital content, raising concerns around authenticity, ownership, and misuse. While watermarking has become an increasingly important mechanism to trace and protect digital media, most existing image watermarking schemes operate as black boxes, producing global detection scores without offering any insight into how or where the watermark is present. This lack of transparency impacts user trust and makes it difficult to interpret the impact of tampering. In this paper, we present a post-hoc image watermarking method that combines localised embedding with region-level interpretability. Our approach embeds watermark signals in the discrete wavelet transform domain using a statistical block-wise strategy. This allows us to generate detection maps that reveal which regions of an image are likely watermarked or altered. We show that our method achieves strong robustness against common image transformations while remaining sensitive to semantic manipulations. At the same time, the watermark remains highly imperceptible. Compared to prior post-hoc methods, our approach offers more interpretable detection while retaining competitive robustness. For example, our watermarks are robust to cropping up to half the image.

</details>


### [16] [Beyond Proximity: A Keypoint-Trajectory Framework for Classifying Affiliative and Agonistic Social Networks in Dairy Cattle](https://arxiv.org/abs/2512.14998)
*Sibi Parivendan,Kashfia Sailunaz,Suresh Neethirajan*

Main category: cs.CV

TL;DR: A pose-based framework for classifying livestock interactions using anatomical keypoints, surpassing proximity-based methods by differentiating affiliative and agonistic behaviors with high accuracy.


<details>
  <summary>Details</summary>
Motivation: Precision livestock farming needs objective social behavior assessment to monitor welfare, but current methods fail to distinguish interaction types in complex environments.

Method: Uses YOLOv11, ByteTrack, ZebraPose, and SVM classifiers on pose-derived motion signatures from keypoint trajectories.

Result: Achieved 77.51% accuracy in classifying interaction valence, outperforming proximity-only baselines.

Conclusion: Demonstrates feasibility of vision-based, automated social interaction analysis for real-time welfare monitoring.

Abstract: Precision livestock farming requires objective assessment of social behavior to support herd welfare monitoring, yet most existing approaches infer interactions using static proximity thresholds that cannot distinguish affiliative from agonistic behaviors in complex barn environments. This limitation constrains the interpretability of automated social network analysis in commercial settings. We present a pose-based computational framework for interaction classification that moves beyond proximity heuristics by modeling the spatiotemporal geometry of anatomical keypoints. Rather than relying on pixel-level appearance or simple distance measures, the proposed method encodes interaction-specific motion signatures from keypoint trajectories, enabling differentiation of social interaction valence. The framework is implemented as an end-to-end computer vision pipeline integrating YOLOv11 for object detection (mAP@0.50: 96.24%), supervised individual identification (98.24% accuracy), ByteTrack for multi-object tracking (81.96% accuracy), ZebraPose for 27-point anatomical keypoint estimation, and a support vector machine classifier trained on pose-derived distance dynamics. On annotated interaction clips collected from a commercial dairy barn, the classifier achieved 77.51% accuracy in distinguishing affiliative and agonistic behaviors using pose information alone. Comparative evaluation against a proximity-only baseline shows substantial gains in behavioral discrimination, particularly for affiliative interactions. The results establish a proof-of-concept for automated, vision-based inference of social interactions suitable for constructing interaction-aware social networks, with near-real-time performance on commodity hardware.

</details>


### [17] [Evaluating the Capability of Video Question Generation for Expert Knowledge Elicitation](https://arxiv.org/abs/2512.15006)
*Huaying Zhang,Atsushi Hashimoto,Tosho Hirasawa*

Main category: cs.CV

TL;DR: The paper evaluates question-generation models by focusing on question quality for eliciting unseen knowledge, proposing a protocol using question-to-answer retrieval with a new dataset, EgoExoAsk.


<details>
  <summary>Details</summary>
Motivation: To understand what makes questions effective in extracting information from experts, shifting focus from answerability to question quality.

Method: Proposes a protocol evaluating question quality via simulated expert communication using question-to-answer retrieval, leveraging the EgoExoAsk dataset.

Result: Experiments show the metric aligns with question generation goals; models with richer context perform better.

Conclusion: The proposed protocol and dataset effectively evaluate question-generation models for eliciting expert knowledge.

Abstract: Skilled human interviewers can extract valuable information from experts. This raises a fundamental question: what makes some questions more effective than others? To address this, a quantitative evaluation of question-generation models is essential. Video question generation (VQG) is a topic for video question answering (VideoQA), where questions are generated for given answers. Their evaluation typically focuses on the ability to answer questions, rather than the quality of generated questions. In contrast, we focus on the question quality in eliciting unseen knowledge from human experts. For a continuous improvement of VQG models, we propose a protocol that evaluates the ability by simulating question-answering communication with experts using a question-to-answer retrieval. We obtain the retriever by constructing a novel dataset, EgoExoAsk, which comprises 27,666 QA pairs generated from Ego-Exo4D's expert commentary annotation. The EgoExoAsk training set is used to obtain the retriever, and the benchmark is constructed on the validation set with Ego-Exo4D video segments. Experimental results demonstrate our metric reasonably aligns with question generation settings: models accessing richer context are evaluated better, supporting that our protocol works as intended. The EgoExoAsk dataset is available in https://github.com/omron-sinicx/VQG4ExpertKnowledge .

</details>


### [18] [Model Agnostic Preference Optimization for Medical Image Segmentation](https://arxiv.org/abs/2512.15009)
*Yunseong Nam,Jiwon Jang,Dongkyu Won,Sang Hyun Park,Soopil Kim*

Main category: cs.CV

TL;DR: MAPO is a model-agnostic preference optimization framework for medical image segmentation, improving boundary adherence and reducing overfitting without direct ground-truth supervision.


<details>
  <summary>Details</summary>
Motivation: Prior preference optimization methods in medical image segmentation were model-specific and used low-diversity prediction sampling, limiting their applicability and effectiveness.

Method: MAPO employs Dropout-driven stochastic segmentation hypotheses to create preference-consistent gradients, avoiding direct ground-truth supervision. It works with 2D/3D CNN and Transformer-based pipelines.

Result: MAPO consistently improves boundary adherence, reduces overfitting, and provides more stable optimization dynamics compared to traditional supervised training across diverse medical datasets.

Conclusion: MAPO offers a versatile and effective approach for enhancing medical image segmentation, overcoming limitations of prior methods.

Abstract: Preference optimization offers a scalable supervision paradigm based on relative preference signals, yet prior attempts in medical image segmentation remain model-specific and rely on low-diversity prediction sampling. In this paper, we propose MAPO (Model-Agnostic Preference Optimization), a training framework that utilizes Dropout-driven stochastic segmentation hypotheses to construct preference-consistent gradients without direct ground-truth supervision. MAPO is fully architecture- and dimensionality-agnostic, supporting 2D/3D CNN and Transformer-based segmentation pipelines. Comprehensive evaluations across diverse medical datasets reveal that MAPO consistently enhances boundary adherence, reduces overfitting, and yields more stable optimization dynamics compared to conventional supervised training.

</details>


### [19] [MVGSR: Multi-View Consistent 3D Gaussian Super-Resolution via Epipolar Guidance](https://arxiv.org/abs/2512.15048)
*Kaizhe Zhang,Shinan Chen,Qian Zhao,Weizhan Zhang,Caixia Yan,Yudeng Xin*

Main category: cs.CV

TL;DR: MVGSR improves super-resolution for 3D Gaussian Splatting by introducing multi-view consistency and a novel epipolar-constrained attention mechanism.


<details>
  <summary>Details</summary>
Motivation: Existing 3DGS SR methods lack cross-view consistency or require sequential frames, limiting their use for unstructured multi-view datasets.

Method: Proposes an Auxiliary View Selection Method and an epipolar-constrained multi-view attention mechanism to integrate multi-view information for consistent HR rendering.

Result: Achieves state-of-the-art performance on object-centric and scene-level benchmarks, enhancing detail fidelity and geometric consistency.

Conclusion: MVGSR effectively bridges LR inputs to HR rendering for 3DGS, addressing limitations of prior methods.

Abstract: Scenes reconstructed by 3D Gaussian Splatting (3DGS) trained on low-resolution (LR) images are unsuitable for high-resolution (HR) rendering. Consequently, a 3DGS super-resolution (SR) method is needed to bridge LR inputs and HR rendering. Early 3DGS SR methods rely on single-image SR networks, which lack cross-view consistency and fail to fuse complementary information across views. More recent video-based SR approaches attempt to address this limitation but require strictly sequential frames, limiting their applicability to unstructured multi-view datasets. In this work, we introduce Multi-View Consistent 3D Gaussian Splatting Super-Resolution (MVGSR), a framework that focuses on integrating multi-view information for 3DGS rendering with high-frequency details and enhanced consistency. We first propose an Auxiliary View Selection Method based on camera poses, making our method adaptable for arbitrarily organized multi-view datasets without the need of temporal continuity or data reordering. Furthermore, we introduce, for the first time, an epipolar-constrained multi-view attention mechanism into 3DGS SR, which serves as the core of our proposed multi-view SR network. This design enables the model to selectively aggregate consistent information from auxiliary views, enhancing the geometric consistency and detail fidelity of 3DGS representations. Extensive experiments demonstrate that our method achieves state-of-the-art performance on both object-centric and scene-level 3DGS SR benchmarks.

</details>


### [20] [Asynchronous Event Stream Noise Filtering for High-frequency Structure Deformation Measurement](https://arxiv.org/abs/2512.15055)
*Yifei Bian,Banglei Guan,Zibin Liu,Ang Su,Shiyao Zhu,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: Proposes using an event camera and LED markers to measure high-frequency deformations in large-scale structures, overcoming limitations of traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional high-speed cameras are limited by harsh lighting and high costs. Event cameras offer a viable alternative for measuring high-frequency deformations.

Method: Filters noise from event streams of LED markers, distinguishes motion-induced events, and extracts LED markers to measure deformations with a monocular event camera.

Result: Experimental results confirm the method's accuracy in measuring high-frequency planar deformations.

Conclusion: The proposed method effectively measures high-frequency deformations, offering a cost-efficient alternative to traditional high-speed cameras.

Abstract: Large-scale structures suffer high-frequency deformations due to complex loads. However, harsh lighting conditions and high equipment costs limit measurement methods based on traditional high-speed cameras. This paper proposes a method to measure high-frequency deformations by exploiting an event camera and LED markers. Firstly, observation noise is filtered based on the characteristics of the event stream generated by LED markers blinking and spatiotemporal correlation. Then, LED markers are extracted from the event stream after differentiating between motion-induced events and events from LED blinking, which enables the extraction of high-speed moving LED markers. Ultimately, high-frequency planar deformations are measured by a monocular event camera. Experimental results confirm the accuracy of our method in measuring high-frequency planar deformations.

</details>


### [21] [Tracking spatial temporal details in ultrasound long video via wavelet analysis and memory bank](https://arxiv.org/abs/2512.15066)
*Chenxiao Zhang,Runshi Zhang,Junchen Wang*

Main category: cs.CV

TL;DR: Proposes a memory bank-based wavelet filtering and fusion network for accurate segmentation of small objects in medical ultrasound videos, outperforming state-of-the-art methods.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of low contrast, noisy backgrounds, and small object losses in medical ultrasound video segmentation, as well as improve object tracking in long videos.

Method: Uses an encoder-decoder structure with memory-based wavelet convolution, cascaded wavelet compression, and a long short-term memory bank with cross-attention and memory compression mechanisms. Includes an HF-aware feature fusion module for boundary-sensitive details.

Result: Demonstrates significant improvements in segmentation metrics on four ultrasound video datasets, particularly for small thyroid nodules.

Conclusion: The proposed method effectively segments small objects in long ultrasound videos and enhances boundary accuracy, proving its utility in computer-assisted surgery workflows.

Abstract: Medical ultrasound videos are widely used for medical inspections, disease diagnosis and surgical planning. High-fidelity lesion area and target organ segmentation constitutes a key component of the computer-assisted surgery workflow. The low contrast levels and noisy backgrounds of ultrasound videos cause missegmentation of organ boundary, which may lead to small object losses and increase boundary segmentation errors. Object tracking in long videos also remains a significant research challenge. To overcome these challenges, we propose a memory bank-based wavelet filtering and fusion network, which adopts an encoder-decoder structure to effectively extract fine-grained detailed spatial features and integrate high-frequency (HF) information. Specifically, memory-based wavelet convolution is presented to simultaneously capture category, detailed information and utilize adjacent information in the encoder. Cascaded wavelet compression is used to fuse multiscale frequency-domain features and expand the receptive field within each convolutional layer. A long short-term memory bank using cross-attention and memory compression mechanisms is designed to track objects in long video. To fully utilize the boundary-sensitive HF details of feature maps, an HF-aware feature fusion module is designed via adaptive wavelet filters in the decoder. In extensive benchmark tests conducted on four ultrasound video datasets (two thyroid nodule, the thyroid gland, the heart datasets) compared with the state-of-the-art methods, our method demonstrates marked improvements in segmentation metrics. In particular, our method can more accurately segment small thyroid nodules, demonstrating its effectiveness for cases involving small ultrasound objects in long video. The code is available at https://github.com/XiAooZ/MWNet.

</details>


### [22] [PMMD: A pose-guided multi-view multi-modal diffusion for person generation](https://arxiv.org/abs/2512.15069)
*Ziyu Shang,Haoran Liu,Rongchao Zhang,Zhiqian Wei,Tongtong Feng*

Main category: cs.CV

TL;DR: PMMD is a diffusion framework for generating realistic human images using multi-view references, pose maps, and text prompts, addressing issues like occlusions and garment drift.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve consistency and controllability in generating human images for applications like virtual try-on and digital human creation.

Method: PMMD uses a multimodal encoder for visual, pose, and text features, a ResCVA module for detail enhancement, and a cross-modal fusion module for integration during denoising.

Result: Experiments show PMMD outperforms baselines in consistency, detail preservation, and controllability on the DeepFashion MultiModal dataset.

Conclusion: PMMD successfully enhances image generation quality and control, offering a robust solution for various applications.

Abstract: Generating consistent human images with controllable pose and appearance is essential for applications in virtual try on, image editing, and digital human creation. Current methods often suffer from occlusions, garment style drift, and pose misalignment. We propose Pose-guided Multi-view Multimodal Diffusion (PMMD), a diffusion framework that synthesizes photorealistic person images conditioned on multi-view references, pose maps, and text prompts. A multimodal encoder jointly models visual views, pose features, and semantic descriptions, which reduces cross modal discrepancy and improves identity fidelity. We further design a ResCVA module to enhance local detail while preserving global structure, and a cross modal fusion module that integrates image semantics with text throughout the denoising pipeline. Experiments on the DeepFashion MultiModal dataset show that PMMD outperforms representative baselines in consistency, detail preservation, and controllability. Project page and code are available at https://github.com/ZANMANGLOOPYE/PMMD.

</details>


### [23] [Uni-Parser Technical Report](https://arxiv.org/abs/2512.15098)
*Xi Fang,Haoyi Tao,Shuwen Yang,Suyang Zhong,Haocheng Lu,Han Lyu,Chaozheng Huang,Xinyu Li,Linfeng Zhang,Guolin Ke*

Main category: cs.CV

TL;DR: Uni-Parser is an industrial-grade document parsing engine optimized for high throughput and accuracy in processing scientific literature and patents, featuring a modular multi-expert architecture and efficient GPU utilization.


<details>
  <summary>Details</summary>
Motivation: The need for scalable and efficient document parsing tailored for complex scientific and patent documents, preserving cross-modal alignments (text, equations, tables, etc.) and supporting emerging modalities.

Method: Employs a modular, loosely coupled multi-expert architecture with adaptive GPU load balancing, distributed inference, and dynamic module orchestration.

Result: Achieves up to 20 PDF pages per second on 8 x NVIDIA RTX 4090D GPUs, enabling cost-efficient large-scale parsing.

Conclusion: Uni-Parser's scalability and efficiency support diverse downstream applications, from literature retrieval to AI model training.

Abstract: This technical report introduces Uni-Parser, an industrial-grade document parsing engine tailored for scientific literature and patents, delivering high throughput, robust accuracy, and cost efficiency. Unlike pipeline-based document parsing methods, Uni-Parser employs a modular, loosely coupled multi-expert architecture that preserves fine-grained cross-modal alignments across text, equations, tables, figures, and chemical structures, while remaining easily extensible to emerging modalities. The system incorporates adaptive GPU load balancing, distributed inference, dynamic module orchestration, and configurable modes that support either holistic or modality-specific parsing. Optimized for large-scale cloud deployment, Uni-Parser achieves a processing rate of up to 20 PDF pages per second on 8 x NVIDIA RTX 4090D GPUs, enabling cost-efficient inference across billions of pages. This level of scalability facilitates a broad spectrum of downstream applications, ranging from literature retrieval and summarization to the extraction of chemical structures, reaction schemes, and bioactivity data, as well as the curation of large-scale corpora for training next-generation large language models and AI4Science models.

</details>


### [24] [Is Nano Banana Pro a Low-Level Vision All-Rounder? A Comprehensive Evaluation on 14 Tasks and 40 Datasets](https://arxiv.org/abs/2512.15110)
*Jialong Zuo,Haoyou Deng,Hanyu Zhou,Jiaxin Zhu,Yicheng Zhang,Yiwei Zhang,Yongxin Yan,Kaixing Huang,Weisen Chen,Yongtai Deng,Rui Jin,Nong Sang,Changxin Gao*

Main category: cs.CV

TL;DR: The paper evaluates Nano Banana Pro's zero-shot performance on 14 low-level vision tasks, finding it excels in subjective visual quality but lags in traditional quantitative metrics due to generative stochasticity.


<details>
  <summary>Details</summary>
Motivation: To explore whether Nano Banana Pro, a commercial text-to-image model, can serve as a generalist solver for low-level vision tasks, given its underexplored potential in this domain.

Method: Conducted a zero-shot evaluation across 14 low-level vision tasks using 40 datasets, benchmarking against state-of-the-art specialist models with simple textual prompts and no fine-tuning.

Result: Nano Banana Pro shows superior subjective visual quality (hallucinating plausible details) but underperforms in reference-based quantitative metrics due to generative model stochasticity.

Conclusion: Nano Banana Pro is a capable zero-shot option for low-level vision tasks but faces challenges in matching the high fidelity of domain-specific models due to inherent limitations in pixel-level consistency.

Abstract: The rapid evolution of text-to-image generation models has revolutionized visual content creation. While commercial products like Nano Banana Pro have garnered significant attention, their potential as generalist solvers for traditional low-level vision challenges remains largely underexplored. In this study, we investigate the critical question: Is Nano Banana Pro a Low-Level Vision All-Rounder? We conducted a comprehensive zero-shot evaluation across 14 distinct low-level tasks spanning 40 diverse datasets. By utilizing simple textual prompts without fine-tuning, we benchmarked Nano Banana Pro against state-of-the-art specialist models. Our extensive analysis reveals a distinct performance dichotomy: while \textbf{Nano Banana Pro demonstrates superior subjective visual quality}, often hallucinating plausible high-frequency details that surpass specialist models, it lags behind in traditional reference-based quantitative metrics. We attribute this discrepancy to the inherent stochasticity of generative models, which struggle to maintain the strict pixel-level consistency required by conventional metrics. This report identifies Nano Banana Pro as a capable zero-shot contender for low-level vision tasks, while highlighting that achieving the high fidelity of domain specialists remains a significant hurdle.

</details>


### [25] [3DProxyImg: Controllable 3D-Aware Animation Synthesis from Single Image via 2D-3D Aligned Proxy Embedding](https://arxiv.org/abs/2512.15126)
*Yupeng Zhu,Xiongzhen Zhang,Ye Chen,Bingbing Ni*

Main category: cs.CV

TL;DR: A lightweight 3D animation framework decouples geometric control from appearance synthesis, enabling efficient, high-quality animation with precise control, outperforming video-based methods.


<details>
  <summary>Details</summary>
Motivation: Traditional 3D animation pipelines are labor-intensive and expensive, while AIGC-based approaches often sacrifice 3D controllability. The paper aims to bridge this gap by addressing the trade-off between rendering quality and 3D control.

Method: The proposed framework uses a 2D-3D aligned proxy representation, leveraging coarse 3D estimates for structural control and learned image-space priors for high-fidelity appearance synthesis. This avoids expensive optimization while preserving interactive control.

Result: The method efficiently generates 3D animations on low-power platforms, outperforming video-based approaches in identity preservation, consistency, and interactive control.

Conclusion: The framework successfully balances rendering quality and 3D control, offering a practical solution for single-image 3D animation generation with broad applicability.

Abstract: 3D animation is central to modern visual media, yet traditional production pipelines remain labor-intensive, expertise-demanding, and computationally expensive. Recent AIGC-based approaches partially automate asset creation and rigging, but they either inherit the heavy costs of full 3D pipelines or rely on video-synthesis paradigms that sacrifice 3D controllability and interactivity. We focus on single-image 3D animation generation and argue that progress is fundamentally constrained by a trade-off between rendering quality and 3D control.
  To address this limitation, we propose a lightweight 3D animation framework that decouples geometric control from appearance synthesis. The core idea is a 2D-3D aligned proxy representation that uses a coarse 3D estimate as a structural carrier, while delegating high-fidelity appearance and view synthesis to learned image-space generative priors. This proxy formulation enables 3D-aware motion control and interaction comparable to classical pipelines, without requiring accurate geometry or expensive optimization, and naturally extends to coherent background animation. Extensive experiments demonstrate that our method achieves efficient animation generation on low-power platforms and outperforms video-based 3D animation generation in identity preservation, geometric and textural consistency, and the level of precise, interactive control it offers to users.

</details>


### [26] [Explainable Action Form Assessment by Exploiting Multimodal Chain-of-Thoughts Reasoning](https://arxiv.org/abs/2512.15153)
*Mengshi Qi,Yeteng Wu,Xianlin Zhang,Huadong Ma*

Main category: cs.CV

TL;DR: The paper introduces a new Human Action Form Assessment (AFA) task and dataset CoT-AFA, focusing on assessing and explaining action standardization in fitness and martial arts videos. A framework, Explainable Fitness Assessor, is proposed to judge actions and provide detailed feedback.


<details>
  <summary>Details</summary>
Motivation: Current video understanding methods lack the ability to assess action standardization, and existing datasets lack detailed feedback labels. The paper addresses this gap by defining AFA and introducing CoT-AFA.

Method: A novel dataset CoT-AFA with multi-level annotations and Chain-of-Thought explanations is introduced. The Explainable Fitness Assessor framework uses parallel processing streams and dynamic gating to fuse visual and semantic information.

Result: The method improves explanation generation (+16.0% CIDEr), action classification (+2.7% accuracy), and quality assessment (+2.1% accuracy).

Conclusion: The CoT-AFA dataset and framework show promise for future studies in action standardization assessment and feedback.

Abstract: Evaluating whether human action is standard or not and providing reasonable feedback to improve action standardization is very crucial but challenging in real-world scenarios. However, current video understanding methods are mainly concerned with what and where the action is, which is unable to meet the requirements. Meanwhile, most of the existing datasets lack the labels indicating the degree of action standardization, and the action quality assessment datasets lack explainability and detailed feedback. Therefore, we define a new Human Action Form Assessment (AFA) task, and introduce a new diverse dataset CoT-AFA, which contains a large scale of fitness and martial arts videos with multi-level annotations for comprehensive video analysis. We enrich the CoT-AFA dataset with a novel Chain-of-Thought explanation paradigm. Instead of offering isolated feedback, our explanations provide a complete reasoning process--from identifying an action step to analyzing its outcome and proposing a concrete solution. Furthermore, we propose a framework named Explainable Fitness Assessor, which can not only judge an action but also explain why and provide a solution. This framework employs two parallel processing streams and a dynamic gating mechanism to fuse visual and semantic information, thereby boosting its analytical capabilities. The experimental results demonstrate that our method has achieved improvements in explanation generation (e.g., +16.0% in CIDEr), action classification (+2.7% in accuracy) and quality assessment (+2.1% in accuracy), revealing great potential of CoT-AFA for future studies. Our dataset and source code is available at https://github.com/MICLAB-BUPT/EFA.

</details>


### [27] [EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence](https://arxiv.org/abs/2512.15160)
*Jiaxu Wan,Xu Wang,Mengwei Xie,Hang Zhang,Mu Xu,Yang Han,Hong Zhang,Ding Yuan,Yifan Yang*

Main category: cs.CV

TL;DR: EagleVision is a dual-stage framework addressing spatial CoT challenges with macro perception and micro verification, achieving top performance on VSI-Bench.


<details>
  <summary>Details</summary>
Motivation: To overcome weak spatial consistency and limited viewpoint diversity in existing spatial intelligence approaches by addressing key challenges in spatial Chain-of-Thought.

Method: Uses SPF-DPP for keyframe selection in macro perception and BEV-grounded pose querying with reinforcement learning in micro verification.

Result: Achieves state-of-the-art performance on VSI-Bench, demonstrating strong spatial understanding.

Conclusion: EagleVision effectively addresses spatial CoT challenges and generalizes well in spatial cognition tasks.

Abstract: Recent spatial intelligence approaches typically attach 3D cues to 2D reasoning pipelines or couple MLLMs with black-box reconstruction modules, leading to weak spatial consistency, limited viewpoint diversity, and evidence chains that cannot be traced back to supporting views. Frameworks for "thinking with images" (e.g., ChatGPT-o3 and DeepEyes) show that stepwise multimodal reasoning can emerge by interleaving hypothesis formation with active acquisition of visual evidence, but they do not address three key challenges in spatial Chain-of-Thought (CoT): building global space perception under strict token budgets, explicitly associating 3D hypotheses with video frames for verification, and designing spatially grounded rewards for reinforcement learning. To address these issues, we present EagleVision, a dual-stage framework for progressive spatial cognition through macro perception and micro verification. In the macro perception stage, EagleVision employs a semantics-perspective-fusion determinantal point process (SPF-DPP) to select a compact set of geometry- and semantics-aware keyframes from long videos under a fixed token budget. In the micro verification stage, we formalize spatial CoT as BEV-grounded pose querying: the agent iteratively predicts poses on a BEV plane, retrieves the nearest real frames, and is trained purely by reinforcement learning with a spatial grounding reward that scores the consistency between predicted poses and observed views. On VSI-Bench, EagleVision achieves state-of-the-art performance among open-source vision-language models, demonstrating strong and generalizable spatial understanding.

</details>


### [28] [Criticality Metrics for Relevance Classification in Safety Evaluation of Object Detection in Automated Driving](https://arxiv.org/abs/2512.15181)
*Jörg Gamerdinger,Sven Teufel,Stephan Amann,Oliver Bringmann*

Main category: cs.CV

TL;DR: This paper analyzes criticality metrics for safety evaluation of object detection systems in automated driving, proposing novel strategies to improve accuracy by up to 100%.


<details>
  <summary>Details</summary>
Motivation: Ensuring safety in automated driving requires accurate perception, necessitating safety-specific metrics to evaluate object detection systems reliably.

Method: The study conducts a literature review, identifies applicable metrics, validates them using the DeepAccident dataset, and proposes bidirectional criticality rating and multi-metric aggregation.

Result: The approach improves criticality classification accuracy by up to 100%.

Conclusion: The proposed strategies significantly advance safety evaluation for object detection in automated vehicles.

Abstract: Ensuring safety is the primary objective of automated driving, which necessitates a comprehensive and accurate perception of the environment. While numerous performance evaluation metrics exist for assessing perception capabilities, incorporating safety-specific metrics is essential to reliably evaluate object detection systems. A key component for safety evaluation is the ability to distinguish between relevant and non-relevant objects - a challenge addressed by criticality or relevance metrics. This paper presents the first in-depth analysis of criticality metrics for safety evaluation of object detection systems. Through a comprehensive review of existing literature, we identify and assess a range of applicable metrics. Their effectiveness is empirically validated using the DeepAccident dataset, which features a variety of safety-critical scenarios. To enhance evaluation accuracy, we propose two novel application strategies: bidirectional criticality rating and multi-metric aggregation. Our approach demonstrates up to a 100% improvement in terms of criticality classification accuracy, highlighting its potential to significantly advance the safety evaluation of object detection systems in automated vehicles.

</details>


### [29] [Robust and Calibrated Detection of Authentic Multimedia Content](https://arxiv.org/abs/2512.15182)
*Sarim Hashmi,Abdelrahman Elsayed,Mohammed Talha Alam,Samuele Poppi,Nils Lukas*

Main category: cs.CV

TL;DR: The paper proposes a resynthesis framework to detect deepfakes reliably, focusing on high-precision and robustness against efficient adversaries.


<details>
  <summary>Details</summary>
Motivation: Current deepfake detection methods are unreliable due to high false positives and lack of robustness against adversaries.

Method: The authors introduce a resynthesis framework leveraging inversion techniques to verify authenticity or plausibly deny it.

Result: Their method shows reliable verification of authentic samples with low false positives and achieves adversarial robustness against efficient adversaries.

Conclusion: The resynthesis framework outperforms prior methods in reliability and robustness for deepfake detection.

Abstract: Generative models can synthesize highly realistic content, so-called deepfakes, that are already being misused at scale to undermine digital media authenticity. Current deepfake detection methods are unreliable for two reasons: (i) distinguishing inauthentic content post-hoc is often impossible (e.g., with memorized samples), leading to an unbounded false positive rate (FPR); and (ii) detection lacks robustness, as adversaries can adapt to known detectors with near-perfect accuracy using minimal computational resources. To address these limitations, we propose a resynthesis framework to determine if a sample is authentic or if its authenticity can be plausibly denied. We make two key contributions focusing on the high-precision, low-recall setting against efficient (i.e., compute-restricted) adversaries. First, we demonstrate that our calibrated resynthesis method is the most reliable approach for verifying authentic samples while maintaining controllable, low FPRs. Second, we show that our method achieves adversarial robustness against efficient adversaries, whereas prior methods are easily evaded under identical compute budgets. Our approach supports multiple modalities and leverages state-of-the-art inversion techniques.

</details>


### [30] [ERIENet: An Efficient RAW Image Enhancement Network under Low-Light Environment](https://arxiv.org/abs/2512.15186)
*Jianan Wang,Yang Hong,Hesong Li,Tao Wang,Songrong Liu,Ying Fu*

Main category: cs.CV

TL;DR: ERIENet is a lightweight, efficient network for RAW image enhancement that processes multi-scale information in parallel and leverages green channel superiority, achieving high speed and better performance.


<details>
  <summary>Details</summary>
Motivation: Existing RAW-based low-light enhancement methods are computationally heavy and ignore the green channel's rich information, limiting performance and speed.

Method: ERIENet uses a parallel multi-scale architecture with a channel-aware residual dense block and a green channel guidance branch for efficient feature extraction and reconstruction.

Result: ERIENet outperforms state-of-the-art methods, achieves over 146 FPS for 4K images, and demonstrates higher efficiency and better reconstruction quality.

Conclusion: The proposed ERIENet efficiently enhances low-light RAW images by leveraging parallel processing and green channel information, setting a new benchmark for speed and performance.

Abstract: RAW images have shown superior performance than sRGB images in many image processing tasks, especially for low-light image enhancement. However, most existing methods for RAW-based low-light enhancement usually sequentially process multi-scale information, which makes it difficult to achieve lightweight models and high processing speeds. Besides, they usually ignore the green channel superiority of RAW images, and fail to achieve better reconstruction performance with good use of green channel information. In this work, we propose an efficient RAW Image Enhancement Network (ERIENet), which parallelly processes multi-scale information with efficient convolution modules, and takes advantage of rich information in green channels to guide the reconstruction of images. Firstly, we introduce an efficient multi-scale fully-parallel architecture with a novel channel-aware residual dense block to extract feature maps, which reduces computational costs and achieves real-time processing speed. Secondly, we introduce a green channel guidance branch to exploit the rich information within the green channels of the input RAW image. It increases the quality of reconstruction results with few parameters and computations. Experiments on commonly used low-light image enhancement datasets show that ERIENet outperforms state-of-the-art methods in enhancing low-light RAW images with higher effiency. It also achieves an optimal speed of over 146 frame-per-second (FPS) for 4K-resolution images on a single NVIDIA GeForce RTX 3090 with 24G memory.

</details>


### [31] [TBC: A Target-Background Contrast Metric for Low-Altitude Infrared and Visible Image Fusion](https://arxiv.org/abs/2512.15211)
*Yufeng Xie*

Main category: cs.CV

TL;DR: The paper introduces the Target-Background Contrast (TBC) metric to improve infrared and visible image fusion in UAV missions, addressing the limitations of traditional no-reference metrics in low-light environments.


<details>
  <summary>Details</summary>
Motivation: Current metrics like EN and AG fail in complex low-light conditions by misinterpreting noise as valid detail, leading to a 'Noise Trap' that misguides fusion algorithms.

Method: Proposes the TBC metric, inspired by Weber's Law, which evaluates relative contrast of salient targets instead of global statistics, penalizing noise and enhancing target visibility.

Result: Tests on the DroneVehicle dataset show TBC aligns better with human perception and is more reliable for low-altitude UAV scenarios.

Conclusion: TBC provides a more accurate and practical metric for image fusion in challenging environments, outperforming traditional approaches.

Abstract: Infrared and visible image fusion is a pivotal technology in low-altitude UAV reconnaissance missions, providing high-quality data support for downstream tasks such as target detection and tracking by integrating thermal saliency with background texture details.However, traditional no-reference metrics fail(Specifically,like Entropy (EN) and Average Gradient (AG)) in complex low-light environments. They often misinterpret high-frequency sensor noise as valid detail. This creates a "Noise Trap," paradoxically assigning higher scores to noisy images and misguiding fusion algorithms.To address this, we propose the Target-Background Contrast (TBC) metric. Inspired by Weber's Law, TBC focuses on the relative contrast of salient targets rather than global statistics. Unlike traditional metrics, TBC penalizes background noise and rewards target visibility. Experiments on the DroneVehicle dataset demonstrate that TBC aligns better with human perception and provides a reliable standard for low-altitude scenarios.

</details>


### [32] [From Camera to World: A Plug-and-Play Module for Human Mesh Transformation](https://arxiv.org/abs/2512.15212)
*Changhai Ma,Ziyu Wu,Yunkang Zhang,Qijun Ying,Boyan Liu,Xiaohui Cai*

Main category: cs.CV

TL;DR: Mesh-Plug is a plug-and-play module transforming human meshes from camera to world coordinates by estimating camera rotation using RGB images and depth maps, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Accurate 3D human mesh reconstruction in-world coordinates is hindered by unknown camera rotation, leading to errors when simplified assumptions (zero rotation) are made.

Method: Mesh-Plug uses RGB images and depth maps from initial meshes to predict camera rotation (focusing on human spatial configuration) and refines root joint orientation and body pose.

Result: Outperforms state-of-the-art methods on SPEC-SYN and SPEC-MTP datasets.

Conclusion: Mesh-Plug effectively addresses camera rotation challenges for accurate 3D human mesh reconstruction in-world coordinates.

Abstract: Reconstructing accurate 3D human meshes in the world coordinate system from in-the-wild images remains challenging due to the lack of camera rotation information. While existing methods achieve promising results in the camera coordinate system by assuming zero camera rotation, this simplification leads to significant errors when transforming the reconstructed mesh to the world coordinate system. To address this challenge, we propose Mesh-Plug, a plug-and-play module that accurately transforms human meshes from camera coordinates to world coordinates. Our key innovation lies in a human-centered approach that leverages both RGB images and depth maps rendered from the initial mesh to estimate camera rotation parameters, eliminating the dependency on environmental cues. Specifically, we first train a camera rotation prediction module that focuses on the human body's spatial configuration to estimate camera pitch angle. Then, by integrating the predicted camera parameters with the initial mesh, we design a mesh adjustment module that simultaneously refines the root joint orientation and body pose. Extensive experiments demonstrate that our framework outperforms state-of-the-art methods on the benchmark datasets SPEC-SYN and SPEC-MTP.

</details>


### [33] [Null-LoRA: Low-Rank Adaptation on Null Space](https://arxiv.org/abs/2512.15233)
*Yi Zhang,Yulei Kang,Haoxuan Chen,Jinxuan Li,ian-Fang Hu*

Main category: cs.CV

TL;DR: Null-LoRA introduces a subspace-based low-rank adaptation method, leveraging null spaces in pre-trained models to reduce redundancy and improve efficiency, outperforming existing methods with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Existing low-rank adaptation methods operate over the full parameter space, which may be redundant. Fine-tuning within a subspace can achieve comparable effectiveness by utilizing null spaces in pre-trained models.

Method: Null-LoRA freezes portions of low-rank matrices and constrains incremental updates within the null space of pre-trained models, enhancing parameter efficiency and effective rank.

Result: Null-LoRA outperforms state-of-the-art methods with fewer parameters in tasks like image-text retrieval and visual question answering.

Conclusion: Null-LoRA demonstrates that subspace-based adaptation is effective, reducing redundancy while maintaining performance, making it a promising approach for parameter-efficient fine-tuning.

Abstract: Parameter-efficient fine-tuning methods have gained considerable popularity for adapting large-scale models to downstream tasks, particularly LoRA and its variants. Existing methods perform low-rank adaptation over the full parameter space. However, fine-tuning within a subspace can achieve comparable effectiveness. Inspired by the observation that pre-trained models possess non-trivial null spaces, we propose Null-space based Low-Rank Adaptation (Null-LoRA). Null-LoRA effectively reduces redundancy and enhances effective rank by freezing portions of the low-rank matrices. To further improve parameter efficiency, Null-LoRA constrains the entire incremental update within the null space, maximizing the utilization of incremental updates to adapt to new task paradigms. Null-LoRA surpasses the state of the art with fewer parameters in extensive experiments across image-text retrieval and visual question answering tasks.

</details>


### [34] [Intersectional Fairness in Vision-Language Models for Medical Image Disease Classification](https://arxiv.org/abs/2512.15249)
*Yupeng Zhang,Adam G. Dunn,Usman Naseem,Jinman Kim*

Main category: cs.CV

TL;DR: The study introduces Cross-Modal Alignment Consistency (CMAC-MMD) to reduce intersectional biases in medical AI systems, improving diagnostic accuracy and fairness without needing sensitive demographic data during inference.


<details>
  <summary>Details</summary>
Motivation: Existing medical AI systems exhibit intersectional biases, leading to inaccurate diagnoses for marginalized subgroups. Current fairness methods often fail or degrade performance.

Method: Developed CMAC-MMD, a training framework that standardizes diagnostic certainty across intersectional subgroups without requiring demographic data during clinical inference.

Result: CMAC-MMD reduced intersectional missed diagnosis gaps ($Δ$TPR) and improved AUC in dermatology (reduced $Δ$TPR from 0.50 to 0.26, AUC from 0.94 to 0.97) and glaucoma screening (reduced $Δ$TPR from 0.41 to 0.31, AUC from 0.71 to 0.72).

Conclusion: The framework ensures equitable and accurate clinical decision support without privacy risks, making it scalable for high-stakes applications.

Abstract: Medical artificial intelligence (AI) systems, particularly multimodal vision-language models (VLM), often exhibit intersectional biases where models are systematically less confident in diagnosing marginalised patient subgroups. Such bias can lead to higher rates of inaccurate and missed diagnoses due to demographically skewed data and divergent distributions of diagnostic certainty. Current fairness interventions frequently fail to address these gaps or compromise overall diagnostic performance to achieve statistical parity among the subgroups. In this study, we developed Cross-Modal Alignment Consistency (CMAC-MMD), a training framework that standardises diagnostic certainty across intersectional patient subgroups. Unlike traditional debiasing methods, this approach equalises the model's decision confidence without requiring sensitive demographic data during clinical inference. We evaluated this approach using 10,015 skin lesion images (HAM10000) with external validation on 12,000 images (BCN20000), and 10,000 fundus images for glaucoma detection (Harvard-FairVLMed), stratifying performance by intersectional age, gender, and race attributes. In the dermatology cohort, the proposed method reduced the overall intersectional missed diagnosis gap (difference in True Positive Rate, $Δ$TPR) from 0.50 to 0.26 while improving the overall Area Under the Curve (AUC) from 0.94 to 0.97 compared to standard training. Similarly, for glaucoma screening, the method reduced $Δ$TPR from 0.41 to 0.31, achieving a better AUC of 0.72 (vs. 0.71 baseline). This establishes a scalable framework for developing high-stakes clinical decision support systems that are both accurate and can perform equitably across diverse patient subgroups, ensuring reliable performance without increasing privacy risks.

</details>


### [35] [Assessing the Visual Enumeration Abilities of Specialized Counting Architectures and Vision-Language Models](https://arxiv.org/abs/2512.15254)
*Kuinan Hou,Jing Mi,Marco Zorzi,Lamberto Ballan,Alberto Testolin*

Main category: cs.CV

TL;DR: VLMs perform comparably or better than specialized counting architectures in enumerating items in visual scenes, especially with intermediate representations, but struggle in complex scenes.


<details>
  <summary>Details</summary>
Motivation: The study aims to explore if large-scale multimodal vision-language models (VLMs) can outperform specialized counting architectures in open-set object counting tasks.

Method: The performance of VLMs and specialized counting architectures was systematically compared on two popular counting datasets and a novel benchmark with controlled visual properties.

Result: VLMs match or surpass specialized architectures in enumeration accuracy, particularly when generating intermediate representations. However, both struggle in complex scenes.

Conclusion: While VLMs show promise for open-set counting, further research is needed to improve their reliability in complex visual environments.

Abstract: Counting the number of items in a visual scene remains a fundamental yet challenging task in computer vision. Traditional approaches to solving this problem rely on domain-specific counting architectures, which are trained using datasets annotated with a predefined set of object categories. However, recent progress in creating large-scale multimodal vision-language models (VLMs) suggests that these domain-general architectures may offer a flexible alternative for open-set object counting. In this study, we therefore systematically compare the performance of state-of-the-art specialized counting architectures against VLMs on two popular counting datasets, as well as on a novel benchmark specifically created to have a finer-grained control over the visual properties of test images. Our findings show that most VLMs can approximately enumerate the number of items in a visual scene, matching or even surpassing the performance of specialized computer vision architectures. Notably, enumeration accuracy significantly improves when VLMs are prompted to generate intermediate representations (i.e., locations and verbal labels) of each object to be counted. Nevertheless, none of the models can reliably count the number of objects in complex visual scenes, showing that further research is still needed to create AI systems that can reliably deploy counting procedures in realistic environments.

</details>


### [36] [MMMamba: A Versatile Cross-Modal In Context Fusion Framework for Pan-Sharpening and Zero-Shot Image Enhancement](https://arxiv.org/abs/2512.15261)
*Yingying Wang,Xuanhua He,Chen Wu,Jialing Huang,Suiyun Zhang,Rui Liu,Xinghao Ding,Haoxuan Che*

Main category: cs.CV

TL;DR: The paper introduces MMMamba, a cross-modal in-context fusion framework for pan-sharpening, leveraging the Mamba architecture to improve efficiency and performance over traditional methods.


<details>
  <summary>Details</summary>
Motivation: Traditional CNN-based pan-sharpening methods are limited by fixed operators, while cross-attention mechanisms are inefficient. MMMamba addresses these issues by enabling direct cross-modal information exchange.

Method: MMMamba uses the Mamba architecture with a novel multimodal interleaved scanning mechanism for efficient cross-modal fusion. It supports zero-shot image super-resolution.

Result: The method outperforms existing state-of-the-art techniques in pan-sharpening and related tasks across multiple benchmarks.

Conclusion: MMMamba offers a scalable, efficient solution for pan-sharpening with superior performance, leveraging in-context conditioning and linear computational complexity.

Abstract: Pan-sharpening aims to generate high-resolution multispectral (HRMS) images by integrating a high-resolution panchromatic (PAN) image with its corresponding low-resolution multispectral (MS) image. To achieve effective fusion, it is crucial to fully exploit the complementary information between the two modalities. Traditional CNN-based methods typically rely on channel-wise concatenation with fixed convolutional operators, which limits their adaptability to diverse spatial and spectral variations. While cross-attention mechanisms enable global interactions, they are computationally inefficient and may dilute fine-grained correspondences, making it difficult to capture complex semantic relationships. Recent advances in the Multimodal Diffusion Transformer (MMDiT) architecture have demonstrated impressive success in image generation and editing tasks. Unlike cross-attention, MMDiT employs in-context conditioning to facilitate more direct and efficient cross-modal information exchange. In this paper, we propose MMMamba, a cross-modal in-context fusion framework for pan-sharpening, with the flexibility to support image super-resolution in a zero-shot manner. Built upon the Mamba architecture, our design ensures linear computational complexity while maintaining strong cross-modal interaction capacity. Furthermore, we introduce a novel multimodal interleaved (MI) scanning mechanism that facilitates effective information exchange between the PAN and MS modalities. Extensive experiments demonstrate the superior performance of our method compared to existing state-of-the-art (SOTA) techniques across multiple tasks and benchmarks.

</details>


### [37] [SynthSeg-Agents: Multi-Agent Synthetic Data Generation for Zero-Shot Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2512.15310)
*Wangyu Wu,Zhenhong Chen,Xiaowei Huang,Fei Ma,Jimin Xiao*

Main category: cs.CV

TL;DR: The paper introduces Zero Shot Weakly Supervised Semantic Segmentation (ZSWSSS) and proposes SynthSeg Agents, a framework using LLMs to generate synthetic training data without real images, achieving competitive results on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: To eliminate the dependency on real-world training samples for semantic segmentation by leveraging synthetic data generation.

Method: Uses a multi-agent framework with a Self-Refine Prompt Agent and Image Generation Agent to create diverse synthetic images guided by CLIP and VLMs, followed by quality filtering and relabeling.

Result: Achieves competitive performance on PASCAL VOC 2012 and COCO 2014 without real training images.

Conclusion: Demonstrates the potential of LLM-driven agents for cost-efficient and scalable semantic segmentation.

Abstract: Weakly Supervised Semantic Segmentation (WSSS) with image level labels aims to produce pixel level predictions without requiring dense annotations. While recent approaches have leveraged generative models to augment existing data, they remain dependent on real world training samples. In this paper, we introduce a novel direction, Zero Shot Weakly Supervised Semantic Segmentation (ZSWSSS), and propose SynthSeg Agents, a multi agent framework driven by Large Language Models (LLMs) to generate synthetic training data entirely without real images. SynthSeg Agents comprises two key modules, a Self Refine Prompt Agent and an Image Generation Agent. The Self Refine Prompt Agent autonomously crafts diverse and semantically rich image prompts via iterative refinement, memory mechanisms, and prompt space exploration, guided by CLIP based similarity and nearest neighbor diversity filtering. These prompts are then passed to the Image Generation Agent, which leverages Vision Language Models (VLMs) to synthesize candidate images. A frozen CLIP scoring model is employed to select high quality samples, and a ViT based classifier is further trained to relabel the entire synthetic dataset with improved semantic precision. Our framework produces high quality training data without any real image supervision. Experiments on PASCAL VOC 2012 and COCO 2014 show that SynthSeg Agents achieves competitive performance without using real training images. This highlights the potential of LLM driven agents in enabling cost efficient and scalable semantic segmentation.

</details>


### [38] [KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Bird's-Eye-View Segmentation](https://arxiv.org/abs/2512.15311)
*Wenke E,Yixin Sun,Jiaxu Liu,Hubert P. H. Shum,Amir Atapour-Abarghouei,Toby P. Breckon*

Main category: cs.CV

TL;DR: A cross-modality distillation framework for BEV segmentation using a single panoramic camera, outperforming existing methods and achieving fast inference speeds.


<details>
  <summary>Details</summary>
Motivation: To provide an efficient, low-cost solution for BEV segmentation in autonomous driving by reducing sensor complexity and deployment costs.

Method: Uses a novel LiDAR image representation and a voxel-aligned view transformer for cross-modality distillation from a Teacher (LiDAR + camera) to a Student (single camera) network.

Result: Teacher model improves IoU by 25.6%, while the Student achieves an 8.5% IoU gain and 31.2 FPS. Framework generalizes to diverse camera setups.

Conclusion: The framework is feasible, robust, and practical for real-world autonomous driving.

Abstract: We present the first cross-modality distillation framework specifically tailored for single-panoramic-camera Bird's-Eye-View (BEV) segmentation. Our approach leverages a novel LiDAR image representation fused from range, intensity and ambient channels, together with a voxel-aligned view transformer that preserves spatial fidelity while enabling efficient BEV processing. During training, a high-capacity LiDAR and camera fusion Teacher network extracts both rich spatial and semantic features for cross-modality knowledge distillation into a lightweight Student network that relies solely on a single 360-degree panoramic camera image. Extensive experiments on the Dur360BEV dataset demonstrate that our teacher model significantly outperforms existing camera-based BEV segmentation methods, achieving a 25.6\% IoU improvement. Meanwhile, the distilled Student network attains competitive performance with an 8.5\% IoU gain and state-of-the-art inference speed of 31.2 FPS. Moreover, evaluations on KITTI-360 (two fisheye cameras) confirm that our distillation framework generalises to diverse camera setups, underscoring its feasibility and robustness. This approach reduces sensor complexity and deployment costs while providing a practical solution for efficient, low-cost BEV segmentation in real-world autonomous driving.

</details>


### [39] [Automated Motion Artifact Check for MRI (AutoMAC-MRI): An Interpretable Framework for Motion Artifact Detection and Severity Assessment](https://arxiv.org/abs/2512.15315)
*Antony Jerald,Dattesh Shanbhag,Sudhanya Chatterjee*

Main category: cs.CV

TL;DR: AutoMAC-MRI is an explainable framework for grading motion artifacts in MRI images using supervised contrastive learning and affinity scores, improving interpretability and workflow efficiency.


<details>
  <summary>Details</summary>
Motivation: Motion artifacts degrade MRI quality, but existing automated methods lack interpretability and granularity.

Method: Uses supervised contrastive learning to create discriminative representations of motion severity and computes grade-specific affinity scores.

Result: Evaluated on 5000+ MRI slices, AutoMAC-MRI's affinity scores align well with expert labels.

Conclusion: AutoMAC-MRI enhances MRI quality control by providing interpretable motion severity grading, reducing rescans and improving efficiency.

Abstract: Motion artifacts degrade MRI image quality and increase patient recalls. Existing automated quality assessment methods are largely limited to binary decisions and provide little interpretability. We introduce AutoMAC-MRI, an explainable framework for grading motion artifacts across heterogeneous MR contrasts and orientations. The approach uses supervised contrastive learning to learn a discriminative representation of motion severity. Within this feature space, we compute grade-specific affinity scores that quantify an image's proximity to each motion grade, thereby making grade assignments transparent and interpretable. We evaluate AutoMAC-MRI on more than 5000 expert-annotated brain MRI slices spanning multiple contrasts and views. Experiments assessing affinity scores against expert labels show that the scores align well with expert judgment, supporting their use as an interpretable measure of motion severity. By coupling accurate grade detection with per-grade affinity scoring, AutoMAC-MRI enables inline MRI quality control, with the potential to reduce unnecessary rescans and improve workflow efficiency.

</details>


### [40] [Prototypical Learning Guided Context-Aware Segmentation Network for Few-Shot Anomaly Detection](https://arxiv.org/abs/2512.15319)
*Yuxin Jiang,Yunkang Cao,Weiming Shen*

Main category: cs.CV

TL;DR: PCSNet improves few-shot anomaly detection by addressing domain gaps with prototypical learning and context-aware segmentation, achieving high accuracy with limited samples.


<details>
  <summary>Details</summary>
Motivation: Existing FSAD methods rely on pre-trained features but overlook domain gaps, leading to suboptimal performance in target scenarios.

Method: PCSNet uses a Prototypical Feature Adaption sub-network for better feature compactness and a Context-Aware Segmentation sub-network for pixel-level anomaly localization, leveraging pseudo anomalies for training.

Result: PCSNet achieves 94.9% and 80.2% image-level AUROC on MVTec and MPDD datasets in an 8-shot scenario, with real-world validation in automotive inspections.

Conclusion: PCSNet effectively addresses domain gaps in FSAD, outperforming existing methods and demonstrating practical applicability with limited samples.

Abstract: Few-shot anomaly detection (FSAD) denotes the identification of anomalies within a target category with a limited number of normal samples. Existing FSAD methods largely rely on pre-trained feature representations to detect anomalies, but the inherent domain gap between pre-trained representations and target FSAD scenarios is often overlooked. This study proposes a Prototypical Learning Guided Context-Aware Segmentation Network (PCSNet) to address the domain gap, thereby improving feature descriptiveness in target scenarios and enhancing FSAD performance. In particular, PCSNet comprises a prototypical feature adaption (PFA) sub-network and a context-aware segmentation (CAS) sub-network. PFA extracts prototypical features as guidance to ensure better feature compactness for normal data while distinct separation from anomalies. A pixel-level disparity classification loss is also designed to make subtle anomalies more distinguishable. Then a CAS sub-network is introduced for pixel-level anomaly localization, where pseudo anomalies are exploited to facilitate the training process. Experimental results on MVTec and MPDD demonstrate the superior FSAD performance of PCSNet, with 94.9% and 80.2% image-level AUROC in an 8-shot scenario, respectively. Real-world applications on automotive plastic part inspection further demonstrate that PCSNet can achieve promising results with limited training samples. Code is available at https://github.com/yuxin-jiang/PCSNet.

</details>


### [41] [MECAD: A multi-expert architecture for continual anomaly detection](https://arxiv.org/abs/2512.15323)
*Malihe Dahmardeh,Francesco Setti*

Main category: cs.CV

TL;DR: MECAD introduces a multi-expert architecture for continual anomaly detection, optimizing coreset selection and replay buffers to retain class knowledge without full retraining, achieving AUROC 0.8259 on MVTec AD.


<details>
  <summary>Details</summary>
Motivation: Addresses the challenge of continual anomaly detection in dynamic industrial environments with evolving product types.

Method: Uses a multi-expert architecture with dynamic expert assignment, coreset selection, and replay buffers for incremental learning.

Result: Achieves an average AUROC of 0.8259 on MVTec AD with reduced knowledge degradation compared to single-expert approaches.

Conclusion: MECAD balances efficiency, knowledge retention, and adaptability, making it suitable for industrial applications.

Abstract: In this paper we propose MECAD, a novel approach for continual anomaly detection using a multi-expert architecture. Our system dynamically assigns experts to object classes based on feature similarity and employs efficient memory management to preserve the knowledge of previously seen classes. By leveraging an optimized coreset selection and a specialized replay buffer mechanism, we enable incremental learning without requiring full model retraining. Our experimental evaluation on the MVTec AD dataset demonstrates that the optimal 5-expert configuration achieves an average AUROC of 0.8259 across 15 diverse object categories while significantly reducing knowledge degradation compared to single-expert approaches. This framework balances computational efficiency, specialized knowledge retention, and adaptability, making it well-suited for industrial environments with evolving product types.

</details>


### [42] [A Masked Reverse Knowledge Distillation Method Incorporating Global and Local Information for Image Anomaly Detection](https://arxiv.org/abs/2512.15326)
*Yuxin Jiang,Yunkang Can,Weiming Shen*

Main category: cs.CV

TL;DR: MRKD improves anomaly detection by masking inputs at image and feature levels, reducing overgeneralization and achieving high performance.


<details>
  <summary>Details</summary>
Motivation: Address the overgeneralization issue in knowledge distillation for anomaly detection by differentiating input and supervisory signals.

Method: Introduces masked reverse knowledge distillation (MRKD) using image-level masking (ILM) and feature-level masking (FLM) to transform reconstruction into restoration.

Result: Achieves 98.9% AU-ROC (image-level), 98.4% AU-ROC (pixel-level), and 95.3% AU-PRO on MVTec dataset; mitigates overgeneralization.

Conclusion: MRKD effectively enhances context capture and reduces overgeneralization, outperforming existing methods.

Abstract: Knowledge distillation is an effective image anomaly detection and localization scheme. However, a major drawback of this scheme is its tendency to overly generalize, primarily due to the similarities between input and supervisory signals. In order to address this issue, this paper introduces a novel technique called masked reverse knowledge distillation (MRKD). By employing image-level masking (ILM) and feature-level masking (FLM), MRKD transforms the task of image reconstruction into image restoration. Specifically, ILM helps to capture global information by differentiating input signals from supervisory signals. On the other hand, FLM incorporates synthetic feature-level anomalies to ensure that the learned representations contain sufficient local information. With these two strategies, MRKD is endowed with stronger image context capture capacity and is less likely to be overgeneralized. Experiments on the widely-used MVTec anomaly detection dataset demonstrate that MRKD achieves impressive performance: image-level 98.9% AU-ROC, pixel-level 98.4% AU-ROC, and 95.3% AU-PRO. In addition, extensive ablation experiments have validated the superiority of MRKD in mitigating the overgeneralization problem.

</details>


### [43] [Vision-based module for accurately reading linear scales in a laboratory](https://arxiv.org/abs/2512.15327)
*Parvesh Saini,Soumyadipta Maiti,Beena Rai*

Main category: cs.CV

TL;DR: Vision models can perform tasks like object detection and image classification but struggle with quantitative measurements from images. This paper presents a human-inspired approach for reading measurements from linear scales, tested on syringes and measuring cylinders, achieving accuracy comparable to human readings.


<details>
  <summary>Details</summary>
Motivation: Existing vision models lack the ability to take accurate quantitative measurements from images, a crucial skill for autonomous robots in laboratory environments.

Method: The approach involves correcting the orientation of randomly oriented syringes, reducing the area of interest to the linear scale, extracting features like major markers and digits, and calculating the final reading.

Result: The system's readings were compared to human readings and showed accurate correspondence, demonstrating its effectiveness.

Conclusion: The proposed method successfully mimics human-like measurement reading from linear scales, proving useful for autonomous laboratory robots.

Abstract: Capabilities and the number of vision-based models are increasing rapidly. And these vision models are now able to do more tasks like object detection, image classification, instance segmentation etc. with great accuracy. But models which can take accurate quantitative measurements form an image, as a human can do by just looking at it, are rare. For a robot to work with complete autonomy in a Laboratory environment, it needs to have some basic skills like navigation, handling objects, preparing samples etc. to match human-like capabilities in an unstructured environment. Another important capability is to read measurements from instruments and apparatus. Here, we tried to mimic a human inspired approach to read measurements from a linear scale. As a test case we have picked reading level from a syringe and a measuring cylinder. For a randomly oriented syringe we carry out transformations to correct the orientation. To make the system efficient and robust, the area of interest is reduced to just the linear scale containing part of the image. After that, a series of features were extracted like the major makers, the corresponding digits, and the level indicator location, from which the final reading was calculated. Readings obtained using this system were also compared against human read values of the same instances and an accurate correspondence was observed.

</details>


### [44] [Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics](https://arxiv.org/abs/2512.15340)
*Junjie Chen,Fei Wang,Zhihao Huang,Qing Zhou,Kun Li,Dan Guo,Linfeng Zhang,Xun Yang*

Main category: cs.CV

TL;DR: TIMAR (Turn-level Interleaved Masked AutoRegression) is a causal framework for 3D conversational head generation, modeling dialogue as interleaved audio-visual contexts to improve temporal coherence and expressive variability.


<details>
  <summary>Details</summary>
Motivation: Existing frameworks for modeling conversational dynamics in 3D often treat talking and listening as independent processes or use non-causal full-sequence modeling, which lacks temporal coherence across turns.

Method: TIMAR fuses multimodal information within each conversational turn and uses turn-level causal attention to accumulate history. A lightweight diffusion head predicts continuous 3D head dynamics.

Result: TIMAR reduces Fréchet Distance and MSE by 15-30% on the DualTalk benchmark and shows similar improvements on out-of-distribution data.

Conclusion: TIMAR effectively models bidirectional conversational dynamics in 3D, improving temporal coherence and expressive variability for avatars and interactive robots.

Abstract: Human conversation involves continuous exchanges of speech and nonverbal cues such as head nods, gaze shifts, and facial expressions that convey attention and emotion. Modeling these bidirectional dynamics in 3D is essential for building expressive avatars and interactive robots. However, existing frameworks often treat talking and listening as independent processes or rely on non-causal full-sequence modeling, hindering temporal coherence across turns. We present TIMAR (Turn-level Interleaved Masked AutoRegression), a causal framework for 3D conversational head generation that models dialogue as interleaved audio-visual contexts. It fuses multimodal information within each turn and applies turn-level causal attention to accumulate conversational history, while a lightweight diffusion head predicts continuous 3D head dynamics that captures both coordination and expressive variability. Experiments on the DualTalk benchmark show that TIMAR reduces Fréchet Distance and MSE by 15-30% on the test set, and achieves similar gains on out-of-distribution data. The source code will be released in the GitHub repository https://github.com/CoderChen01/towards-seamleass-interaction.

</details>


### [45] [Expand and Prune: Maximizing Trajectory Diversity for Effective GRPO in Generative Models](https://arxiv.org/abs/2512.15347)
*Shiran Ge,Chenyi Huang,Yuang Ai,Qihang Fan,Huaibo Huang,Ran He*

Main category: cs.CV

TL;DR: Pro-GRPO addresses the computational bottleneck in Group Relative Policy Optimization (GRPO) by dynamically pruning low-variance trajectories during sampling, improving efficiency without sacrificing performance.


<details>
  <summary>Details</summary>
Motivation: The conflict between large group sizes and high computational costs in GRPO limits its effectiveness, prompting the need for a more efficient approach.

Method: Pro-GRPO integrates latent feature-based trajectory pruning into the sampling process, using an 'Expand-and-Prune' strategy and Optimal Variance Filtering (OVF) to reduce overhead.

Result: Experiments show Pro-GRPO reduces computational costs while maintaining or improving performance compared to traditional GRPO.

Conclusion: Pro-GRPO is a dynamic and efficient framework that enhances GRPO by proactively filtering trajectories, making it practical for large-scale applications.

Abstract: Group Relative Policy Optimization (GRPO) is a powerful technique for aligning generative models, but its effectiveness is bottlenecked by the conflict between large group sizes and prohibitive computational costs. In this work, we investigate the trade-off through empirical studies, yielding two key observations. First, we discover the reward clustering phenomenon in which many trajectories collapse toward the group-mean reward, offering limited optimization value. Second, we design a heuristic strategy named Optimal Variance Filtering (OVF), and verify that a high-variance subset of trajectories, selected by OVF can outperform the larger, unfiltered group. However, this static, post-sampling OVF approach still necessitates critical computational overhead, as it performs unnecessary sampling for trajectories that are ultimately discarded. To resolve this, we propose Pro-GRPO (Proactive GRPO), a novel dynamic framework that integrates latent feature-based trajectory pruning into the sampling process. Through the early termination of reward-clustered trajectories, Pro-GRPO reduces computational overhead. Leveraging its efficiency, Pro-GRPO employs an "Expand-and-Prune" strategy. This strategy first expands the size of initial sampling group to maximize trajectory diversity, then it applies multi-step OVF to the latents, avoiding prohibitive computational costs. Extensive experiments on both diffusion-based and flow-based models demonstrate the generality and effectiveness of our Pro-GRPO framework.

</details>


### [46] [SemanticBridge -- A Dataset for 3D Semantic Segmentation of Bridges and Domain Gap Analysis](https://arxiv.org/abs/2512.15369)
*Maximilian Kellner,Mariana Ferrandon Cervantes,Yuandong Pan,Ruodan Lu,Ioannis Brilakis,Alexander Reiterer*

Main category: cs.CV

TL;DR: A novel dataset for 3D semantic segmentation of bridges is introduced, addressing infrastructure inspection needs. It includes diverse bridge scans with semantic labels and analyzes sensor-induced domain gaps.


<details>
  <summary>Details</summary>
Motivation: The motivation is to improve infrastructure inspection and maintenance by enabling accurate automated segmentation of bridge components.

Method: The dataset includes high-resolution 3D scans with semantic labels. Three state-of-the-art 3D deep learning models are evaluated, and domain gaps from sensor variations are analyzed.

Result: All architectures perform robustly, but sensor variations can cause up to an 11.4% mIoU performance drop.

Conclusion: This dataset and analysis advance structural health monitoring but highlight the impact of sensor-induced domain gaps.

Abstract: We propose a novel dataset that has been specifically designed for 3D semantic segmentation of bridges and the domain gap analysis caused by varying sensors. This addresses a critical need in the field of infrastructure inspection and maintenance, which is essential for modern society. The dataset comprises high-resolution 3D scans of a diverse range of bridge structures from various countries, with detailed semantic labels provided for each. Our initial objective is to facilitate accurate and automated segmentation of bridge components, thereby advancing the structural health monitoring practice. To evaluate the effectiveness of existing 3D deep learning models on this novel dataset, we conduct a comprehensive analysis of three distinct state-of-the-art architectures. Furthermore, we present data acquired through diverse sensors to quantify the domain gap resulting from sensor variations. Our findings indicate that all architectures demonstrate robust performance on the specified task. However, the domain gap can potentially lead to a decline in the performance of up to 11.4% mIoU.

</details>


### [47] [See It Before You Grab It: Deep Learning-based Action Anticipation in Basketball](https://arxiv.org/abs/2512.15386)
*Arnau Barrera Roy,Albert Clapés Sintes*

Main category: cs.CV

TL;DR: The paper introduces action anticipation in basketball videos, specifically predicting post-shot ball possession. It presents a new dataset of 100K clips and benchmarks deep learning methods for rebound prediction.


<details>
  <summary>Details</summary>
Motivation: To address the lack of attention on anticipating actions in sports videos, focusing on predicting which team gains possession after a shot in basketball.

Method: A self-curated dataset of 100,000 basketball clips (300+ hours) with 2,000 annotated rebound events is used. State-of-the-art action anticipation methods are benchmarked.

Result: Feasibility and challenges of rebound anticipation are demonstrated, with insights into predictive modeling for dynamic sports scenarios.

Conclusion: The work enables real-time broadcasting and post-game analysis tools by forecasting team possession before rebounds occur.

Abstract: Computer vision and video understanding have transformed sports analytics by enabling large-scale, automated analysis of game dynamics from broadcast footage. Despite significant advances in player and ball tracking, pose estimation, action localization, and automatic foul recognition, anticipating actions before they occur in sports videos has received comparatively little attention. This work introduces the task of action anticipation in basketball broadcast videos, focusing on predicting which team will gain possession of the ball following a shot attempt. To benchmark this task, a new self-curated dataset comprising 100,000 basketball video clips, over 300 hours of footage, and more than 2,000 manually annotated rebound events is presented. Comprehensive baseline results are reported using state-of-the-art action anticipation methods, representing the first application of deep learning techniques to basketball rebound prediction. Additionally, two complementary tasks, rebound classification and rebound spotting, are explored, demonstrating that this dataset supports a wide range of video understanding applications in basketball, for which no comparable datasets currently exist. Experimental results highlight both the feasibility and inherent challenges of anticipating rebounds, providing valuable insights into predictive modeling for dynamic multi-agent sports scenarios. By forecasting team possession before rebounds occur, this work enables applications in real-time automated broadcasting and post-game analysis tools to support decision-making.

</details>


### [48] [VTCBench: Can Vision-Language Models Understand Long Context with Vision-Text Compression?](https://arxiv.org/abs/2512.15649)
*Hongbo Zhao,Meng Wang,Fei Zhu,Wenzhuo Liu,Bolin Ni,Fanhu Zeng,Gaofeng Meng,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: The paper introduces a benchmark to evaluate vision-text compression (VTC) impact on vision-language models (VLMs) and finds that VLMs struggle with long-context understanding despite high compression ratios.


<details>
  <summary>Details</summary>
Motivation: To investigate the unexplored impact of high information density in VTC on VLMs' long-context capabilities and address scalability limitations.

Method: Introduces VTCBench, a benchmark with three tasks (VTC-Retrieval, VTC-Reasoning, VTC-Memory) and VTCBench-Wild for diverse input scenarios, evaluating leading VLMs.

Result: Most VLMs perform poorly in long-context understanding with VTC-compressed information, failing to capture associations or dependencies.

Conclusion: The study highlights VLMs' limitations with VTC and lays groundwork for designing more efficient and scalable models.

Abstract: The computational and memory overheads associated with expanding the context window of LLMs severely limit their scalability. A noteworthy solution is vision-text compression (VTC), exemplified by frameworks like DeepSeek-OCR and Glyph, which convert long texts into dense 2D visual representations, thereby achieving token compression ratios of 3x-20x. However, the impact of this high information density on the core long-context capabilities of vision-language models (VLMs) remains under-investigated. To address this gap, we introduce the first benchmark for VTC and systematically assess the performance of VLMs across three long-context understanding settings: VTC-Retrieval, which evaluates the model's ability to retrieve and aggregate information; VTC-Reasoning, which requires models to infer latent associations to locate facts with minimal lexical overlap; and VTC-Memory, which measures comprehensive question answering within long-term dialogue memory. Furthermore, we establish the VTCBench-Wild to simulate diverse input scenarios.We comprehensively evaluate leading open-source and proprietary models on our benchmarks. The results indicate that, despite being able to decode textual information (e.g., OCR) well, most VLMs exhibit a surprisingly poor long-context understanding ability with VTC-compressed information, failing to capture long associations or dependencies in the context.This study provides a deep understanding of VTC and serves as a foundation for designing more efficient and scalable VLMs.

</details>


### [49] [Preserving Marker Specificity with Lightweight Channel-Independent Representation Learning](https://arxiv.org/abs/2512.15410)
*Simon Gutwein,Arthur Longuefosse,Jun Seita,Sabine Taschner-Mandl,Roxane Licandro*

Main category: cs.CV

TL;DR: Lightweight, channel-independent models outperform traditional early-fusion CNNs in self-supervised learning for multiplexed tissue imaging, especially in rare-cell discrimination.


<details>
  <summary>Details</summary>
Motivation: Most deep learning models for multiplexed tissue imaging use early channel fusion, assuming shared structure across markers. This study explores whether preserving marker independence and using shallow architectures can provide better inductive bias for self-supervised representation learning.

Method: The study compares standard early-fusion CNNs with channel-separated architectures, including a novel shallow Channel-Independent Model (CIM-S) with 5.5K parameters, on a Hodgkin lymphoma CODEX dataset with 145,000 cells and 49 markers. Contrastive pretraining and linear evaluation are used to assess performance.

Result: Early-fusion models retain limited marker-specific information and struggle with rare-cell discrimination. Channel-independent architectures, particularly CIM-S, achieve stronger representations despite their compact size. Results are consistent across self-supervised frameworks, augmentation settings, and marker configurations (49 and 18 markers).

Conclusion: Lightweight, channel-independent architectures can match or surpass deep early-fusion CNNs and foundation models for multiplex representation learning, demonstrating the effectiveness of preserving marker independence and using shallow designs.

Abstract: Multiplexed tissue imaging measures dozens of protein markers per cell, yet most deep learning models still apply early channel fusion, assuming shared structure across markers. We investigate whether preserving marker independence, combined with deliberately shallow architectures, provides a more suitable inductive bias for self-supervised representation learning in multiplex data than increasing model scale. Using a Hodgkin lymphoma CODEX dataset with 145,000 cells and 49 markers, we compare standard early-fusion CNNs with channel-separated architectures, including a marker-aware baseline and our novel shallow Channel-Independent Model (CIM-S) with 5.5K parameters. After contrastive pretraining and linear evaluation, early-fusion models show limited ability to retain marker-specific information and struggle particularly with rare-cell discrimination. Channel-independent architectures, and CIM-S in particular, achieve substantially stronger representations despite their compact size. These findings are consistent across multiple self-supervised frameworks, remain stable across augmentation settings, and are reproducible across both the 49-marker and reduced 18-marker settings. These results show that lightweight, channel-independent architectures can match or surpass deep early-fusion CNNs and foundation models for multiplex representation learning. Code is available at https://github.com/SimonBon/CIM-S.

</details>


### [50] [Photorealistic Phantom Roads in Real Scenes: Disentangling 3D Hallucinations from Physical Geometry](https://arxiv.org/abs/2512.15423)
*Hoang Nguyen,Xiaohao Xu,Xiaonan Huang*

Main category: cs.CV

TL;DR: The paper introduces a framework to probe, quantify, and mitigate the '3D Mirage' phenomenon where monocular depth models hallucinate false 3D structures from planar inputs.


<details>
  <summary>Details</summary>
Motivation: To address a critical vulnerability in monocular depth foundation models that hallucinate false 3D structures from perceptually ambiguous planar inputs.

Method: Develops 3D-Mirage benchmark, proposes Laplacian-based metrics (DCS and CCS), and introduces Grounded Self-Distillation to enforce planarity while preserving background knowledge.

Result: Provides tools to diagnose and mitigate the 3D Mirage, advocating for a shift in evaluation metrics towards structural and contextual robustness.

Conclusion: The work lays groundwork for addressing safety risks in monocular depth estimation and fosters further research in this direction.

Abstract: Monocular depth foundation models achieve remarkable generalization by learning large-scale semantic priors, but this creates a critical vulnerability: they hallucinate illusory 3D structures from geometrically planar but perceptually ambiguous inputs. We term this failure the 3D Mirage. This paper introduces the first end-to-end framework to probe, quantify, and tame this unquantified safety risk. To probe, we present 3D-Mirage, the first benchmark of real-world illusions (e.g., street art) with precise planar-region annotations and context-restricted crops. To quantify, we propose a Laplacian-based evaluation framework with two metrics: the Deviation Composite Score (DCS) for spurious non-planarity and the Confusion Composite Score (CCS) for contextual instability. To tame this failure, we introduce Grounded Self-Distillation, a parameter-efficient strategy that surgically enforces planarity on illusion ROIs while using a frozen teacher to preserve background knowledge, thus avoiding catastrophic forgetting. Our work provides the essential tools to diagnose and mitigate this phenomenon, urging a necessary shift in MDE evaluation from pixel-wise accuracy to structural and contextual robustness. Our code and benchmark will be publicly available to foster this exciting research direction.

</details>


### [51] [Step-GUI Technical Report](https://arxiv.org/abs/2512.15431)
*Haolong Yan,Jia Wang,Xin Huang,Yeqing Shen,Ziyang Meng,Zhimin Fan,Kaijun Tan,Jin Gao,Lieyu Shi,Mi Yang,Shiliang Yang,Zhirui Wang,Brian Li,Kang An,Chenyang Li,Lei Lei,Mengmeng Duan,Danxun Liang,Guodong Liu,Hang Cheng,Hao Wu,Jie Dong,Junhao Huang,Mei Chen,Renjie Yu,Shunshan Li,Xu Zhou,Yiting Dai,Yineng Deng,Yingdan Liang,Zelin Chen,Wen Sun,Chengxu Yan,Chunqin Xu,Dong Li,Fengqiong Xiao,Guanghao Fan,Guopeng Li,Guozhen Peng,Hongbing Li,Hang Li,Hongming Chen,Jingjing Xie,Jianyong Li,Jingyang Zhang,Jiaju Ren,Jiayu Yuan,Jianpeng Yin,Kai Cao,Liang Zhao,Liguo Tan,Liying Shi,Mengqiang Ren,Min Xu,Manjiao Liu,Mao Luo,Mingxin Wan,Na Wang,Nan Wu,Ning Wang,Peiyao Ma,Qingzhou Zhang,Qiao Wang,Qinlin Zeng,Qiong Gao,Qiongyao Li,Shangwu Zhong,Shuli Gao,Shaofan Liu,Shisi Gao,Shuang Luo,Xingbin Liu,Xiaojia Liu,Xiaojie Hou,Xin Liu,Xuanti Feng,Xuedan Cai,Xuan Wen,Xianwei Zhu,Xin Liang,Xin Liu,Xin Zhou,Yingxiu Zhao,Yukang Shi,Yunfang Xu,Yuqing Zeng,Yixun Zhang,Zejia Weng,Zhonghao Yan,Zhiguo Huang,Zhuoyu Wang,Zheng Ge,Jing Li,Yibo Zhu,Binxing Jiao,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CV

TL;DR: The paper introduces a self-evolving training pipeline, Step-GUI models, and GUI-MCP protocol for efficient, high-quality GUI automation, validated by the AndroidDaily benchmark.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of acquiring high-quality training data for GUI automation while ensuring annotation reliability and cost efficiency.

Method: Proposes a Calibrated Step Reward System for training data generation, develops Step-GUI models (4B/8B), and introduces GUI-MCP for standardized, privacy-preserving interfaces.

Result: Achieves state-of-the-art performance (e.g., 8B model: 80.2% on AndroidWorld) and high annotation accuracy (>90%) at lower cost, with robust general capabilities.

Conclusion: Demonstrates practical advancements in GUI automation with potential for real-world deployment, supported by the AndroidDaily benchmark.

Abstract: Recent advances in multimodal large language models unlock unprecedented opportunities for GUI automation. However, a fundamental challenge remains: how to efficiently acquire high-quality training data while maintaining annotation reliability? We introduce a self-evolving training pipeline powered by the Calibrated Step Reward System, which converts model-generated trajectories into reliable training signals through trajectory-level calibration, achieving >90% annotation accuracy with 10-100x lower cost. Leveraging this pipeline, we introduce Step-GUI, a family of models (4B/8B) that achieves state-of-the-art GUI performance (8B: 80.2% AndroidWorld, 48.5% OSWorld, 62.6% ScreenShot-Pro) while maintaining robust general capabilities. As GUI agent capabilities improve, practical deployment demands standardized interfaces across heterogeneous devices while protecting user privacy. To this end, we propose GUI-MCP, the first Model Context Protocol for GUI automation with hierarchical architecture that combines low-level atomic operations and high-level task delegation to local specialist models, enabling high-privacy execution where sensitive data stays on-device. Finally, to assess whether agents can handle authentic everyday usage, we introduce AndroidDaily, a benchmark grounded in real-world mobile usage patterns with 3146 static actions and 235 end-to-end tasks across high-frequency daily scenarios (8B: static 89.91%, end-to-end 52.50%). Our work advances the development of practical GUI agents and demonstrates strong potential for real-world deployment in everyday digital interactions.

</details>


### [52] [CLIP-FTI: Fine-Grained Face Template Inversion via CLIP-Driven Attribute Conditioning](https://arxiv.org/abs/2512.15433)
*Longchen Dai,Zixuan Shen,Zhiheng Zhou,Peipeng Yu,Zhihua Xia*

Main category: cs.CV

TL;DR: CLIP-FTI is a novel framework leveraging CLIP and StyleGAN for fine-grained face template inversion, improving realism and transferability.


<details>
  <summary>Details</summary>
Motivation: Existing face template inversion methods produce over-smoothed images with limited transferability, posing privacy risks.

Method: Uses CLIP embeddings for facial features, fuses them with templates via a cross-modal network, and leverages StyleGAN for synthesis.

Result: Achieves higher accuracy, sharper attributes, and better transferability compared to prior methods.

Conclusion: CLIP-FTI sets a new benchmark for face template inversion, enhancing realism and security implications.

Abstract: Face recognition systems store face templates for efficient matching. Once leaked, these templates pose a threat: inverting them can yield photorealistic surrogates that compromise privacy and enable impersonation. Although existing research has achieved relatively realistic face template inversion, the reconstructed facial images exhibit over-smoothed facial-part attributes (eyes, nose, mouth) and limited transferability. To address this problem, we present CLIP-FTI, a CLIP-driven fine-grained attribute conditioning framework for face template inversion. Our core idea is to use the CLIP model to obtain the semantic embeddings of facial features, in order to realize the reconstruction of specific facial feature attributes. Specifically, facial feature attribute embeddings extracted from CLIP are fused with the leaked template via a cross-modal feature interaction network and projected into the intermediate latent space of a pretrained StyleGAN. The StyleGAN generator then synthesizes face images with the same identity as the templates but with more fine-grained facial feature attributes. Experiments across multiple face recognition backbones and datasets show that our reconstructions (i) achieve higher identification accuracy and attribute similarity, (ii) recover sharper component-level attribute semantics, and (iii) improve cross-model attack transferability compared to prior reconstruction attacks. To the best of our knowledge, ours is the first method to use additional information besides the face template attack to realize face template inversion and obtains SOTA results.

</details>


### [53] [ST-DETrack: Identity-Preserving Branch Tracking in Entangled Plant Canopies via Dual Spatiotemporal Evidence](https://arxiv.org/abs/2512.15445)
*Yueqianji Chen,Kevin Williams,John H. Doonan,Paolo Remagnino,Jo Hepworth*

Main category: cs.CV

TL;DR: ST-DETrack is a spatiotemporal-fusion network for accurate branch tracking in plants, outperforming baselines with 93.6% BMA.


<details>
  <summary>Details</summary>
Motivation: Automated branch extraction is challenging due to non-rigid growth and identity fragmentation in plant canopies.

Method: ST-DETrack combines spatial (geometric priors) and temporal (motion consistency) decoders with adaptive gating and biological constraints.

Result: Achieves 93.6% BMA, outperforming baselines by 28.9 and 3.3 percentage points.

Conclusion: The method robustly maintains branch identity in dynamic plant architectures.

Abstract: Automated extraction of individual plant branches from time-series imagery is essential for high-throughput phenotyping, yet it remains computationally challenging due to non-rigid growth dynamics and severe identity fragmentation within entangled canopies. To overcome these stage-dependent ambiguities, we propose ST-DETrack, a spatiotemporal-fusion dual-decoder network designed to preserve branch identity from budding to flowering. Our architecture integrates a spatial decoder, which leverages geometric priors such as position and angle for early-stage tracking, with a temporal decoder that exploits motion consistency to resolve late-stage occlusions. Crucially, an adaptive gating mechanism dynamically shifts reliance between these spatial and temporal cues, while a biological constraint based on negative gravitropism mitigates vertical growth ambiguities. Validated on a Brassica napus dataset, ST-DETrack achieves a Branch Matching Accuracy (BMA) of 93.6%, significantly outperforming spatial and temporal baselines by 28.9 and 3.3 percentage points, respectively. These results demonstrate the method's robustness in maintaining long-term identity consistency amidst complex, dynamic plant architectures.

</details>


### [54] [Evaluation of deep learning architectures for wildlife object detection: A comparative study of ResNet and Inception](https://arxiv.org/abs/2512.15480)
*Malach Obisa Amonga,Benard Osero,Edna Too*

Main category: cs.CV

TL;DR: The study evaluates ResNet-101 and Inception v3 for wildlife object detection, finding both effective despite some challenges with similar species and poor conditions.


<details>
  <summary>Details</summary>
Motivation: Wildlife detection aids biodiversity conservation but faces challenges like environmental variability and species similarity.

Method: Models trained on wildlife images with preprocessing (resizing, RGB conversion, tensor transformation) and a 70:30 training-validation split.

Result: ResNet-101 achieved 94% accuracy and 0.91 mAP; Inception v3 scored 95% accuracy and 0.92 mAP.

Conclusion: Both models are effective for wildlife detection, supporting conservation-focused computer vision.

Abstract: Wildlife object detection plays a vital role in biodiversity conservation, ecological monitoring, and habitat protection. However, this task is often challenged by environmental variability, visual similarities among species, and intra-class diversity. This study investigates the effectiveness of two individual deep learning architectures ResNet-101 and Inception v3 for wildlife object detection under such complex conditions. The models were trained and evaluated on a wildlife image dataset using a standardized preprocessing approach, which included resizing images to a maximum dimension of 800 pixels, converting them to RGB format, and transforming them into PyTorch tensors. A ratio of 70:30 training and validation split was used for model development. The ResNet-101 model achieved a classification accuracy of 94% and a mean Average Precision (mAP) of 0.91, showing strong performance in extracting deep hierarchical features. The Inception v3 model performed slightly better, attaining a classification accuracy of 95% and a mAP of 0.92, attributed to its efficient multi-scale feature extraction through parallel convolutions. Despite the strong results, both models exhibited challenges when detecting species with similar visual characteristics or those captured under poor lighting and occlusion. Nonetheless, the findings confirm that both ResNet-101 and Inception v3 are effective models for wildlife object detection tasks and provide a reliable foundation for conservation-focused computer vision applications.

</details>


### [55] [RUMPL: Ray-Based Transformers for Universal Multi-View 2D to 3D Human Pose Lifting](https://arxiv.org/abs/2512.15488)
*Seyed Abolfazl Ghasemzadeh,Alexandre Alahi,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: RUMPL is a transformer-based 3D pose lifter that introduces a 3D ray-based representation of 2D keypoints, enabling universal deployment across multi-view configurations without retraining. It significantly outperforms existing methods in accuracy.


<details>
  <summary>Details</summary>
Motivation: The challenge of estimating 3D human poses from 2D images is exacerbated by occlusions and projective ambiguity. Existing multi-view approaches struggle to generalize due to limited datasets.

Method: RUMPL uses a transformer-based 3D pose lifter with a 3D ray-based representation, making it camera-calibration-independent. A View Fusion Transformer aggregates information along rays for improved consistency.

Result: RUMPL reduces MPJPE by up to 53% compared to triangulation and over 60% compared to transformer-based baselines. It shows robustness on in-the-wild datasets.

Conclusion: RUMPL offers a scalable and robust solution for 3D pose estimation, outperforming existing methods and demonstrating adaptability to diverse multi-view setups.

Abstract: Estimating 3D human poses from 2D images remains challenging due to occlusions and projective ambiguity. Multi-view learning-based approaches mitigate these issues but often fail to generalize to real-world scenarios, as large-scale multi-view datasets with 3D ground truth are scarce and captured under constrained conditions. To overcome this limitation, recent methods rely on 2D pose estimation combined with 2D-to-3D pose lifting trained on synthetic data. Building on our previous MPL framework, we propose RUMPL, a transformer-based 3D pose lifter that introduces a 3D ray-based representation of 2D keypoints. This formulation makes the model independent of camera calibration and the number of views, enabling universal deployment across arbitrary multi-view configurations without retraining or fine-tuning. A new View Fusion Transformer leverages learned fused-ray tokens to aggregate information along rays, further improving multi-view consistency. Extensive experiments demonstrate that RUMPL reduces MPJPE by up to 53% compared to triangulation and over 60% compared to transformer-based image-representation baselines. Results on new benchmarks, including in-the-wild multi-view and multi-person datasets, confirm its robustness and scalability. The framework's source code is available at https://github.com/aghasemzadeh/OpenRUMPL

</details>


### [56] [The LUMirage: An independent evaluation of zero-shot performance in the LUMIR challenge](https://arxiv.org/abs/2512.15505)
*Rohit Jena,Pratik Chaudhari,James C. Gee*

Main category: cs.CV

TL;DR: The LUMIR challenge's claims about zero-shot generalization of deep learning methods in neuroimaging are re-evaluated, revealing nuanced performance variations and alignment with domain shift literature.


<details>
  <summary>Details</summary>
Motivation: To independently assess the LUMIR challenge's assertions about deep learning's zero-shot generalization on neuroimaging data, addressing potential biases and contrasting with established domain shift understanding.

Method: Rigorous evaluation protocols were applied to test deep learning methods on in-distribution and out-of-distribution neuroimaging data, including different contrasts and resolutions, while addressing instrumentation bias.

Result: Deep learning methods perform well on in-distribution T1w images and macaque data but degrade on out-of-distribution contrasts and high-resolution images, showing sensitivity to preprocessing.

Conclusion: Claims of universal zero-shot superiority for deep learning methods require scrutiny; evaluation protocols should reflect real-world clinical and research conditions.

Abstract: The LUMIR challenge represents an important benchmark for evaluating deformable image registration methods on large-scale neuroimaging data. While the challenge demonstrates that modern deep learning methods achieve competitive accuracy on T1-weighted MRI, it also claims exceptional zero-shot generalization to unseen contrasts and resolutions, assertions that contradict established understanding of domain shift in deep learning. In this paper, we perform an independent re-evaluation of these zero-shot claims using rigorous evaluation protocols while addressing potential sources of instrumentation bias. Our findings reveal a more nuanced picture: (1) deep learning methods perform comparably to iterative optimization on in-distribution T1w images and even on human-adjacent species (macaque), demonstrating improved task understanding; (2) however, performance degrades significantly on out-of-distribution contrasts (T2, T2*, FLAIR), with Cohen's d scores ranging from 0.7-1.5, indicating substantial practical impact on downstream clinical workflows; (3) deep learning methods face scalability limitations on high-resolution data, failing to run on 0.6 mm isotropic images, while iterative methods benefit from increased resolution; and (4) deep methods exhibit high sensitivity to preprocessing choices. These results align with the well-established literature on domain shift and suggest that claims of universal zero-shot superiority require careful scrutiny. We advocate for evaluation protocols that reflect practical clinical and research workflows rather than conditions that may inadvertently favor particular method classes.

</details>


### [57] [Off The Grid: Detection of Primitives for Feed-Forward 3D Gaussian Splatting](https://arxiv.org/abs/2512.15508)
*Arthur Moreau,Richard Shaw,Michal Nazarczuk,Jisu Shin,Thomas Tanay,Zhensong Zhang,Songcen Xu,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: A new feed-forward architecture improves 3D Gaussian Splatting (3DGS) by using adaptive, sub-pixel primitive placement, achieving faster and higher-quality scene generation with fewer primitives.


<details>
  <summary>Details</summary>
Motivation: Existing feed-forward 3DGS models suffer from suboptimal primitive placement due to rigid grids, limiting quality and efficiency. The goal is to enhance scene generation by dynamically distributing primitives.

Method: The proposed method replaces pixel grids with an adaptive, multi-resolution decoder for sub-pixel primitive detection, trained end-to-end with a 3D reconstruction backbone using self-supervised learning.

Result: The model generates photorealistic scenes in seconds, outperforming competitors with fewer primitives, while also improving camera pose estimation.

Conclusion: The architecture offers a more accurate and efficient 3DGS solution, with potential for label-free training of foundational models.

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) models enable real-time scene generation but are hindered by suboptimal pixel-aligned primitive placement, which relies on a dense, rigid grid and limits both quality and efficiency. We introduce a new feed-forward architecture that detects 3D Gaussian primitives at a sub-pixel level, replacing the pixel grid with an adaptive, "Off The Grid" distribution. Inspired by keypoint detection, our multi-resolution decoder learns to distribute primitives across image patches. This module is trained end-to-end with a 3D reconstruction backbone using self-supervised learning. Our resulting pose-free model generates photorealistic scenes in seconds, achieving state-of-the-art novel view synthesis for feed-forward models. It outperforms competitors while using far fewer primitives, demonstrating a more accurate and efficient allocation that captures fine details and reduces artifacts. Moreover, we observe that by learning to render 3D Gaussians, our 3D reconstruction backbone improves camera pose estimation, suggesting opportunities to train these foundational models without labels.

</details>


### [58] [VAAS: Vision-Attention Anomaly Scoring for Image Manipulation Detection in Digital Forensics](https://arxiv.org/abs/2512.15512)
*Opeyemi Bamigbade,Mark Scanlon,John Sheppard*

Main category: cs.CV

TL;DR: The paper introduces VAAS, a dual-module framework for detecting AI-generated image forgeries, combining global attention and patch-level scoring for interpretable anomaly detection.


<details>
  <summary>Details</summary>
Motivation: Traditional methods struggle with AI-generated forgeries lacking pixel anomalies, and lack measures for manipulation severity.

Method: VAAS integrates Vision Transformers (ViT) for global attention-based anomaly estimation and SegFormer for patch-level self-consistency scoring.

Result: VAAS shows competitive F1 and IoU on DF2023 and CASIA v2.0 datasets, with improved visual explainability.

Conclusion: VAAS bridges quantitative detection and human-understandable reasoning, offering reliable image integrity assessment. Source code is open.

Abstract: Recent advances in AI-driven image generation have introduced new challenges for verifying the authenticity of digital evidence in forensic investigations. Modern generative models can produce visually consistent forgeries that evade traditional detectors based on pixel or compression artefacts. Most existing approaches also lack an explicit measure of anomaly intensity, which limits their ability to quantify the severity of manipulation. This paper introduces Vision-Attention Anomaly Scoring (VAAS), a novel dual-module framework that integrates global attention-based anomaly estimation using Vision Transformers (ViT) with patch-level self-consistency scoring derived from SegFormer embeddings. The hybrid formulation provides a continuous and interpretable anomaly score that reflects both the location and degree of manipulation. Evaluations on the DF2023 and CASIA v2.0 datasets demonstrate that VAAS achieves competitive F1 and IoU performance, while enhancing visual explainability through attention-guided anomaly maps. The framework bridges quantitative detection with human-understandable reasoning, supporting transparent and reliable image integrity assessment. The source code for all experiments and corresponding materials for reproducing the results are available open source.

</details>


### [59] [DeX-Portrait: Disentangled and Expressive Portrait Animation via Explicit and Latent Motion Representations](https://arxiv.org/abs/2512.15524)
*Yuxiang Shi,Zhe Li,Yanwen Wang,Hao Zhu,Xun Cao,Ligang Liu*

Main category: cs.CV

TL;DR: DeX-Portrait introduces a novel method for portrait animation using disentangled pose and expression signals, outperforming existing baselines in quality and control.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion models fail to achieve high-fidelity disentangled control between head pose and facial expression, limiting applications like expression-only or pose-only editing.

Method: The approach uses a motion trainer for pose and expression encoders, injects pose via dual-branch conditioning, and leverages cross-attention for expression. It also employs a progressive hybrid classifier-free guidance for identity consistency.

Result: Experiments demonstrate superior animation quality and disentangled controllability compared to state-of-the-art baselines.

Conclusion: DeX-Portrait effectively addresses the disentanglement challenge, enabling more flexible and high-quality portrait animation.

Abstract: Portrait animation from a single source image and a driving video is a long-standing problem. Recent approaches tend to adopt diffusion-based image/video generation models for realistic and expressive animation. However, none of these diffusion models realizes high-fidelity disentangled control between the head pose and facial expression, hindering applications like expression-only or pose-only editing and animation. To address this, we propose DeX-Portrait, a novel approach capable of generating expressive portrait animation driven by disentangled pose and expression signals. Specifically, we represent the pose as an explicit global transformation and the expression as an implicit latent code. First, we design a powerful motion trainer to learn both pose and expression encoders for extracting precise and decomposed driving signals. Then we propose to inject the pose transformation into the diffusion model through a dual-branch conditioning mechanism, and the expression latent through cross attention. Finally, we design a progressive hybrid classifier-free guidance for more faithful identity consistency. Experiments show that our method outperforms state-of-the-art baselines on both animation quality and disentangled controllability.

</details>


### [60] [EmoCaliber: Advancing Reliable Visual Emotion Comprehension via Confidence Verbalization and Calibration](https://arxiv.org/abs/2512.15528)
*Daiqing Wu,Dongbao Yang,Can Ma. Yu Zhou*

Main category: cs.CV

TL;DR: The paper introduces EmoCaliber, a confidence-aware MLLM for Visual Emotion Comprehension (VEC), addressing the subjectivity of emotion perception by verbalizing confidence in predictions.


<details>
  <summary>Details</summary>
Motivation: Current VEC paradigms treat emotion prediction deterministically, ignoring subjectivity and alternative interpretations. The paper aims to enhance reliability by incorporating confidence estimation.

Method: A three-stage training framework equips MLLMs with structured reasoning, confidence verbalization, and calibration, resulting in EmoCaliber.

Result: EmoCaliber outperforms existing methods in emotion prediction and confidence estimation on VECBench.

Conclusion: The approach improves VEC reliability and marks progress toward more dependable emotion comprehension systems.

Abstract: Visual Emotion Comprehension (VEC) aims to infer sentiment polarities or emotion categories from affective cues embedded in images. In recent years, Multimodal Large Language Models (MLLMs) have established a popular paradigm in VEC, leveraging their generalizability to unify VEC tasks defined under diverse emotion taxonomies. While this paradigm achieves notable success, it typically formulates VEC as a deterministic task, requiring the model to output a single, definitive emotion label for each image. Such a formulation insufficiently accounts for the inherent subjectivity of emotion perception, overlooking alternative interpretations that may be equally plausible to different viewers. To address this limitation, we propose equipping MLLMs with capabilities to verbalize their confidence in emotion predictions. This additional signal provides users with an estimate of both the plausibility of alternative interpretations and the MLLMs' self-assessed competence, thereby enhancing reliability in practice. Building on this insight, we introduce a three-stage training framework that progressively endows with structured reasoning, teaches to verbalize confidence, and calibrates confidence expression, culminating in EmoCaliber, a confidence-aware MLLM for VEC. Through fair and comprehensive evaluations on the unified benchmark VECBench, EmoCaliber demonstrates overall superiority against existing methods in both emotion prediction and confidence estimation. These results validate the effectiveness of our approach and mark a feasible step toward more reliable VEC systems. Project page: https://github.com/wdqqdw/EmoCaliber.

</details>


### [61] [An Efficient and Effective Encoder Model for Vision and Language Tasks in the Remote Sensing Domain](https://arxiv.org/abs/2512.15531)
*João Daniel Silva,Joao Magalhaes,Devis Tuia,Bruno Martins*

Main category: cs.CV

TL;DR: The paper proposes GeoMELT, a compact encoder-only model for multi-task learning in remote sensing, addressing text generation and cross-modal retrieval efficiently.


<details>
  <summary>Details</summary>
Motivation: High computational costs of Large Vision and Language Models (LVLMs) limit their accessibility, prompting a need for efficient alternatives.

Method: The study explores encoder-only architectures to create a parameter-efficient model (GeoMELT) for multi-task learning.

Result: GeoMELT performs effectively in benchmarks for text generation and cross-modal retrieval tasks.

Conclusion: GeoMELT offers an efficient and effective solution for multi-task learning in remote sensing, reducing computational costs.

Abstract: The remote sensing community has recently seen the emergence of methods based on Large Vision and Language Models (LVLMs) that can address multiple tasks at the intersection of computer vision and natural language processing. To fully exploit the potential of such models, a significant focus has been given to the collection of large amounts of training data that cover multiple remote sensing-specific tasks, such as image captioning or visual question answering. However, the cost of using and training LVLMs is high, due to the large number of parameters. While multiple parameter-efficient adaptation techniques have been explored, the computational costs of training and inference with these models can remain prohibitive for most institutions. In this work, we explore the use of encoder-only architectures and propose a model that can effectively address multi-task learning while remaining compact in terms of the number of parameters. In particular, our model tackles combinations of tasks that are not typically explored in a unified model: the generation of text from remote sensing images and cross-modal retrieval. The results of our GeoMELT model - named from Multi-task Efficient Learning Transformer - in established benchmarks confirm the efficacy and efficiency of the proposed approach.

</details>


### [62] [BLANKET: Anonymizing Faces in Infant Video Recordings](https://arxiv.org/abs/2512.15542)
*Ditmar Hadera,Jan Cech,Miroslav Purkrabek,Matej Hoffmann*

Main category: cs.CV

TL;DR: BLANKET is a novel anonymization method for infant faces in videos, outperforming DeepPrivacy2 by preserving facial attributes and ensuring temporal consistency, with an available demo.


<details>
  <summary>Details</summary>
Motivation: To ethically anonymize infant faces in videos while maintaining essential facial features and temporal consistency.

Method: BLANKET uses a diffusion model for inpainting a new face and temporally consistent face swapping with expression transfer.

Result: BLANKET outperforms DeepPrivacy2 in de-identification, attribute preservation, pose estimation impact, and artifact reduction.

Conclusion: BLANKET is effective for infant face anonymization in videos, offering better performance and usability.

Abstract: Ensuring the ethical use of video data involving human subjects, particularly infants, requires robust anonymization methods. We propose BLANKET (Baby-face Landmark-preserving ANonymization with Keypoint dEtection consisTency), a novel approach designed to anonymize infant faces in video recordings while preserving essential facial attributes. Our method comprises two stages. First, a new random face, compatible with the original identity, is generated via inpainting using a diffusion model. Second, the new identity is seamlessly incorporated into each video frame through temporally consistent face swapping with authentic expression transfer. The method is evaluated on a dataset of short video recordings of babies and is compared to the popular anonymization method, DeepPrivacy2. Key metrics assessed include the level of de-identification, preservation of facial attributes, impact on human pose estimation (as an example of a downstream task), and presence of artifacts. Both methods alter the identity, and our method outperforms DeepPrivacy2 in all other respects. The code is available as an easy-to-use anonymization demo at https://github.com/ctu-vras/blanket-infant-face-anonym.

</details>


### [63] [GRAN-TED: Generating Robust, Aligned, and Nuanced Text Embedding for Diffusion Models](https://arxiv.org/abs/2512.15560)
*Bozhou Li,Sihan Yang,Yushuo Guan,Ruichuan An,Xinlong Chen,Yang Shi,Pengfei Wan,Wentao Zhang,Yuanxing zhang*

Main category: cs.CV

TL;DR: GRAN-TED introduces a new paradigm for generating high-quality text embeddings for diffusion models, addressing challenges in evaluation and adaptation of pretrained language models.


<details>
  <summary>Details</summary>
Motivation: To overcome the lack of efficient evaluation frameworks and difficulties in adapting pretrained language models for visual synthesis tasks.

Method: Proposes TED-6K benchmark for encoder evaluation and a two-stage training paradigm involving fine-tuning and layer-wise weighting for better text features.

Result: GRAN-TED achieves state-of-the-art performance on TED-6K and improves text-to-image and text-to-video generation.

Conclusion: GRAN-TED provides a robust and efficient solution for enhancing text encoders in diffusion models.

Abstract: The text encoder is a critical component of text-to-image and text-to-video diffusion models, fundamentally determining the semantic fidelity of the generated content. However, its development has been hindered by two major challenges: the lack of an efficient evaluation framework that reliably predicts downstream generation performance, and the difficulty of effectively adapting pretrained language models for visual synthesis. To address these issues, we introduce GRAN-TED, a paradigm to Generate Robust, Aligned, and Nuanced Text Embeddings for Diffusion models. Our contribution is twofold. First, we propose TED-6K, a novel text-only benchmark that enables efficient and robust assessment of an encoder's representational quality without requiring costly end-to-end model training. We demonstrate that performance on TED-6K, standardized via a lightweight, unified adapter, strongly correlates with an encoder's effectiveness in downstream generation tasks. Second, guided by this validated framework, we develop a superior text encoder using a novel two-stage training paradigm. This process involves an initial fine-tuning stage on a Multimodal Large Language Model for better visual representation, followed by a layer-wise weighting method to extract more nuanced and potent text features. Our experiments show that the resulting GRAN-TED encoder not only achieves state-of-the-art performance on TED-6K but also leads to demonstrable performance gains in text-to-image and text-to-video generation. Our code is available at the following link: https://anonymous.4open.science/r/GRAN-TED-4FCC/.

</details>


### [64] [On the Effectiveness of Textual Prompting with Lightweight Fine-Tuning for SAM3 Remote Sensing Segmentation](https://arxiv.org/abs/2512.15564)
*Roni Blushtein-Livnon,Osher Rafaeli,David Ioffe,Amir Boger,Karen Sandberg Esquenazi,Tal Svoray*

Main category: cs.CV

TL;DR: The paper explores adapting SAM3, a concept-driven framework, for remote sensing image segmentation under limited supervision, comparing textual, geometric, and hybrid prompting strategies.


<details>
  <summary>Details</summary>
Motivation: Remote sensing image segmentation faces challenges due to limited annotated data and differences between overhead imagery and natural images used to train foundational models. This motivates the need for effective adaptation under limited supervision.

Method: The study evaluates SAM3's performance using textual, geometric, and hybrid prompting strategies for RS imagery. It includes lightweight fine-tuning with increasing supervision levels and zero-shot inference.

Result: Combining semantic and geometric cues yields the best performance. Text-only prompting performs poorly, especially for irregular targets. Light fine-tuning with textual prompts works well for regular and visually salient targets. Performance improves with increasing supervision but shows diminishing returns.

Conclusion: A modest geometric annotation effort suffices for effective adaptation. Boundary inaccuracies and under-segmentation remain common errors, particularly for irregular or less prevalent targets.

Abstract: Remote sensing (RS) image segmentation is constrained by the limited availability of annotated data and a gap between overhead imagery and natural images used to train foundational models. This motivates effective adaptation under limited supervision. SAM3 concept-driven framework generates masks from textual prompts without requiring task-specific modifications, which may enable this adaptation. We evaluate SAM3 for RS imagery across four target types, comparing textual, geometric, and hybrid prompting strategies, under lightweight fine-tuning scales with increasing supervision, alongside zero-shot inference. Results show that combining semantic and geometric cues yields the highest performance across targets and metrics. Text-only prompting exhibits the lowest performance, with marked score gaps for irregularly shaped targets, reflecting limited semantic alignment between SAM3 textual representations and their overhead appearances. Nevertheless, textual prompting with light fine-tuning offers a practical performance-effort trade-off for geometrically regular and visually salient targets. Across targets, performance improves between zero-shot inference and fine-tuning, followed by diminishing returns as the supervision scale increases. Namely, a modest geometric annotation effort is sufficient for effective adaptation. A persistent gap between Precision and IoU further indicates that under-segmentation and boundary inaccuracies remain prevalent error patterns in RS tasks, particularly for irregular and less prevalent targets.

</details>


### [65] [MoonSeg3R: Monocular Online Zero-Shot Segment Anything in 3D with Reconstructive Foundation Priors](https://arxiv.org/abs/2512.15577)
*Zhipeng Du,Duolikun Danier,Jan Eric Lenssen,Hakan Bilen*

Main category: cs.CV

TL;DR: MoonSeg3R enables online monocular 3D instance segmentation using CUT3R for geometric priors, with key innovations in query refinement, temporal consistency, and cross-frame fusion, achieving competitive performance with RGB-D-based systems.


<details>
  <summary>Details</summary>
Motivation: Existing methods fail in online zero-shot monocular 3D instance segmentation as they rely on posed RGB-D sequences. MoonSeg3R addresses this by leveraging CUT3R for geometric priors from a single RGB stream.

Method: Proposes MoonSeg3R with: (1) self-supervised query refinement using spatial-semantic distillation, (2) a 3D query index memory for temporal consistency, and (3) a state-distribution token from CUT3R for cross-frame fusion.

Result: Achieves competitive performance with RGB-D-based systems on ScanNet200 and SceneNN, becoming the first method for online monocular 3D segmentation.

Conclusion: MoonSeg3R successfully addresses the limitations of existing approaches and demonstrates competitive performance, enabling practical online monocular 3D segmentation.

Abstract: In this paper, we focus on online zero-shot monocular 3D instance segmentation, a novel practical setting where existing approaches fail to perform because they rely on posed RGB-D sequences. To overcome this limitation, we leverage CUT3R, a recent Reconstructive Foundation Model (RFM), to provide reliable geometric priors from a single RGB stream. We propose MoonSeg3R, which introduces three key components: (1) a self-supervised query refinement module with spatial-semantic distillation that transforms segmentation masks from 2D visual foundation models (VFMs) into discriminative 3D queries; (2) a 3D query index memory that provides temporal consistency by retrieving contextual queries; and (3) a state-distribution token from CUT3R that acts as a mask identity descriptor to strengthen cross-frame fusion. Experiments on ScanNet200 and SceneNN show that MoonSeg3R is the first method to enable online monocular 3D segmentation and achieves performance competitive with state-of-the-art RGB-D-based systems. Code and models will be released.

</details>


### [66] [IMKD: Intensity-Aware Multi-Level Knowledge Distillation for Camera-Radar Fusion](https://arxiv.org/abs/2512.15581)
*Shashank Mishra,Karan Patil,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: IMKD, a radar-camera fusion framework, uses multi-level knowledge distillation to enhance 3D object detection while preserving each sensor's unique strengths, achieving state-of-the-art results on the nuScenes benchmark.


<details>
  <summary>Details</summary>
Motivation: Existing distillation methods in radar-camera fusion often distort sensor-specific features, weakening their individual strengths. IMKD aims to address this by preserving intrinsic characteristics while improving complementary strengths.

Method: IMKD employs a three-stage, intensity-aware distillation strategy: (1) LiDAR-to-Radar feature distillation, (2) LiDAR-to-Fused feature distillation, and (3) Camera-Radar intensity-guided fusion, ensuring effective feature alignment and complementarity.

Result: IMKD achieves 67.0% NDS and 61.0% mAP on the nuScenes benchmark, surpassing all previous distillation-based radar-camera fusion methods.

Conclusion: IMKD successfully enhances radar-camera fusion for 3D object detection by leveraging multi-level knowledge distillation, outperforming existing methods while preserving sensor-specific features.

Abstract: High-performance Radar-Camera 3D object detection can be achieved by leveraging knowledge distillation without using LiDAR at inference time. However, existing distillation methods typically transfer modality-specific features directly to each sensor, which can distort their unique characteristics and degrade their individual strengths. To address this, we introduce IMKD, a radar-camera fusion framework based on multi-level knowledge distillation that preserves each sensor's intrinsic characteristics while amplifying their complementary strengths. IMKD applies a three-stage, intensity-aware distillation strategy to enrich the fused representation across the architecture: (1) LiDAR-to-Radar intensity-aware feature distillation to enhance radar representations with fine-grained structural cues, (2) LiDAR-to-Fused feature intensity-guided distillation to selectively highlight useful geometry and depth information at the fusion level, fostering complementarity between the modalities rather than forcing them to align, and (3) Camera-Radar intensity-guided fusion mechanism that facilitates effective feature alignment and calibration. Extensive experiments on the nuScenes benchmark show that IMKD reaches 67.0% NDS and 61.0% mAP, outperforming all prior distillation-based radar-camera fusion methods. Our code and models are available at https://github.com/dfki-av/IMKD/.

</details>


### [67] [FlexAvatar: Learning Complete 3D Head Avatars with Partial Supervision](https://arxiv.org/abs/2512.15599)
*Tobias Kirschstein,Simon Giebenhain,Matthias Nießner*

Main category: cs.CV

TL;DR: FlexAvatar introduces a method for creating high-quality 3D head avatars from a single image, addressing challenges like incomplete reconstructions by leveraging monocular and multi-view data with a transformer-based model.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations of existing methods in generating complete 3D head avatars from monocular data, which often result in incomplete reconstructions due to the entanglement of driving signals and viewpoints.

Method: The proposed method uses a transformer-based 3D portrait animation model with learnable data source tokens (bias sinks) for unified training across monocular and multi-view datasets, combining their strengths.

Result: FlexAvatar produces complete 3D head avatars with realistic facial animations, outperforming existing methods in tasks like single-view, few-shot, and monocular avatar creation.

Conclusion: FlexAvatar effectively addresses the challenges of incomplete 3D reconstructions by leveraging both monocular and multi-view data, resulting in high-quality avatars with realistic animations.

Abstract: We introduce FlexAvatar, a method for creating high-quality and complete 3D head avatars from a single image. A core challenge lies in the limited availability of multi-view data and the tendency of monocular training to yield incomplete 3D head reconstructions. We identify the root cause of this issue as the entanglement between driving signal and target viewpoint when learning from monocular videos. To address this, we propose a transformer-based 3D portrait animation model with learnable data source tokens, so-called bias sinks, which enables unified training across monocular and multi-view datasets. This design leverages the strengths of both data sources during inference: strong generalization from monocular data and full 3D completeness from multi-view supervision. Furthermore, our training procedure yields a smooth latent avatar space that facilitates identity interpolation and flexible fitting to an arbitrary number of input observations. In extensive evaluations on single-view, few-shot, and monocular avatar creation tasks, we verify the efficacy of FlexAvatar. Many existing methods struggle with view extrapolation while FlexAvatar generates complete 3D head avatars with realistic facial animations. Website: https://tobias-kirschstein.github.io/flexavatar/

</details>


### [68] [Qwen-Image-Layered: Towards Inherent Editability via Layer Decomposition](https://arxiv.org/abs/2512.15603)
*Shengming Yin,Zekai Zhang,Zecheng Tang,Kaiyuan Gao,Xiao Xu,Kun Yan,Jiahao Li,Yilei Chen,Yuxiang Chen,Heung-Yeung Shum,Lionel M. Ni,Jingren Zhou,Junyang Lin,Chenfei Wu*

Main category: cs.CV

TL;DR: Qwen-Image-Layered is a diffusion model that decomposes RGB images into editable RGBA layers, enabling isolated edits and consistent image editing.


<details>
  <summary>Details</summary>
Motivation: Current generative models struggle with consistency in edits due to raster images' fused nature. Layered representations in design tools inspire disentangled RGBA layers for better editability.

Method: Uses RGBA-VAE, VLD-MMDiT architecture, and Multi-stage Training to decompose images into variable layers. A pipeline extracts multilayer training data from PSD files.

Result: Outperforms existing methods in decomposition quality, enabling consistent image editing.

Conclusion: Qwen-Image-Layered sets a new standard for editable image decomposition, with released code and models.

Abstract: Recent visual generative models often struggle with consistency during image editing due to the entangled nature of raster images, where all visual content is fused into a single canvas. In contrast, professional design tools employ layered representations, allowing isolated edits while preserving consistency. Motivated by this, we propose \textbf{Qwen-Image-Layered}, an end-to-end diffusion model that decomposes a single RGB image into multiple semantically disentangled RGBA layers, enabling \textbf{inherent editability}, where each RGBA layer can be independently manipulated without affecting other content. To support variable-length decomposition, we introduce three key components: (1) an RGBA-VAE to unify the latent representations of RGB and RGBA images; (2) a VLD-MMDiT (Variable Layers Decomposition MMDiT) architecture capable of decomposing a variable number of image layers; and (3) a Multi-stage Training strategy to adapt a pretrained image generation model into a multilayer image decomposer. Furthermore, to address the scarcity of high-quality multilayer training images, we build a pipeline to extract and annotate multilayer images from Photoshop documents (PSD). Experiments demonstrate that our method significantly surpasses existing approaches in decomposition quality and establishes a new paradigm for consistent image editing. Our code and models are released on \href{https://github.com/QwenLM/Qwen-Image-Layered}{https://github.com/QwenLM/Qwen-Image-Layered}

</details>


### [69] [Robust Multi-view Camera Calibration from Dense Matches](https://arxiv.org/abs/2512.15608)
*Johannes Hägerlind,Bao-Long Tran,Urs Waldmann,Per-Erik Forssén*

Main category: cs.CV

TL;DR: The paper introduces a robust method for camera pose estimation and calibration, focusing on improving accuracy in structure-from-motion pipelines for specific applications like animal behavior studies and forensic analysis.


<details>
  <summary>Details</summary>
Motivation: Addressing challenges in camera intrinsics and extrinsics estimation, particularly for setups with rigid cameras observing scenes from different perspectives, common in animal behavior and forensic analysis.

Method: Analyzes SfM pipeline components, proposing improved subsampling of correspondences and incremental view addition criteria. Evaluates changes quantitatively, including handling cameras with strong radial distortion.

Result: Demonstrates significant improvements (79.9% accuracy vs. 40.4% baseline) and generalizability across diverse camera setups, validated in a global SfM setting.

Conclusion: The proposed pipeline enhances accuracy and robustness in pose estimation, making it a promising tool for specialized applications like animal behavior and forensic analysis.

Abstract: Estimating camera intrinsics and extrinsics is a fundamental problem in computer vision, and while advances in structure-from-motion (SfM) have improved accuracy and robustness, open challenges remain. In this paper, we introduce a robust method for pose estimation and calibration. We consider a set of rigid cameras, each observing the scene from a different perspective, which is a typical camera setup in animal behavior studies and forensic analysis of surveillance footage. Specifically, we analyse the individual components in a structure-from-motion (SfM) pipeline, and identify design choices that improve accuracy. Our main contributions are: (1) we investigate how to best subsample the predicted correspondences from a dense matcher to leverage them in the estimation process. (2) We investigate selection criteria for how to add the views incrementally. In a rigorous quantitative evaluation, we show the effectiveness of our changes, especially for cameras with strong radial distortion (79.9% ours vs. 40.4 vanilla VGGT). Finally, we demonstrate our correspondence subsampling in a global SfM setting where we initialize the poses using VGGT. The proposed pipeline generalizes across a wide range of camera setups, and could thus become a useful tool for animal behavior and forensic analysis.

</details>


### [70] [Persistent feature reconstruction of resident space objects (RSOs) within inverse synthetic aperture radar (ISAR) images](https://arxiv.org/abs/2512.15618)
*Morgan Coe,Gruffudd Jones,Leah-Nani Alconcel,Marina Gashinova*

Main category: cs.CV

TL;DR: The paper proposes using sub-THz ISAR imaging for Space Domain Awareness, focusing on detecting and tracking linear features in satellite images to improve recognition of external structures.


<details>
  <summary>Details</summary>
Motivation: With the increasing population of resident space objects (RSOs), detailed information about their condition and capabilities is needed for Space Domain Awareness (SDA). Space-based sensing can provide this by inspecting RSOs at shorter ranges without atmospheric interference.

Method: The paper uses a sub-THz ISAR imaging system and employs the Hough transform to detect and track linear features in sequences of aligned ISAR images. A metaheuristic simulator generates ISAR imagery, and edge detection is performed using a gradient-by-ratio method.

Result: The proposed approach increases confidence in feature detection and classification by analyzing feature evolution across image sequences. An example demonstrates robust detection of shadowing as a feature.

Conclusion: The method enhances Space Domain Awareness by improving the accuracy and reliability of feature detection and tracking in satellite imagery.

Abstract: With the rapidly growing population of resident space objects (RSOs) in the near-Earth space environment, detailed information about their condition and capabilities is needed to provide Space Domain Awareness (SDA). Space-based sensing will enable inspection of RSOs at shorter ranges, independent of atmospheric effects, and from all aspects. The use of a sub-THz inverse synthetic aperture radar (ISAR) imaging and sensing system for SDA has been proposed in previous work, demonstrating the achievement of sub-cm image resolution at ranges of up to 100 km. This work focuses on recognition of external structures by use of sequential feature detection and tracking throughout the aligned ISAR images of the satellites. The Hough transform is employed to detect linear features, which are tracked throughout the sequence. ISAR imagery is generated via a metaheuristic simulator capable of modelling encounters for a variety of deployment scenarios. Initial frame-to-frame alignment is achieved through a series of affine transformations to facilitate later association between image features. A gradient-by-ratio method is used for edge detection within individual ISAR images, and edge magnitude and direction are subsequently used to inform a double-weighted Hough transform to detect features with high accuracy. Feature evolution during sequences of frames is analysed. It is shown that the use of feature tracking within sequences with the proposed approach will increase confidence in feature detection and classification, and an example use-case of robust detection of shadowing as a feature is presented.

</details>


### [71] [OccSTeP: Benchmarking 4D Occupancy Spatio-Temporal Persistence](https://arxiv.org/abs/2512.15621)
*Yu Zheng,Jie Hu,Kailun Yang,Jiaming Zhang*

Main category: cs.CV

TL;DR: The paper introduces a new concept called 4D Occupancy Spatio-Temporal Persistence (OccSTeP) for autonomous driving, addressing reactive and proactive forecasting tasks. It proposes OccSTeP-WM, a tokenizer-free world model, and benchmarks its performance in challenging scenarios.


<details>
  <summary>Details</summary>
Motivation: To enhance autonomous driving by providing a robust understanding of 3D scenes that accounts for temporal disturbances and future actions, addressing gaps in existing methods.

Method: The paper proposes OccSTeP-WM, a dense voxel-based scene state model with linear-complexity attention and a recurrent state-space module for spatio-temporal context fusion.

Result: OccSTeP-WM achieves a semantic mIoU of 23.70% (+6.56% improvement) and occupancy IoU of 35.89% (+9.26% improvement) on the new benchmark.

Conclusion: The OccSTeP concept and OccSTeP-WM model are effective for robust scene understanding in autonomous driving, even with missing or noisy sensor data, and the work is made open-source.

Abstract: Autonomous driving requires a persistent understanding of 3D scenes that is robust to temporal disturbances and accounts for potential future actions. We introduce a new concept of 4D Occupancy Spatio-Temporal Persistence (OccSTeP), which aims to address two tasks: (1) reactive forecasting: ''what will happen next'' and (2) proactive forecasting: "what would happen given a specific future action". For the first time, we create a new OccSTeP benchmark with challenging scenarios (e.g., erroneous semantic labels and dropped frames). To address this task, we propose OccSTeP-WM, a tokenizer-free world model that maintains a dense voxel-based scene state and incrementally fuses spatio-temporal context over time. OccSTeP-WM leverages a linear-complexity attention backbone and a recurrent state-space module to capture long-range spatial dependencies while continually updating the scene memory with ego-motion compensation. This design enables online inference and robust performance even when historical sensor input is missing or noisy. Extensive experiments prove the effectiveness of the OccSTeP concept and our OccSTeP-WM, yielding an average semantic mIoU of 23.70% (+6.56% gain) and occupancy IoU of 35.89% (+9.26% gain). The data and code will be open source at https://github.com/FaterYU/OccSTeP.

</details>


### [72] [Towards Physically-Based Sky-Modeling For Image Based Lighting](https://arxiv.org/abs/2512.15632)
*Ian J. Maquignaz*

Main category: cs.CV

TL;DR: AllSky is a new sky-model trained on real HDR imagery, improving photorealism and dynamic range for outdoor illumination compared to existing DNN-based methods.


<details>
  <summary>Details</summary>
Motivation: Existing sky-models fail to replicate natural skies accurately, lacking photorealism and full dynamic range for outdoor scenes.

Method: AllSky learns directly from physically captured HDRI, with user control over sun and cloud positions, and evaluates input modalities, tonemapping, and conditioning.

Result: AllSky outperforms current DNN sky-models, offering better photorealism and dynamic range.

Conclusion: Current DNN sky-models fall short compared to physically captured HDRI; AllSky bridges this gap with enhanced functionality and accuracy.

Abstract: Accurate environment maps are a key component for rendering photorealistic outdoor scenes with coherent illumination. They enable captivating visual arts, immersive virtual reality, and a wide range of engineering and scientific applications. Recent works have extended sky-models to be more comprehensive and inclusive of cloud formations but, as we demonstrate, existing methods fall short in faithfully recreating natural skies. Though in recent years the visual quality of DNN-generated High Dynamic Range Imagery (HDRI) has greatly improved, the environment maps generated by DNN sky-models do not re-light scenes with the same tones, shadows, and illumination as physically captured HDR imagery. In this work, we demonstrate progress in HDR literature to be tangential to sky-modelling as current works cannot support both photorealism and the 22 f-stops required for the Full Dynamic Range (FDR) of outdoor illumination. We achieve this by proposing AllSky, a flexible all-weather sky-model learned directly from physically captured HDRI which we leverage to study the input modalities, tonemapping, conditioning, and evaluation of sky-models. Per user-controlled positioning of the sun and cloud formations, AllSky expands on current functionality by allowing for intuitive user control over environment maps and achieves state-of-the-art sky-model performance. Through our proposed evaluation, we demonstrate existing DNN sky-models are not interchangeable with physically captured HDRI or parametric sky-models, with current limitations being prohibitive of scalability and accurate illumination in downstream applications

</details>


### [73] [IC-Effect: Precise and Efficient Video Effects Editing via In-Context Learning](https://arxiv.org/abs/2512.15635)
*Yuanhang Li,Yiren Song,Junzhe Bai,Xinran Liang,Hu Yang,Libiao Jin,Qi Mao*

Main category: cs.CV

TL;DR: IC-Effect is a DiT-based framework for few-shot video VFX editing, ensuring spatial and temporal consistency while efficiently learning effects from limited data.


<details>
  <summary>Details</summary>
Motivation: Video VFX editing is challenging due to the need for seamless effect blending, unchanged backgrounds, and learning from limited data, which existing models fail to address.

Method: IC-Effect uses a DiT model with contextual learning, a two-stage training strategy (general editing adaptation and Effect-LoRA), and spatiotemporal sparse tokenization for efficiency.

Result: IC-Effect achieves high-quality, controllable, and temporally consistent VFX editing, validated by extensive experiments.

Conclusion: The framework opens new possibilities for video creation by addressing the challenges in video VFX editing.

Abstract: We propose \textbf{IC-Effect}, an instruction-guided, DiT-based framework for few-shot video VFX editing that synthesizes complex effects (\eg flames, particles and cartoon characters) while strictly preserving spatial and temporal consistency. Video VFX editing is highly challenging because injected effects must blend seamlessly with the background, the background must remain entirely unchanged, and effect patterns must be learned efficiently from limited paired data. However, existing video editing models fail to satisfy these requirements. IC-Effect leverages the source video as clean contextual conditions, exploiting the contextual learning capability of DiT models to achieve precise background preservation and natural effect injection. A two-stage training strategy, consisting of general editing adaptation followed by effect-specific learning via Effect-LoRA, ensures strong instruction following and robust effect modeling. To further improve efficiency, we introduce spatiotemporal sparse tokenization, enabling high fidelity with substantially reduced computation. We also release a paired VFX editing dataset spanning $15$ high-quality visual styles. Extensive experiments show that IC-Effect delivers high-quality, controllable, and temporally consistent VFX editing, opening new possibilities for video creation.

</details>


### [74] [InpaintDPO: Mitigating Spatial Relationship Hallucinations in Foreground-conditioned Inpainting via Diverse Preference Optimization](https://arxiv.org/abs/2512.15644)
*Qirui Li,Yizhe Tang,Ran Yi,Guangben Lu,Fangyuan Zou,Peng Shu,Huan Yu,Jie Jiang*

Main category: cs.CV

TL;DR: InpaintDPO addresses spatial hallucinations in foreground-conditioned inpainting by introducing DPO-based optimizations for plausible foreground-background relationships.


<details>
  <summary>Details</summary>
Motivation: Current methods struggle with spatial rationality in foreground-conditioned inpainting, lacking quantifiable metrics for RLHF.

Method: Proposes InpaintDPO with MaskDPO for background optimization, Conditional Asymmetric Preference Optimization for boundary coherence, and Shared Commonality Preference Optimization for spatial rationality.

Result: Ensures plausible spatial relationships and robust foreground preservation while enhancing boundary coherence.

Conclusion: InpaintDPO effectively improves spatial rationality in foreground-conditioned inpainting through tailored DPO-based optimizations.

Abstract: Foreground-conditioned inpainting, which aims at generating a harmonious background for a given foreground subject based on the text prompt, is an important subfield in controllable image generation. A common challenge in current methods, however, is the occurrence of Spatial Relationship Hallucinations between the foreground subject and the generated background, including inappropriate scale, positional relationships, and viewpoints. Critically, the subjective nature of spatial rationality makes it challenging to quantify, hindering the use of traditional reward-based RLHF methods. To address this issue, we propose InpaintDPO, the first Direct Preference Optimization (DPO) based framework dedicated to spatial rationality in foreground-conditioned inpainting, ensuring plausible spatial relationships between foreground and background elements. To resolve the gradient conflicts in standard DPO caused by identical foreground in win-lose pairs, we propose MaskDPO, which confines preference optimization exclusively to the background to enhance background spatial relationships, while retaining the inpainting loss in the foreground region for robust foreground preservation. To enhance coherence at the foreground-background boundary, we propose Conditional Asymmetric Preference Optimization, which samples pairs with differentiated cropping operations and applies global preference optimization to promote contextual awareness and enhance boundary coherence. Finally, based on the observation that winning samples share a commonality in plausible spatial relationships, we propose Shared Commonality Preference Optimization to enhance the model's understanding of spatial commonality across high-quality winning samples, further promoting shared spatial rationality.

</details>


### [75] [Hard Labels In! Rethinking the Role of Hard Labels in Mitigating Local Semantic Drift](https://arxiv.org/abs/2512.15647)
*Jiacheng Cui,Bingkui Tong,Xinyue Bi,Xiaohan Zhao,Jiacheng Liu,Zhiqiang shen*

Main category: cs.CV

TL;DR: The paper addresses the issue of local semantic drift in soft labels when few crops per image are used, proposing a hybrid approach (HALD) combining soft and hard labels to improve generalization.


<details>
  <summary>Details</summary>
Motivation: Soft labels can deviate from ground-truth semantics due to local visual similarities, introducing errors. The paper aims to correct this drift using hard labels.

Method: Introduces HALD, a training paradigm that integrates hard labels as corrective signals alongside soft labels.

Result: Achieves 42.7% on ImageNet-1K with 285M soft-label storage, outperforming prior methods by 9.0%.

Conclusion: Hard labels are vital complements in soft-label-dominated training, improving alignment and generalization.

Abstract: Soft labels generated by teacher models have become a dominant paradigm for knowledge transfer and recent large-scale dataset distillation such as SRe2L, RDED, LPLD, offering richer supervision than conventional hard labels. However, we observe that when only a limited number of crops per image are used, soft labels are prone to local semantic drift: a crop may visually resemble another class, causing its soft embedding to deviate from the ground-truth semantics of the original image. This mismatch between local visual content and global semantic meaning introduces systematic errors and distribution misalignment between training and testing. In this work, we revisit the overlooked role of hard labels and show that, when appropriately integrated, they provide a powerful content-agnostic anchor to calibrate semantic drift. We theoretically characterize the emergence of drift under few soft-label supervision and demonstrate that hybridizing soft and hard labels restores alignment between visual content and semantic supervision. Building on this insight, we propose a new training paradigm, Hard Label for Alleviating Local Semantic Drift (HALD), which leverages hard labels as intermediate corrective signals while retaining the fine-grained advantages of soft labels. Extensive experiments on dataset distillation and large-scale conventional classification benchmarks validate our approach, showing consistent improvements in generalization. On ImageNet-1K, we achieve 42.7% with only 285M storage for soft labels, outperforming prior state-of-the-art LPLD by 9.0%. Our findings re-establish the importance of hard labels as a complementary tool, and call for a rethinking of their role in soft-label-dominated training.

</details>


### [76] [Stylized Synthetic Augmentation further improves Corruption Robustness](https://arxiv.org/abs/2512.15675)
*Georg Siedel,Rojan Regmi,Abhirami Anand,Weijia Shao,Silvia Vock,Andrey Morozov*

Main category: cs.CV

TL;DR: Proposes combining synthetic images and neural style transfer to improve deep vision models' robustness to corruptions, achieving SOTA results.


<details>
  <summary>Details</summary>
Motivation: Address vulnerability of deep vision models to common corruptions.

Method: Training data augmentation pipeline combining synthetic image data and neural style transfer, analyzed systematically.

Result: Achieves 93.54%, 74.9%, and 50.86% robust accuracy on CIFAR-10-C, CIFAR-100-C, and TinyImageNet-C, respectively.

Conclusion: Stylization and synthetic data complement each other well and can enhance robustness when combined with certain augmentation techniques.

Abstract: This paper proposes a training data augmentation pipeline that combines synthetic image data with neural style transfer in order to address the vulnerability of deep vision models to common corruptions. We show that although applying style transfer on synthetic images degrades their quality with respect to the common FID metric, these images are surprisingly beneficial for model training. We conduct a systematic empirical analysis of the effects of both augmentations and their key hyperparameters on the performance of image classifiers. Our results demonstrate that stylization and synthetic data complement each other well and can be combined with popular rule-based data augmentation techniques such as TrivialAugment, while not working with others. Our method achieves state-of-the-art corruption robustness on several small-scale image classification benchmarks, reaching 93.54%, 74.9% and 50.86% robust accuracy on CIFAR-10-C, CIFAR-100-C and TinyImageNet-C, respectively

</details>


### [77] [Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning](https://arxiv.org/abs/2512.15693)
*Yifei Li,Wenzhao Zheng,Yanran Zhang,Runze Sun,Yu Zheng,Lei Chen,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Skyra is an MLLM that detects and explains AI-generated videos by identifying visual artifacts, trained on ViF-CoT-4K and evaluated with ViF-Bench, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Addressing the social concerns of AI-generated video misuse and the limitations of current detection methods lacking interpretability.

Method: Develops Skyra, a multimodal LLM trained on ViF-CoT-4K with a two-stage strategy to enhance artifact perception and explanation.

Result: Skyra outperforms existing methods on benchmarks and provides interpretable detection insights.

Conclusion: Skyra advances explainable AI-generated video detection, offering a robust solution with human-understandable explanations.

Abstract: The misuse of AI-driven video generation technologies has raised serious social concerns, highlighting the urgent need for reliable AI-generated video detectors. However, most existing methods are limited to binary classification and lack the necessary explanations for human interpretation. In this paper, we present Skyra, a specialized multimodal large language model (MLLM) that identifies human-perceivable visual artifacts in AI-generated videos and leverages them as grounded evidence for both detection and explanation. To support this objective, we construct ViF-CoT-4K for Supervised Fine-Tuning (SFT), which represents the first large-scale AI-generated video artifact dataset with fine-grained human annotations. We then develop a two-stage training strategy that systematically enhances our model's spatio-temporal artifact perception, explanation capability, and detection accuracy. To comprehensively evaluate Skyra, we introduce ViF-Bench, a benchmark comprising 3K high-quality samples generated by over ten state-of-the-art video generators. Extensive experiments demonstrate that Skyra surpasses existing methods across multiple benchmarks, while our evaluation yields valuable insights for advancing explainable AI-generated video detection.

</details>


### [78] [VLIC: Vision-Language Models As Perceptual Judges for Human-Aligned Image Compression](https://arxiv.org/abs/2512.15701)
*Kyle Sargent,Ruiqi Gao,Philipp Henzler,Charles Herrmann,Aleksander Holynski,Li Fei-Fei,Jiajun Wu,Jason Zhang*

Main category: cs.CV

TL;DR: The paper proposes a novel image compression system (VLIC) using vision-language models (VLMs) to align with human perception, achieving competitive performance without needing separate perceptual loss networks.


<details>
  <summary>Details</summary>
Motivation: Traditional distortion functions like MSE are misaligned with human perception. VLMs can replicate human judgments zero-shot, offering a promising tool for improving image compression.

Method: VLIC uses a diffusion-based image compression system, post-trained with VLM judgments instead of distilling them into a separate perceptual loss network.

Result: VLIC achieves competitive or state-of-the-art performance on human-aligned visual compression, validated by perceptual metrics and user studies.

Conclusion: VLMs provide a powerful, zero-shot method for aligning image compression with human perception, eliminating the need for separate perceptual loss networks.

Abstract: Evaluations of image compression performance which include human preferences have generally found that naive distortion functions such as MSE are insufficiently aligned to human perception. In order to align compression models to human perception, prior work has employed differentiable perceptual losses consisting of neural networks calibrated on large-scale datasets of human psycho-visual judgments. We show that, surprisingly, state-of-the-art vision-language models (VLMs) can replicate binary human two-alternative forced choice (2AFC) judgments zero-shot when asked to reason about the differences between pairs of images. Motivated to exploit the powerful zero-shot visual reasoning capabilities of VLMs, we propose Vision-Language Models for Image Compression (VLIC), a diffusion-based image compression system designed to be post-trained with binary VLM judgments. VLIC leverages existing techniques for diffusion model post-training with preferences, rather than distilling the VLM judgments into a separate perceptual loss network. We show that calibrating this system on VLM judgments produces competitive or state-of-the-art performance on human-aligned visual compression depending on the dataset, according to perceptual metrics and large-scale user studies. We additionally conduct an extensive analysis of the VLM-based reward design and training procedure and share important insights. More visuals are available at https://kylesargent.github.io/vlic

</details>


### [79] [End-to-End Training for Autoregressive Video Diffusion via Self-Resampling](https://arxiv.org/abs/2512.15702)
*Yuwei Guo,Ceyuan Yang,Hao He,Yang Zhao,Meng Wei,Zhenheng Yang,Weilin Huang,Dahua Lin*

Main category: cs.CV

TL;DR: The paper introduces Resampling Forcing, a teacher-free method for training autoregressive video diffusion models, addressing exposure bias with self-resampling and sparse causal masks, and improving long-horizon generation with history routing.


<details>
  <summary>Details</summary>
Motivation: Exposure bias in autoregressive video diffusion models due to train-test mismatch limits their effectiveness for world simulation. Existing solutions rely on bidirectional teachers or online discriminators, prompting the need for an end-to-end alternative.

Method: Proposes Resampling Forcing, combining self-resampling to simulate inference errors during training, sparse causal masks for parallel training, and history routing for efficient long-horizon generation.

Result: The approach matches distillation-based baselines in performance and enhances temporal consistency in longer videos through native-length training.

Conclusion: Resampling Forcing offers a scalable, teacher-free solution for autoregressive video model training, improving generalization and temporal coherence.

Abstract: Autoregressive video diffusion models hold promise for world simulation but are vulnerable to exposure bias arising from the train-test mismatch. While recent works address this via post-training, they typically rely on a bidirectional teacher model or online discriminator. To achieve an end-to-end solution, we introduce Resampling Forcing, a teacher-free framework that enables training autoregressive video models from scratch and at scale. Central to our approach is a self-resampling scheme that simulates inference-time model errors on history frames during training. Conditioned on these degraded histories, a sparse causal mask enforces temporal causality while enabling parallel training with frame-level diffusion loss. To facilitate efficient long-horizon generation, we further introduce history routing, a parameter-free mechanism that dynamically retrieves the top-k most relevant history frames for each query. Experiments demonstrate that our approach achieves performance comparable to distillation-based baselines while exhibiting superior temporal consistency on longer videos owing to native-length training.

</details>


### [80] [GateFusion: Hierarchical Gated Cross-Modal Fusion for Active Speaker Detection](https://arxiv.org/abs/2512.15707)
*Yu Wang,Juhyung Ha,Frangil M. Ramirez,Yuchen Wang,David J. Crandall*

Main category: cs.CV

TL;DR: GateFusion introduces a novel Hierarchical Gated Fusion Decoder (HiGate) for ASD, combining pretrained unimodal encoders with adaptive cross-modal feature injection and auxiliary objectives, achieving SOTA results.


<details>
  <summary>Details</summary>
Motivation: Late fusion methods often miss fine-grained cross-modal interactions crucial for robust ASD performance in unconstrained scenarios.

Method: Proposes HiGate for progressive multi-depth fusion using learnable bimodal gates, plus Masked Alignment Loss and Over-Positive Penalty for multimodal learning.

Result: Achieves 77.8% mAP (+9.4%), 86.1% mAP (+2.9%), and 96.1% mAP (+0.5%) on Ego4D-ASD, UniTalk, and WASD benchmarks, respectively, with competitive AVA-ActiveSpeaker performance.

Conclusion: GateFusion's components generalize well and deliver complementary benefits, establishing new SOTA results.

Abstract: Active Speaker Detection (ASD) aims to identify who is currently speaking in each frame of a video. Most state-of-the-art approaches rely on late fusion to combine visual and audio features, but late fusion often fails to capture fine-grained cross-modal interactions, which can be critical for robust performance in unconstrained scenarios. In this paper, we introduce GateFusion, a novel architecture that combines strong pretrained unimodal encoders with a Hierarchical Gated Fusion Decoder (HiGate). HiGate enables progressive, multi-depth fusion by adaptively injecting contextual features from one modality into the other at multiple layers of the Transformer backbone, guided by learnable, bimodally-conditioned gates. To further strengthen multimodal learning, we propose two auxiliary objectives: Masked Alignment Loss (MAL) to align unimodal outputs with multimodal predictions, and Over-Positive Penalty (OPP) to suppress spurious video-only activations. GateFusion establishes new state-of-the-art results on several challenging ASD benchmarks, achieving 77.8% mAP (+9.4%), 86.1% mAP (+2.9%), and 96.1% mAP (+0.5%) on Ego4D-ASD, UniTalk, and WASD benchmarks, respectively, and delivering competitive performance on AVA-ActiveSpeaker. Out-of-domain experiments demonstrate the generalization of our model, while comprehensive ablations show the complementary benefits of each component.

</details>


### [81] [Multi-View Foundation Models](https://arxiv.org/abs/2512.15708)
*Leo Segre,Or Hirschorn,Shai Avidan*

Main category: cs.CV

TL;DR: The paper proposes a method to enhance foundation models in Computer Vision to handle multi-view images consistently, improving feature matching across views without needing a 3D model.


<details>
  <summary>Details</summary>
Motivation: Current foundation models process single RGB images independently, leading to inconsistent features for the same 3D point across multiple views.

Method: Augmenting Transformers-based foundation models (e.g., DINO, SAM, CLIP) with 3D-aware attention layers to ensure feature consistency across multiple views.

Result: The proposed method significantly improves feature matching compared to existing foundation models, demonstrated through tasks like surface normal estimation and multi-view segmentation.

Conclusion: The approach successfully converts single-view foundation models into multi-view ones, enabling consistent feature representation across images without requiring a 3D model.

Abstract: Foundation models are vital tools in various Computer Vision applications. They take as input a single RGB image and output a deep feature representation that is useful for various applications. However, in case we have multiple views of the same 3D scene, they operate on each image independently and do not always produce consistent features for the same 3D point. We propose a way to convert a Foundation Model into a Multi-View Foundation Model. Such a model takes as input a set of images and outputs a feature map for each image such that the features of corresponding points are as consistent as possible. This approach bypasses the need to build a consistent 3D model of the features and allows direct manipulation in the image space. Specifically, we show how to augment Transformers-based foundation models (i.e., DINO, SAM, CLIP) with intermediate 3D-aware attention layers that help match features across different views. As leading examples, we show surface normal estimation and multi-view segmentation tasks. Quantitative experiments show that our method improves feature matching considerably compared to current foundation models.

</details>


### [82] [DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models](https://arxiv.org/abs/2512.15713)
*Lunbin Zeng,Jingfeng Yao,Bencheng Liao,Hongyuan Tao,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionVL introduces a method to transform autoregressive (AR) models into diffusion-based vision-language models (dVLMs), achieving competitive performance and faster inference with minimal training data.


<details>
  <summary>Details</summary>
Motivation: The study aims to bridge the performance gap between diffusion-based vision-language models and mainstream autoregressive models by leveraging existing AR models.

Method: The approach involves fine-tuning AR models into the diffusion paradigm, introducing block-decoding for efficient generation and KV cache reuse.

Result: DiffusionVL achieves a 34.4% improvement on MMMU-Pro and 37.5% on MME benchmarks, with a 2x inference speedup, using less than 5% of the data required by previous methods.

Conclusion: The results demonstrate the feasibility and effectiveness of converting AR models into dVLMs, offering significant performance gains and efficiency improvements.

Abstract: In recent multimodal research, the diffusion paradigm has emerged as a promising alternative to the autoregressive paradigm (AR), owing to its unique decoding advantages. However, due to the capability limitations of the base diffusion language model, the performance of the diffusion vision language model (dVLM) still lags significantly behind that of mainstream models. This leads to a simple yet fundamental question: Is it possible to construct dVLMs based on existing powerful AR models? In response, we propose DiffusionVL, a dVLM family that could be translated from any powerful AR models. Through simple fine-tuning, we successfully adapt AR pre-trained models into the diffusion paradigm. This approach yields two key observations: (1) The paradigm shift from AR-based multimodal models to diffusion is remarkably effective. (2) Direct conversion of an AR language model to a dVLM is also feasible, achieving performance competitive with LLaVA-style visual-instruction-tuning. Further, we introduce a block-decoding design into dVLMs that supports arbitrary-length generation and KV cache reuse, achieving a significant inference speedup. We conduct a large number of experiments. Despite training with less than 5% of the data required by prior methods, DiffusionVL achieves a comprehensive performance improvement-a 34.4% gain on the MMMU-Pro (vision) bench and 37.5% gain on the MME (Cog.) bench-alongside a 2x inference speedup. The model and code are released at https://github.com/hustvl/DiffusionVL.

</details>


### [83] [In Pursuit of Pixel Supervision for Visual Pre-training](https://arxiv.org/abs/2512.15715)
*Lihe Yang,Shang-Wen Li,Yang Li,Xinjie Lei,Dong Wang,Abdelrahman Mohamed,Hengshuang Zhao,Hu Xu*

Main category: cs.CV

TL;DR: Autoencoder-based self-supervised learning (Pixio) remains competitive, offering simple, stable, and efficient representations for downstream tasks like depth estimation and semantic segmentation.


<details>
  <summary>Details</summary>
Motivation: Pixels are fundamental visual information sources, and autoencoders are classical tools for learning representations. This work aims to show their continued relevance.

Method: Pixio, an enhanced masked autoencoder (MAE), uses challenging pre-training tasks, capable architectures, and self-curation on 2B web-crawled images.

Result: Pixio performs competitively in downstream tasks (e.g., depth estimation, 3D reconstruction) and matches or outperforms DINOv3 at similar scales.

Conclusion: Pixel-space self-supervised learning is a viable and complementary alternative to latent-space approaches.

Abstract: At the most basic level, pixels are the source of the visual information through which we perceive the world. Pixels contain information at all levels, ranging from low-level attributes to high-level concepts. Autoencoders represent a classical and long-standing paradigm for learning representations from pixels or other raw inputs. In this work, we demonstrate that autoencoder-based self-supervised learning remains competitive today and can produce strong representations for downstream tasks, while remaining simple, stable, and efficient. Our model, codenamed "Pixio", is an enhanced masked autoencoder (MAE) with more challenging pre-training tasks and more capable architectures. The model is trained on 2B web-crawled images with a self-curation strategy with minimal human curation. Pixio performs competitively across a wide range of downstream tasks in the wild, including monocular depth estimation (e.g., Depth Anything), feed-forward 3D reconstruction (i.e., MapAnything), semantic segmentation, and robot learning, outperforming or matching DINOv3 trained at similar scales. Our results suggest that pixel-space self-supervised learning can serve as a promising alternative and a complement to latent-space approaches.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [84] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: Hallucinations in LLMs like transformers are argued to stem from their intrinsic architecture, not just misaligned incentives, and require external validation for elimination.


<details>
  <summary>Details</summary>
Motivation: To challenge the view that hallucinations in large language models (LLMs) are due to misaligned incentives, proposing instead they are inherent to transformer architectures.

Method: Used empirical experiments with a Licensing Oracle and analyzed structural hallucination to demonstrate the architectural inevitability of hallucinations.

Result: Hallucinations persist due to transformers modeling token co-occurrence, not world representations, and can only be eliminated via external validation.

Conclusion: Hallucination is inherent to generative architectures; reliable AI needs hybrid systems separating linguistic fluency from epistemic grounding.

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [85] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: T5Gemma 2 is an advanced lightweight open encoder-decoder model with multilingual, multimodal, and long-context capabilities, building on the T5Gemma family.


<details>
  <summary>Details</summary>
Motivation: The paper aims to extend the T5Gemma framework to handle multimodal data and improve efficiency while maintaining strong performance.

Method: Adapts pretrained decoder-only models into encoder-decoder models, introduces tied word embeddings and merged attention for efficiency, and extends support to multimodal data.

Result: T5Gemma 2 shows comparable or better pretraining and significantly improved post-training performance compared to Gemma 3.

Conclusion: The adaptation strategy is versatile across architectures and modalities, with encoder-decoder architecture excelling in long-context modeling. Models are released for community use.

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [86] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: The paper improves a pipeline for analyzing news viewpoints by fine-tuning LLMs and enriching claim representations with Wikidata data, achieving better results.


<details>
  <summary>Details</summary>
Motivation: To enhance understanding of media dynamics and ensure balanced public discourse by refining methods for identifying and classifying viewpoints in news content.

Method: Fine-tuning Large Language Models (LLMs) for viewpoint classification and enriching claim representations with semantic actor descriptions from Wikidata.

Result: Both fine-tuning LLMs and Wikidata integration independently improve classification, but combining them yields the best performance, especially with long-input LLMs.

Conclusion: The enhanced pipeline successfully improves viewpoint classification in news content, contributing to more accurate media landscape assessments.

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [87] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: The paper evaluates LLM performance on pharmacy QA tasks and introduces DrugRAG, a method integrating external drug knowledge to boost accuracy without altering model architecture.


<details>
  <summary>Details</summary>
Motivation: To improve LLM accuracy in pharmacy-related question-answering tasks by leveraging external structured knowledge.

Method: Benchmarked 11 LLMs on a 141-question pharmacy dataset, then developed DrugRAG, a retrieval-augmented generation pipeline integrating validated drug knowledge.

Result: Baseline accuracies varied (46%-92%), with DrugRAG improving all models' performance by 7-21 percentage points.

Conclusion: DrugRAG effectively enhances LLM accuracy for pharmacy tasks by integrating external evidence-based knowledge, offering a practical solution for AI applications.

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [88] [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)
*Caner Erden*

Main category: cs.CL

TL;DR: MAHA introduces a hierarchical attention framework to reduce computational costs in LLMs while maintaining global dependencies and multiscale granularity, achieving an 81% FLOPs reduction.


<details>
  <summary>Details</summary>
Motivation: The quadratic complexity of MHSA limits LLM scalability for long-context tasks. Existing solutions compromise global dependencies or multiscale granularity.

Method: MAHA hierarchically partitions input sequences and aggregates attention matrices optimally via convex optimization or game theory, implemented in a hybrid dilated-convolutional transformer.

Result: MAHA reduces computational cost by 81% at sequence length 4096 compared to standard attention, maintaining performance.

Conclusion: MAHA bridges optimization theory and sequence modeling, offering a scalable solution for next-generation LLMs.

Abstract: The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global dependencies or fail to capture multiscale semantic granularity effectively. In this paper, we propose Multiscale Aggregated Hierarchical Attention (MAHA), a novel architectural framework that reformulates the attention mechanism through hierarchical decomposition and mathematically rigorous aggregation. Unlike conventional approaches that treat token interactions at a single resolution, MAHA dynamically partitions the input sequence into hierarchical scales via learnable downsampling operators. The core innovation lies in its aggregation strategy: we model the fusion of scalespecific attention matrices as a resource allocation problem, solved via a convex optimization framework or a Nash equilibriumbased gametheoretic approach. This ensures a theoretically optimal balance between local nuance and global context fidelity. Implemented within a hybrid dilatedconvolutional transformer backbone, MAHA utilizes differentiable optimization layers to enable endtoend training. Experimental evaluations demonstrate that MAHA achieves superior scalability; empirical FLOPs analysis confirms an 81% reduction in computational cost at a sequence length of 4096 compared to standard attention. This work bridges the gap between optimization theory and sequence modeling, offering a scalable solution for nextgeneration LLMs.

</details>


### [89] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: The paper translates and extends the Flickr30k dataset for Romanian, using open-source LLMs for visual question answering (VQA). Fine-tuned VLMs show improved performance and fluency in Romanian tasks.


<details>
  <summary>Details</summary>
Motivation: To democratize generative AI by addressing the resource gap for low-resource languages like Romanian in multimodal NLP.

Method: Translate Flickr30k into Romanian, extend it for VQA, fine-tune open-source VLMs (LLaMA, LLaVA, Qwen2) using LoRA, and evaluate on Romanian VQA and image description tasks.

Result: Fine-tuned models show improved Romanian VQA performance (e.g., Qwen2-VL-RoVQA gains +6.05% BERTScore F1), better task generalization, and fewer grammatical errors.

Conclusion: The approach successfully enhances Romanian multimodal NLP capabilities, demonstrating the viability of fine-tuning VLMs for low-resource languages.

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [90] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: The paper evaluates multimodal LLMs on chemistry questions, finding challenges in vision-language integration and highlighting Chain-of-Thought prompting as beneficial.


<details>
  <summary>Details</summary>
Motivation: Assessing multimodal LLMs' scientific reasoning in chemistry due to their reliance on visual and textual data.

Method: Systematic evaluation of 40 models using Olympiad-style chemistry questions benchmarked from USNCO exams.

Result: Models struggle with modality fusion; Chain-of-Thought improves accuracy and visual grounding.

Conclusion: Current MLLMs have limitations in scientific reasoning, calling for better multimodal systems in chemistry.

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [91] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: DASH-DTS is an LLM-based framework for Dialogue Topic Segmentation (DTS), addressing informal speech and implicit transitions in maritime VHF dialogues. It introduces novel techniques like topic shift detection, contextual enhancement, and selective sample generation, validated by experimental results and a new dataset, VHF-Dial.


<details>
  <summary>Details</summary>
Motivation: Traditional methods struggle with informal speech and implicit transitions in dialogues like maritime VHF communications, necessitating a more robust solution.

Method: DASH-DTS uses dialogue handshake recognition for topic shift detection, similarity-guided example selection for contextual enhancement, and selective sample generation to improve discrimination and robustness.

Result: The framework achieves state-of-the-art segmentation accuracy on VHF-Dial and standard benchmarks, offering interpretable reasoning and confidence scores.

Conclusion: DASH-DTS provides a reliable foundation for stable monitoring and decision support in operational dialogues, advancing research with the release of VHF-Dial.

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [92] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: SGM is a neuron-level intervention method for multimodal language models that selectively recalibrates toxic neurons, reducing toxicity rates significantly while maintaining model performance.


<details>
  <summary>Details</summary>
Motivation: Multimodal large language models (MLLMs) inherit toxic and biased signals from pretraining data, posing safety risks that existing detoxification methods fail to address effectively.

Method: SGM recalibrates toxic neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without parameter updates. It's evaluated using MM-TOXIC-QA, a multimodal toxicity framework.

Result: SGM reduces harmful rates from 48.2% to 2.5% in standard and adversarial conditions without compromising fluency or reasoning. SGM* integrates with other methods for enhanced safety.

Conclusion: SGM offers an interpretable, low-cost solution for toxicity-controlled multimodal generation, proving effective and extensible.

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [93] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: The paper introduces the Meta-Prompting Protocol, a framework formalizing LLM orchestration as a programmable system, using an Adversarial Trinity (Generator, Auditor, Optimizer) to ensure reliability and mitigate issues like hallucination.


<details>
  <summary>Details</summary>
Motivation: Current heuristic-based prompt engineering lacks deterministic guarantees for mission-critical applications, necessitating a re-engineering of interaction paradigms for LLMs.

Method: Proposes the Meta-Prompting Protocol with an Adversarial Trinity (P, A, O), treating natural language instructions as differentiable variables and critiques as gradients to optimize LLM performance.

Result: Demonstrates theoretical viability using declarative programming (DSPy) and automatic textual differentiation (TextGrad), aiming to mitigate hallucination and model collapse.

Conclusion: Establishes a foundation for 'Observable Software Engineering' in probabilistic computing, offering a more reliable framework for LLM interaction.

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [94] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: SCOPE improves test-time reinforcement learning by using dynamic subgroup partitioning and step-wise confidence-weighted pseudo-labels, outperforming baselines by significant margins on benchmarks like AIME 2025 and AMC.


<details>
  <summary>Details</summary>
Motivation: The reliance on annotated data and issues like confirmation bias and sparse rewards in majority voting strategies limit the performance of reinforcement learning for LLMs.

Method: SCOPE integrates step-wise confidence and dynamic subgroup partitioning to prioritize high-quality reasoning paths and balance exploration diversity, deriving local consensus through repeat sampling.

Result: SCOPE achieves relative improvements of 13.1% on AIME 2025 and 8.1% on AMC, consistently outperforming recent baselines.

Conclusion: SCOPE effectively addresses the limitations of existing methods, enhancing reasoning ability in LLMs through confidence-weighted pseudo-labels and dynamic subgroup exploration.

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [95] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: Summarizes a large-scale Rakuten Travel Reviews corpus with 7.3M reviews (2009-2024), detailing metadata and analyzing data drift factors (2019-2024).


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive dataset of travel reviews for research and analyze trends influencing data drift.

Method: Collect and organize 7.3 million reviews with detailed metadata; use statistical approaches for insights on data drift.

Result: A rich dataset with statistical insights into factors causing data drift between 2019 and 2024.

Conclusion: The corpus is valuable for research, offering detailed metadata and insights into review trends and data drift.

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [96] [MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163)
*Xuanjun Zong,Zhiqi Shen,Lei Wang,Yunshi Lan,Chao Yang*

Main category: cs.CL

TL;DR: The paper introduces MCP-SafetyBench, a benchmark for evaluating safety risks in Model Context Protocol (MCP) deployments, highlighting vulnerabilities in large language models (LLMs) as they interact with diverse tools.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks fail to capture the safety risks posed by MCP's openness and multi-server workflows, necessitating a comprehensive evaluation tool.

Method: Developed MCP-SafetyBench, a benchmark built on real MCP servers, featuring a taxonomy of 20 attack types and evaluating LLMs across five domains with multi-turn tasks.

Result: Revealed significant safety performance gaps among LLMs and escalating vulnerabilities with increased task complexity and server interactions.

Conclusion: MCP-SafetyBench underscores the need for better defenses and serves as a foundation for addressing safety risks in real-world MCP applications.

Abstract: Large language models (LLMs) are evolving into agentic systems that reason, plan, and operate external tools. The Model Context Protocol (MCP) is a key enabler of this transition, offering a standardized interface for connecting LLMs with heterogeneous tools and services. Yet MCP's openness and multi-server workflows introduce new safety risks that existing benchmarks fail to capture, as they focus on isolated attacks or lack real-world coverage. We present MCP-SafetyBench, a comprehensive benchmark built on real MCP servers that supports realistic multi-turn evaluation across five domains: browser automation, financial analysis, location navigation, repository management, and web search. It incorporates a unified taxonomy of 20 MCP attack types spanning server, host, and user sides, and includes tasks requiring multi-step reasoning and cross-server coordination under uncertainty. Using MCP-SafetyBench, we systematically evaluate leading open- and closed-source LLMs, revealing large disparities in safety performance and escalating vulnerabilities as task horizons and server interactions grow. Our results highlight the urgent need for stronger defenses and establish MCP-SafetyBench as a foundation for diagnosing and mitigating safety risks in real-world MCP deployments.

</details>


### [97] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: The paper draws parallels between NLG evaluation and student grading, highlighting the 'Great Misalignment Problem' due to reliance on final products over processes. It proposes the P-MFA model for process-based assessment.


<details>
  <summary>Details</summary>
Motivation: Addresses the inadequacy of traditional assessment methods in both NLG evaluation and student grading when faced with advanced tools like ChatGPT.

Method: Introduces the Pedagogical Multi-Factor Assessment (P-MFA) model, inspired by multi-factor authentication, focusing on process-based evaluation.

Result: Proposes a shift from product-centric to process-centric assessment to restore validity.

Conclusion: The P-MFA model offers a viable solution to the Great Misalignment Problem by emphasizing learning processes.

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [98] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: RFKG-CoT enhances LLMs' reliability in knowledge-intensive QA by dynamically adjusting KG relation hops and using in-context learning for better path guidance.


<details>
  <summary>Details</summary>
Motivation: Address limitations of rigid hop-count selection and underutilized reasoning paths in existing methods like KG-CoT.

Method: Introduces a relation-driven adaptive hop-count selector and few-shot in-context learning path guidance with CoT.

Result: Improves accuracy by up to 14.7 pp over KG-CoT on KGQA benchmarks.

Conclusion: RFKG-CoT's adaptive hop-count selector and path prompt jointly improve faithfulness of answers.

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [99] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: The paper describes the Yes-MT team's systems for translating between English and four low-resource Indic languages, testing various methods like fine-tuning pre-trained models and LLMs, with results evaluated using SacreBLEU and CHRF.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the challenges of low-resource language translation, focusing on Assamese, Mizo, Khasi, and Manipuri, leveraging advanced models and techniques.

Method: Approaches included fine-tuning models like mT5 and IndicBart, LoRA adjustments, zero-shot/few-shot prompting with LLMs (Llama 3, Mixtral 8x7b), and training Transformer models from scratch.

Result: Evaluation on WMT23 test data showed the difficulties of low-resource translation but underscored the promise of LLMs, especially when fine-tuned.

Conclusion: The study highlights the effectiveness of fine-tuned LLMs for low-resource Indic language translation, despite inherent challenges.

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [100] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: FAME is a synthetic benchmark for evaluating Machine Unlearning in LLMs, addressing limitations of existing benchmarks by supporting multilingual evaluation and enabling both entity-level and instance-level unlearning.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for Machine Unlearning in LLMs are limited to English and only support entity-level forgetting, lacking comprehensive evaluation across languages and finer-grained unlearning scenarios.

Method: FAME introduces 1,000 fictional actor biographies and 20,000 QA pairs across five languages, organized by structured categories. It includes dataset splits for entity-level and instance-level unlearning.

Result: FAME enables controlled evaluation of unlearning techniques across English, French, German, Italian, and Spanish, ensuring synthetic data avoids pretraining contamination.

Conclusion: FAME fills critical gaps in Machine Unlearning benchmarks, offering a multilingual, structured, and synthetic dataset for evaluating unlearning methods effectively.

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [101] [The Moralization Corpus: Frame-Based Annotation and Analysis of Moralizing Speech Acts across Diverse Text Genres](https://arxiv.org/abs/2512.15248)
*Maria Becker,Mirko Sommer,Lars Tapken,Yi Wan Teh,Bruno Brocai*

Main category: cs.CL

TL;DR: The Moralization Corpus is introduced to study moral values in persuasive communication, with an annotation scheme for moral values, demands, and protagonists. LLMs are evaluated for moralization detection, showing detailed prompts work best.


<details>
  <summary>Details</summary>
Motivation: To explore moralizations—moral-value-based arguments—in persuasive communication, this paper introduces the Moralization Corpus due to their pragmatic complexity and implicit nature.

Method: Developed a frame-based annotation scheme for moralizations, applied to diverse German texts (e.g., debates, news). Evaluated LLMs under varied prompting for detection and component extraction.

Result: Detailed prompt instructions outperformed few-shot or explanation-based prompting. Moralization detection is subjective and context-sensitive.

Conclusion: The corpus facilitates fine-grained moralization analysis. Released data and tools aim to advance interdisciplinary research on moral discourse in NLP.

Abstract: Moralizations - arguments that invoke moral values to justify demands or positions - are a yet underexplored form of persuasive communication. We present the Moralization Corpus, a novel multi-genre dataset designed to analyze how moral values are strategically used in argumentative discourse. Moralizations are pragmatically complex and often implicit, posing significant challenges for both human annotators and NLP systems. We develop a frame-based annotation scheme that captures the constitutive elements of moralizations - moral values, demands, and discourse protagonists - and apply it to a diverse set of German texts, including political debates, news articles, and online discussions. The corpus enables fine-grained analysis of moralizing language across communicative formats and domains. We further evaluate several large language models (LLMs) under varied prompting conditions for the task of moralization detection and moralization component extraction and compare it to human annotations in order to investigate the challenges of automatic and manual analysis of moralizations. Results show that detailed prompt instructions has a greater effect than few-shot or explanation-based prompting, and that moralization remains a highly subjective and context-sensitive task. We release all data, annotation guidelines, and code to foster future interdisciplinary research on moral discourse and moral reasoning in NLP.

</details>


### [102] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500 is a clinician-curated collection of 500 synthetic Australian general practice notes, designed to enhance NLP model training by reflecting authentic clinical complexity and diverse conditions.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the lack of generalizable datasets for clinical NLP in Australian general practice, incorporating both common and rare conditions while preserving privacy.

Method: The dataset integrates curriculum-based clinical breadth, epidemiologically-calibrated prevalence, and diverse consultation contexts. It includes messy, authentic elements like typos and patient non-adherence.

Result: Validation shows epidemiological alignment with real GP consultations, high linguistic variation, broad semantic coverage, and improved F1 scores in medical concept extraction tasks.

Conclusion: SynGP500 fills a critical gap by providing a realistic, privacy-protected resource for clinical NLP research and education in Australian general practice.

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [103] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: The paper introduces Progressive Prefix-token Policy Optimization (PPPO), a novel RLVR approach that focuses on optimizing prefix tokens in LLMs to enhance reasoning, outperforming existing methods with significant accuracy improvements.


<details>
  <summary>Details</summary>
Motivation: Current RLVR methods train uniformly across all tokens, neglecting the importance of prefix tokens in reasoning, leading to inefficiency due to optimizing low-return tokens.

Method: PPPO identifies the Beginning Lock-in Effect (BLE) in LLMs and focuses optimization on prefix tokens. It introduces Progressive Prefix Retention and Continuation Accumulated Reward strategies for targeted training.

Result: PPPO achieves an 18.02% accuracy improvement using only 26.17% of training tokens, demonstrating superior performance over existing RLVR methods.

Conclusion: Targeting prefix tokens in LLM reasoning significantly enhances training effectiveness and final results, validated by PPPO's experimental success.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [104] [Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues](https://arxiv.org/abs/2512.15302)
*Xiaotian Zhang,Yuan Wang,Ruizhe Chen,Zeya Wang,Runchen Hou,Zuozhu Liu*

Main category: cs.CL

TL;DR: PersonalAgent is a user-centric lifelong agent designed to continuously learn and adapt to individual user preferences, outperforming existing methods in both idealized and noisy conversational contexts.


<details>
  <summary>Details</summary>
Motivation: The need for LLMs to align with dynamic individual user preferences, addressing limitations of current techniques that focus on universal values or static preferences.

Method: PersonalAgent decomposes dialogues into single-turn interactions, treating preference inference as a sequential decision-making task to dynamically refine a unified user profile.

Result: PersonalAgent outperforms prompt-based and policy optimization baselines, maintaining cross-session preference consistency and excelling in human evaluations.

Conclusion: Lifelong personalization is crucial for developing inclusive and adaptive conversational agents, as demonstrated by PersonalAgent's success.

Abstract: The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.

</details>


### [105] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: The paper evaluates LLMs' efficacy in extracting structured information from zeolite synthesis procedures, focusing on four subtasks and four prompting strategies across six LLMs. Results show strong performance in event classification but limited success in fine-grained extraction, with GPT-5-mini showing high prompt sensitivity. Advanced prompting offers minimal gains, highlighting architectural limitations.


<details>
  <summary>Details</summary>
Motivation: To systematically assess the effectiveness of LLMs in extracting domain-specific scientific information from zeolite synthesis procedures, addressing gaps in existing methods.

Method: Four prompting strategies (zero-shot, few-shot, event-specific, reflection-based) were applied to six LLMs for four subtasks: event classification, trigger identification, argument role extraction, and argument text extraction. The ZSEE dataset (1,530 annotated sentences) was used.

Result: High performance in event classification (80-90% F1), but modest results in fine-grained tasks (50-65% F1). GPT-5-mini showed significant prompt sensitivity (11-79% F1 variation). Advanced prompting strategies provided minimal improvements.

Conclusion: LLMs exhibit high-level understanding but struggle with precise extraction of experimental parameters, indicating the need for domain-adapted models. The study provides benchmarks for scientific information extraction.

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [106] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: The study uses Brookes' Measure to analyze thematic diversity in Arabic Applied Linguistics, finding extreme dispersion (Δ = 0.194) across eight subfields, with Computational Linguistics dominant but not monopolizing.


<details>
  <summary>Details</summary>
Motivation: To understand the thematic structure and diversity within contemporary Arabic Applied Linguistics research.

Method: Analyzed 1,564 publications (2019-2025) using Brookes' Measure of Categorical Dispersion (Δ), classifying them into eight sub-disciplines.

Result: Found extreme thematic dispersion (Δ = 0.194) and identified Computational Linguistics as dominant alongside other active subfields.

Conclusion: Brookes' Measure effectively characterizes field structure, offering a replicable bibliometric method for assessing disciplinary diversity.

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [107] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: Rewriting prompts as poetry can bypass safety measures in LLMs, showing vulnerabilities in current alignment methods.


<details>
  <summary>Details</summary>
Motivation: The study aims to expose the limitations of current alignment regimes in LLMs by demonstrating how versification of prompts can effectively bypass safety controls.

Method: The study uses adversarial poetry to rewrite instructions that are typically refused in prose, testing the effectiveness of versification as a jailbreak mechanism. It evaluates ASR (Attack Success Rate) in benchmarks derived from MLCommons AILuminate.

Result: Manually written poems achieve ~62% ASR, while automated versions reach ~43%, with some models exceeding 90% success in single-turn interactions. The effect is structural and consistent across different training methods (RLHF, constitutional AI, hybrid pipelines).

Conclusion: Versification reveals deep vulnerabilities in LLMs' alignment, as it displaces prompts into sparsely supervised regions. The study highlights the need for evaluating languages like Portuguese, which are currently overlooked.

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [108] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Denser is a framework that optimizes information density for reasoning and answering phases, reducing token usage by up to 62% while maintaining or improving accuracy.


<details>
  <summary>Details</summary>
Motivation: Current LLM approaches use uniform language density for reasoning and answering, which is computationally inefficient. Distinguishing between computational and communicative functions allows for more efficient processing.

Method: Denser uses a query processing module, high-density compressed reasoning mechanism, and human-readable answer generation to optimize efficiency.

Result: Experiments show Denser reduces token consumption by up to 62% compared to Chain-of-Thought methods without sacrificing accuracy.

Conclusion: Denser effectively balances computational efficiency and human readability, making it particularly useful for complex multi-step reasoning tasks.

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [109] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE transforms daily news into weekly insights for a Finnish university by filtering, classifying, and summarizing content into a Time-Dependent Recursive Summary Graph, with a focus on stability and curriculum intelligence.


<details>
  <summary>Details</summary>
Motivation: To provide decision-ready, week-over-week insights from news for educational institutions, enabling PESTEL-aware analysis and curriculum intelligence.

Method: The platform crawls and versions news, applies relevance filtering, embeds content, classifies into PESTEL dimensions, and builds a Time-Dependent Recursive Summary Graph (TRSG) with LLM summarization. It includes a change detector for highlighting updates.

Result: A stable system that delivers concise, actionable insights by clustering and summarizing news, with thematic grouping for analysis.

Conclusion: ORACLE effectively converts news into structured insights, proving useful for curriculum intelligence and decision-making in educational settings.

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [110] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: The study explores using Large Language Models (MI-LLMs) for Motivational Interviewing (MI) in health behavior change, showing improved performance after fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To address the scalability limitations of human counselors in MI by developing AI-driven alternatives using LLMs.

Method: Curated five Chinese counseling datasets, transcribed dialogues into MI-style conversations, fine-tuned three LLMs, and evaluated using automatic metrics and expert coding.

Result: Fine-tuning improved BLEU-4 and ROUGE scores; MI-LLMs achieved MI-adherent ratios close to real human dialogues but lacked complex reflections.

Conclusion: Fine-tuning can equip LLMs for MI counseling, offering scalable AI-assisted health support, though further improvements are needed for complex skills and real-world trials.

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [111] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: The study pioneers Bangla sentiment analysis during Bangladesh's 2024 mass uprising, identifying Outrage, Hope, and Despair themes using LDA and outperforming multilingual transformers and traditional methods.


<details>
  <summary>Details</summary>
Motivation: Address the gap in Bangla sentiment analysis during civil unrest, focusing on understanding public emotions amid political turmoil.

Method: Curated a dataset of 2,028 annotated Bangla news headlines from Facebook, classified into Outrage, Hope, and Despair. Used LDA for theme identification and evaluated multilingual transformers (mBERT, XLM-RoBERTa) and traditional methods (SVM, Logistic Regression).

Result: Language-specific models outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional methods (SVM and Logistic Regression: both 70%).

Conclusion: Highlights the effectiveness of language-specific models for Bangla sentiment analysis during crises, providing insights into public sentiment dynamics.

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [112] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: CTKVR is a novel KV retrieval scheme for LLMs that improves efficiency and accuracy by using a two-stage retrieval strategy and CPU-GPU co-execution, achieving significant performance gains with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Long contexts in LLMs cause high memory overhead and latency due to inefficient KV cache retrieval, motivating the need for a balanced solution.

Method: CTKVR introduces a centroid-then-token retrieval scheme, leveraging query similarity and RoPE effects, with optimized CPU-GPU system implementation.

Result: CTKVR achieves <1% accuracy degradation and 3x-4x throughput speedups on large models like Llama-3-8B and Yi-9B at 96K context length.

Conclusion: CTKVR effectively addresses KV cache retrieval challenges in LLMs, offering a scalable solution for long-context applications.

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [113] [Learning inflection classes using Adaptive Resonance Theory](https://arxiv.org/abs/2512.15551)
*Peter Dekker,Heikki Rasilo,Bart de Boer*

Main category: cs.CL

TL;DR: The study explores how language learners can deduce verbal inflection classes using Adaptive Resonance Theory, tested on Latin, Portuguese, and Estonian, showing best performance in a specific parameter range.


<details>
  <summary>Details</summary>
Motivation: Understanding how individuals learn and process morphological patterns (inflection classes) is crucial for linguistic theory and cognitive modeling.

Method: Unsupervised clustering of lexemes into inflection classes using Adaptive Resonance Theory, a neural network with a vigilance parameter, applied to Latin, Portuguese, and Estonian.

Result: Clustering accuracy varies with inflectional complexity; optimal performance occurs in a narrow vigilance range. Learned features align with linguistic descriptions.

Conclusion: The model effectively captures inflection class patterns and could be extended to study their historical changes in agent-based models.

Abstract: The concept of inflection classes is an abstraction used by linguists, and provides a means to describe patterns in languages that give an analogical base for deducing previously unencountered forms. This ability is an important part of morphological acquisition and processing. We study the learnability of a system of verbal inflection classes by the individual language user by performing unsupervised clustering of lexemes into inflection classes. As a cognitively plausible and interpretable computational model, we use Adaptive Resonance Theory, a neural network with a parameter that determines the degree of generalisation (vigilance). The model is applied to Latin, Portuguese and Estonian. The similarity of clustering to attested inflection classes varies depending on the complexity of the inflectional system. We find the best performance in a narrow region of the generalisation parameter. The learned features extracted from the model show similarity with linguistic descriptions of the inflection classes. The proposed model could be used to study change in inflection classes in the future, by including it in an agent-based model.

</details>


### [114] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: The paper explores automating the creation of Specialized Word Lists (SWLs) for language learning, outperforming the traditional General Service List (GSL) by achieving 95% coverage with fewer words.


<details>
  <summary>Details</summary>
Motivation: To simplify and optimize the process of identifying key words for language learners, reducing reliance on subjective linguistic expertise.

Method: Developed a model to create SWLs tailored to specific subsets of a corpus, using objective criteria for automation and scalability.

Result: SWLs achieved 95% coverage for comprehension with fewer words compared to the industry-standard NGSL.

Conclusion: Automated SWLs offer a scalable, tailored solution for language learners, outperforming traditional methods.

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [115] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: The paper explores Chinese character decomposition technology to improve MWE-aware neural machine translation (NMT), addressing challenges unique to Chinese and Asian languages.


<details>
  <summary>Details</summary>
Motivation: MWEs introduce ambiguity and complexity in NLU, NLP, and NLG tasks, with Western languages like English benefiting from advanced resources and techniques, while Chinese and related languages lag behind.

Method: The study systematically examines Chinese character decomposition technology in MWE-aware NMT, testing its impact on word meaning representation and MWE translation.

Result: Experiments demonstrate how character decomposition aids in representing original meanings and tackling MWE translation challenges in Chinese.

Conclusion: Chinese character decomposition proves effective for MWE-aware NMT, offering a tailored solution for ideograph languages like Chinese.

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [116] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: Bolmo is a family of open byte-level LMs trained by converting subword-level LMs, outperforming prior byte-level LMs and matching subword-level LMs efficiently.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of subword tokenization (e.g., character understanding, fixed vocabulary) while maintaining competitive performance.

Method: Train Bolmo by byteifying existing subword-level LMs using an exact distillation objective, requiring less than 1% of typical pretraining tokens.

Result: Bolmo outperforms prior byte-level LMs and source subword-level LMs in character understanding and coding, with competitive inference speeds.

Conclusion: Byte-level LMs like Bolmo are now practical and competitive with subword-level LMs for diverse use cases.

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [117] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: The paper introduces PsyDefConv, a labeled dialogue corpus for measuring psychological defenses, and DMRS Co-Pilot, a tool that aids annotation. It shows efficiency and reliability improvements but highlights room for improvement in automated defense detection.


<details>
  <summary>Details</summary>
Motivation: Psychological defenses are crucial for mental health but hard to measure in clinical dialogues. The study aims to provide reliable tools for research and clinical practice.

Method: The authors created PsyDefConv, a corpus of 200 dialogues (4709 utterances, 2336 help seeker turns) labeled for defense levels. They introduced DMRS Co-Pilot, a pipeline for pre-annotating defenses, reducing annotation time by 22.4%. The corpus was evaluated using expert reviews and benchmarks with language models.

Result: The co-pilot sped up annotation and scored well in evidence (4.62/7), plausibility (4.44/7), and insight (4.40/7). Benchmarking showed a best macro F1-score of 30%, with models overpredicting mature defenses. The corpus revealed mature defenses as most common and emotion-specific patterns.

Conclusion: The study provides valuable resources for defense research, though automated detection has limitations. Future work can build on the corpus and co-pilot to improve defense measurement.

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [118] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: The paper discusses the challenge of ensuring safety and reliability when integrating LLMs into critical tasks traditionally handled by humans, emphasizing the need for robust evaluation frameworks like LLM-as-Judges (LaJ) to mitigate risks.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the potential risks of using LLMs in safety-critical roles by developing a structured evaluation approach that minimizes errors and ensures reliability.

Method: The proposed method involves using a combination of weighted metrics, context-sensitive error severity definitions, and confidence thresholds to trigger human review when evaluator concordance is low.

Result: The result suggests that while deterministic evaluations are unattainable in many NLP tasks, a basket of metrics can reduce error risks and improve decision reliability in critical LLM applications.

Conclusion: The conclusion advocates for a focus on evidence-based evaluation frameworks like LaJ to safely integrate LLMs into critical information flows, balancing automation with human oversight.

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [119] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: The paper evaluates the performance of LoRA (a PEFT method) vs. SFT in downstream Q&A tasks, focusing on rank configurations and generalization. It finds LoRA can outperform SFT in reasoning tasks at certain ranks.


<details>
  <summary>Details</summary>
Motivation: To explore the understudied impact of PEFT configurations (e.g., rank) on Q&A tasks and generalization, comparing it with SFT.

Method: Comprehensive evaluation using rank sweeps on reasoning and recall datasets, analyzing in-domain/out-of-domain adaptation, and studying internal representations via spectral features and attention patterns.

Result: LoRA achieves competitive or superior performance to SFT, especially in reasoning tasks at specific ranks, and exhibits distinct generalization behavior and task-specific forgetting.

Conclusion: PEFT methods like LoRA can rival SFT in performance, with specific configurations offering advantages in reasoning tasks, while also revealing insights into representational changes.

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [120] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: PPSEBM introduces a novel framework combining Energy-Based Models and Progressive Parameter Selection to mitigate catastrophic forgetting in continual learning for NLP tasks, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The paper addresses catastrophic forgetting in continual learning, where models lose past knowledge when learning new tasks, aiming to improve retention and adaptation.

Method: PPSEBM integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS), using pseudo-samples from prior tasks to guide parameter allocation for new tasks.

Result: Experiments on NLP benchmarks show PPSEBM surpasses state-of-the-art continual learning methods in mitigating catastrophic forgetting.

Conclusion: PPSEBM offers a robust solution to catastrophic forgetting in continual learning, enhancing model performance across sequential NLP tasks.

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [121] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: LatentQA-trained models (Activation Oracles) generalize well in out-of-distribution settings and outperform prior white-box techniques, especially with diversified training data.


<details>
  <summary>Details</summary>
Motivation: To simplify understanding LLM activations by training models to answer natural-language questions about them, focusing on generalization and scalability with diverse training data.

Method: Training Activation Oracles (AOs) using LatentQA, evaluating them in out-of-distribution settings, and testing performance with varied training datasets (e.g., classification tasks, self-supervised prediction).

Result: AOs recover fine-tuned model information not in input text and match/exceed prior white-box baselines on 3 out of 4 tasks. Diversified training improves performance consistently.

Conclusion: Training to answer natural-language queries about LLM activations imparts a general capability, suggesting broader applicability than specialized methods.

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [122] [Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis](https://arxiv.org/abs/2512.15398)
*Zanxiang He,Meng Li,Liyun Shi,Weiye Daia,Liming Nie*

Main category: cs.MA

TL;DR: The paper introduces Mapis, a knowledge-grounded multi-agent framework for guideline-based PCOS diagnosis, addressing limitations of existing tools by leveraging domain-specific knowledge and collaborative agents.


<details>
  <summary>Details</summary>
Motivation: PCOS affects 10% of reproductive-aged women, but current diagnostic tools lack interpretability and rely on large labeled datasets. Multi-agent systems' potential for PCOS detection remains unexplored.

Method: Mapis integrates the 2023 International Guideline into a structured workflow with specialized agents (gynecological endocrine, radiology, exclusion) collaborating for diagnosis. A PCOS knowledge graph supports evidence-based decisions.

Result: Mapis outperforms traditional machine learning by 13.56%, single-agent by 6.55%, and previous multi-agent systems by 7.05% in Accuracy on clinical datasets.

Conclusion: Mapis successfully addresses PCOS diagnostic challenges by combining domain-specific knowledge, interpretability, and collaborative multi-agent workflows, demonstrating superior performance.

Abstract: Polycystic Ovary Syndrome (PCOS) constitutes a significant public health issue affecting 10% of reproductive-aged women, highlighting the critical importance of developing effective diagnostic tools. Previous machine learning and deep learning detection tools are constrained by their reliance on large-scale labeled data and an lack of interpretability. Although multi-agent systems have demonstrated robust capabilities, the potential of such systems for PCOS detection remains largely unexplored. Existing medical multi-agent frameworks are predominantly designed for general medical tasks, suffering from insufficient domain integration and a lack of specific domain knowledge. To address these challenges, we propose Mapis, the first knowledge-grounded multi-agent framework explicitly designed for guideline-based PCOS diagnosis. Specifically, it built upon the 2023 International Guideline into a structured collaborative workflow that simulates the clinical diagnostic process. It decouples complex diagnostic tasks across specialized agents: a gynecological endocrine agent and a radiology agent collaborative to verify inclusion criteria, while an exclusion agent strictly rules out other causes. Furthermore, we construct a comprehensive PCOS knowledge graph to ensure verifiable, evidence-based decision-making. Extensive experiments on public benchmarks and specialized clinical datasets, benchmarking against nine diverse baselines, demonstrate that Mapis significantly outperforms competitive methods. On the clinical dataset, it surpasses traditional machine learning models by 13.56%, single-agent by 6.55%, and previous medical multi-agent systems by 7.05% in Accuracy.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [123] [Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning](https://arxiv.org/abs/2512.14709)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: The paper interprets transformer internals as an approximate Vector Symbolic Architecture (VSA), linking self-attention and residual streams to symbolic reasoning. It explains failure modes and proposes VSA-inspired architectural biases and training objectives for better reasoning systems.


<details>
  <summary>Details</summary>
Motivation: To understand and improve transformer-based models' symbolic reasoning by framing their mechanisms within a VSA framework, addressing brittleness in symbolic tasks.

Method: Analyzes self-attention and residual streams as VSA components (role spaces, fillers, soft unbinding, superposition). Proposes VSA-inspired architectural changes (binding heads, hyperdimensional memory) and training objectives.

Result: Provides insights into transformer reasoning behavior, identifies failure modes (e.g., variable confusion), and suggests practical improvements for logical reliability.

Conclusion: Viewing attention as soft vector-symbolic computation offers a principled approach to enhance transformer interpretability and reasoning reliability.

Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring "VSA-likeness" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.

</details>


### [124] [GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge](https://arxiv.org/abs/2512.14766)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Jiaoyan Chen,Steffen Staab,Yuan He,Evgeny Kharlamov*

Main category: cs.AI

TL;DR: The paper highlights limitations of current KGQA benchmarks due to assumed complete KGs and introduces a methodology for evaluating KGQA under incomplete KGs, proposing GR-Agent for improved reasoning.


<details>
  <summary>Details</summary>
Motivation: Current KGQA benchmarks assume complete KGs, which overlooks the reality of incomplete KGs where answers require inference. This gap limits evaluation of reasoning abilities.

Method: Proposes a benchmark construction methodology for incomplete KGs and introduces GR-Agent, an adaptive reasoning agent that interacts with the KG environment using graph reasoning tools.

Result: Experiments show existing methods degrade under incompleteness, while GR-Agent outperforms non-training baselines and matches training-based methods.

Conclusion: GR-Agent addresses KG incompleteness effectively, demonstrating superior reasoning compared to traditional methods.

Abstract: Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.

</details>


### [125] [IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection](https://arxiv.org/abs/2512.14792)
*Roman Nekrasov,Stefano Fossati,Indika Kumara,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.AI

TL;DR: This paper explores improving LLM-based Infrastructure as Code (IaC) generation for Terraform by injecting structured configuration knowledge, achieving higher success rates but revealing a gap in intent alignment.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) struggle with generating correct and intent-aligned IaC, prompting research into enhancing their performance for Terraform-specific tasks.

Method: Enhanced an IaC-Eval benchmark with cloud emulation and automated error analysis, developed an error taxonomy, and implemented knowledge injection techniques from Naive RAG to Graph RAG.

Result: Baseline LLM performance was low (27.1% success), but structured knowledge injection improved technical validation to 75.3% and overall success to 62.6%. Intent alignment remained limited.

Conclusion: While knowledge injection boosts technical correctness, LLMs still lack nuanced intent alignment, highlighting a 'Correctness-Congruence Gap' between coding proficiency and architectural understanding.

Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a "Correctness-Congruence Gap" where LLMs can become proficient "coders" but remain limited "architects" in fulfilling nuanced user intent.

</details>


### [126] [AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally](https://arxiv.org/abs/2512.14910)
*Nadine Angela Cantonjos,Arpita Biswas*

Main category: cs.AI

TL;DR: AgroAskAI is a multi-agent AI system designed to assist rural agriculture communities with climate adaptation by providing dynamic, context-aware decision support.


<details>
  <summary>Details</summary>
Motivation: Agricultural regions are increasingly vulnerable to climate-related risks, necessitating adaptive solutions. AI, especially agentic AI, offers potential for dynamic, collaborative decision-making.

Method: AgroAskAI uses a modular, role-specialized multi-agent architecture with a chain-of-responsibility approach, integrating real-time tools and datasets.

Result: Experiments show AgroAskAI delivers actionable, grounded, and inclusive outputs for climate adaptation queries in agriculture.

Conclusion: Agentic AI, exemplified by AgroAskAI, holds promise for sustainable and accountable climate adaptation support in agriculture.

Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.

</details>


### [127] [Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation](https://arxiv.org/abs/2512.15033)
*Xidan Song,Weiqi Wang,Ruifeng Cao,Qingya Hu*

Main category: cs.AI

TL;DR: The paper introduces the Geometric Stability Framework to evaluate LLMs' reasoning in chess, revealing an Accuracy-Stability Paradox where high accuracy often masks poor conceptual understanding under transformations.


<details>
  <summary>Details</summary>
Motivation: Standard accuracy metrics in evaluating LLMs for chess fail to distinguish genuine reasoning from memorization. The paper aims to address this gap by testing model consistency under geometric transformations.

Method: Proposes the Geometric Stability Framework, testing LLMs (including GPT-5.1, Claude Sonnet 4.5, and Kimi K2 Turbo) on 3,000 chess positions under invariant transformations like rotation, mirroring, and color inversion.

Result: GPT-5.1 shows high accuracy but catastrophic degradation under transformations (e.g., 600% error surge in rotations). Claude Sonnet 4.5 and Kimi K2 Turbo demonstrate robust consistency. Gemini 2.5 Flash excels in safety (96% illegal state rejection).

Conclusion: Geometric stability is a crucial orthogonal metric for AI evaluation, disentangling reasoning from data contamination and overfitting.

Abstract: The evaluation of Large Language Models (LLMs) in complex reasoning domains typically relies on performance alignment with ground-truth oracles. In the domain of chess, this standard manifests as accuracy benchmarks against strong engines like Stockfish. However, high scalar accuracy does not necessarily imply robust conceptual understanding. This paper argues that standard accuracy metrics fail to distinguish between genuine geometric reasoning and the superficial memorization of canonical board states. To address this gap, we propose a Geometric Stability Framework, a novel evaluation methodology that rigorously tests model consistency under invariant transformations-including board rotation, mirror symmetry, color inversion, and format conversion. We applied this framework to a comparative analysis of six state-of-the-art LLMs including GPT-5.1, Claude Sonnet 4.5, and Kimi K2 Turbo, utilizing a dataset of approximately 3,000 positions. Our results reveal a significant Accuracy-Stability Paradox. While models such as GPT-5.1 achieve near-optimal accuracy on standard positions, they exhibit catastrophic degradation under geometric perturbation, specifically in rotation tasks where error rates surge by over 600%. This disparity suggests a reliance on pattern matching over abstract spatial logic. Conversely, Claude Sonnet 4.5 and Kimi K2 Turbo demonstrate superior dual robustness, maintaining high consistency across all transformation axes. Furthermore, we analyze the trade-off between helpfulness and safety, identifying Gemini 2.5 Flash as the leader in illegal state rejection (96.0%). We conclude that geometric stability provides an orthogonal and essential metric for AI evaluation, offering a necessary proxy for disentangling reasoning capabilities from data contamination and overfitting in large-scale models.

</details>


### [128] [LADY: Linear Attention for Autonomous Driving Efficiency without Transformers](https://arxiv.org/abs/2512.15038)
*Jihao Huang,Xi Xia,Zhiyuan Li,Tianle Liu,Jingke Wang,Junbo Chen,Tengju Ye*

Main category: cs.AI

TL;DR: LADY is a linear attention-based generative model for autonomous driving, addressing the inefficiency of Transformers by enabling constant computational cost and cross-modal interactions.


<details>
  <summary>Details</summary>
Motivation: Current Transformer-based methods for autonomous driving face high computational costs and lack efficient cross-modal support.

Method: LADY uses linear attention mechanisms for efficient spatiotemporal modeling and introduces lightweight linear cross-attention for cross-modal fusion.

Result: LADY achieves state-of-the-art performance with constant computational costs, validated on NAVSIM and Bench2Drive benchmarks and edge devices.

Conclusion: LADY offers a practical, efficient solution for end-to-end autonomous driving, balancing performance and resource constraints.

Abstract: End-to-end paradigms have demonstrated great potential for autonomous driving. Additionally, most existing methods are built upon Transformer architectures. However, transformers incur a quadratic attention cost, limiting their ability to model long spatial and temporal sequences-particularly on resource-constrained edge platforms. As autonomous driving inherently demands efficient temporal modeling, this challenge severely limits their deployment and real-time performance. Recently, linear attention mechanisms have gained increasing attention due to their superior spatiotemporal complexity. However, existing linear attention architectures are limited to self-attention, lacking support for cross-modal and cross-temporal interactions-both crucial for autonomous driving. In this work, we propose LADY, the first fully linear attention-based generative model for end-to-end autonomous driving. LADY enables fusion of long-range temporal context at inference with constant computational and memory costs, regardless of the history length of camera and LiDAR features. Additionally, we introduce a lightweight linear cross-attention mechanism that enables effective cross-modal information exchange. Experiments on the NAVSIM and Bench2Drive benchmarks demonstrate that LADY achieves state-of-the-art performance with constant-time and memory complexity, offering improved planning performance and significantly reduced computational cost. Additionally, the model has been deployed and validated on edge devices, demonstrating its practicality in resource-limited scenarios.

</details>


### [129] [Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study](https://arxiv.org/abs/2512.15044)
*Wenwen Xie,Geng Sun,Ruichen Zhang,Xuejie Liu,Yinqiu Liu,Jiacheng Wang,Dusit Niyato,Ping Zhang*

Main category: cs.AI

TL;DR: This paper explores the role of agentic AI in enhancing ISAC systems for 6G networks, proposing a novel framework and demonstrating its superior performance through a case study.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of wireless environments necessitates smarter, autonomous ISAC systems, which agentic AI can facilitate through continuous perception-reasoning-action loops.

Method: The paper reviews agentic AI and ISAC systems, highlights GenAI-based optimization approaches, and proposes a novel agentic ISAC framework with a case study.

Result: The proposed framework shows superiority in optimizing ISAC performance, as validated by the case study.

Conclusion: Agentic AI holds significant promise for ISAC systems, with future research needed to further explore its potential.

Abstract: Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.

</details>


### [130] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: CogER dynamically selects reasoning strategies for LLMs, balancing efficiency and accuracy by assessing query complexity and using reinforcement learning for strategy selection.


<details>
  <summary>Details</summary>
Motivation: Existing LLM reasoning strategies struggle to balance efficiency and accuracy for varying query difficulties, inspiring the need for a more adaptive approach.

Method: Proposes CogER, a framework that assesses query complexity, assigns levels, and uses a reinforcement-trained agent (CogER-Agent) to select strategies. Includes tool-assisted reasoning for external resources.

Result: CogER outperforms state-of-the-art methods, achieving 13% and 8% relative improvements in exact match for In-Domain and Out-of-Domain tasks, respectively.

Conclusion: CogER effectively enhances LLM reasoning by dynamically adapting strategies, improving both accuracy and efficiency.

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [131] [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)
*Mohsen Nafar,Michael Römer,Lin Xie*

Main category: cs.AI

TL;DR: The paper introduces a clustering-based framework for variable ordering in relaxed decision diagrams to improve dual bounds in discrete optimization, reducing computational costs compared to standard methods.


<details>
  <summary>Details</summary>
Motivation: Efficient exact algorithms for discrete optimization rely on tight dual bounds, which depend on variable ordering and merging decisions in relaxed decision diagrams. Current dynamic ordering heuristics are computationally expensive.

Method: A clustering-based framework partitions variables into clusters, guiding the ordering process. Two strategies are explored: Cluster-to-Cluster and Pick-and-Sort. Theoretical results on decision diagram growth for MWISP inform cluster number policies.

Result: The framework reduces computational costs compared to standard dynamic variable ordering baselines, as demonstrated on MWISP benchmark instances.

Conclusion: The proposed clustering-based framework improves efficiency in deriving dual bounds for discrete optimization, offering practical benefits over existing methods.

Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.

</details>


### [132] [CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](https://arxiv.org/abs/2512.15231)
*Zhengchao Chen,Haoran Wang,Jing Yao,Pedram Ghamisi,Jun Zhou,Peter M. Atkinson,Bing Zhang*

Main category: cs.AI

TL;DR: TL;DR: CangLing-KnowFlow is a unified intelligent agent framework for Earth observation, integrating expert knowledge and adaptive workflows to outperform existing systems in complex tasks.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the lack of a unified framework for automated remote sensing tasks, aiming to integrate diverse workflows from preprocessing to interpretation.

Method: The framework combines a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and Evolutionary Memory Module to guide planning, recover from failures, and continuously learn.

Result: Evaluated on KnowFlow-Bench, CangLing-KnowFlow outperformed Reflexion by at least 4% in Task Success Rate across 324 workflows and 13 LLM backbones.

Conclusion: CangLing-KnowFlow demonstrates robustness and scalability for Earth observation by leveraging expert knowledge into adaptive procedures.

Abstract: The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).

</details>


### [133] [Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis](https://arxiv.org/abs/2512.15295)
*Toshihide Ubukata,Enhong Mu,Takuto Yamauchi,Mingyue Zhang,Jialong Li,Kenji Tei*

Main category: cs.AI

TL;DR: GCRL improves RL-based controller synthesis by using GNNs to capture historical exploration context, showing better efficiency and generalization in benchmarks.


<details>
  <summary>Details</summary>
Motivation: Current RL-based exploration policies in controller synthesis are limited by fixed rules or narrow feature sets, leading to inefficiencies.

Method: GCRL integrates Graph Neural Networks (GNNs) to encode LTS exploration history into a graph, enabling broader context awareness.

Result: GCRL outperformed state-of-the-art methods in 4 out of 5 benchmark domains, with limitations in highly symmetric, locally interactive domains.

Conclusion: GCRL's use of GNNs enhances RL-based controller synthesis, though further improvements are needed for domains with specific interaction constraints.

Abstract: Controller synthesis is a formal method approach for automatically generating Labeled Transition System (LTS) controllers that satisfy specified properties. The efficiency of the synthesis process, however, is critically dependent on exploration policies. These policies often rely on fixed rules or strategies learned through reinforcement learning (RL) that consider only a limited set of current features. To address this limitation, this paper introduces GCRL, an approach that enhances RL-based methods by integrating Graph Neural Networks (GNNs). GCRL encodes the history of LTS exploration into a graph structure, allowing it to capture a broader, non-current-based context. In a comparative experiment against state-of-the-art methods, GCRL exhibited superior learning efficiency and generalization across four out of five benchmark domains, except one particular domain characterized by high symmetry and strictly local interactions.

</details>


### [134] [ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I](https://arxiv.org/abs/2512.15298)
*Seok-Hyun Ga,Chun-Yen Chang*

Main category: cs.AI

TL;DR: Analyzed AI models' scientific reasoning using CSAT questions, revealing key cognitive gaps like perception errors and calculation issues. Suggested designing AI-resistant questions to maintain assessment fairness.


<details>
  <summary>Details</summary>
Motivation: Address growing concerns about academic integrity due to students using AI for assignments by evaluating AI's limitations in scientific reasoning.

Method: Used CSAT's Earth Science section to test LLMs under three input conditions (full-page, individual item, optimized multimodal) and analyzed performance quantitatively and qualitatively.

Result: Models struggled with unstructured inputs, perception errors, and reasoning flaws like 'Process Hallucination.' Optimized inputs still revealed fundamental gaps.

Conclusion: Proposes 'AI-resistant questions' targeting AI's cognitive weaknesses to ensure fair assessments and distinguish genuine student work.

Abstract: The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that "Perception Errors" were dominant, highlighting a "Perception-Cognition Gap" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a "Calculation-Conceptualization Discrepancy," successfully performing calculations while failing to apply the underlying scientific concepts, and "Process Hallucination," where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing "AI-resistant questions" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.

</details>


### [135] [SCOPE: Prompt Evolution for Enhancing Agent Effectiveness](https://arxiv.org/abs/2512.15374)
*Zehua Pei,Hui-Ling Zhen,Shixiong Kai,Sinno Jialin Pan,Yunhe Wang,Mingxuan Yuan,Bei Yu*

Main category: cs.AI

TL;DR: SCOPE introduces a self-evolving prompt optimization method for LLM agents to manage dynamic contexts, improving task success rates significantly.


<details>
  <summary>Details</summary>
Motivation: Static prompts in LLM agents struggle with dynamic contexts, leading to corrective and enhancement failures.

Method: SCOPE frames context management as an online optimization problem, using a Dual-Stream mechanism and Perspective-Driven Exploration.

Result: Experiments on the HLE benchmark show task success rates improving from 14.23% to 38.64%.

Conclusion: SCOPE effectively addresses the capability gap in LLM agents by automating prompt evolution.

Abstract: Large Language Model (LLM) agents are increasingly deployed in environments that generate massive, dynamic contexts. However, a critical bottleneck remains: while agents have access to this context, their static prompts lack the mechanisms to manage it effectively, leading to recurring Corrective and Enhancement failures. To address this capability gap, we introduce \textbf{SCOPE} (Self-evolving Context Optimization via Prompt Evolution). SCOPE frames context management as an \textit{online optimization} problem, synthesizing guidelines from execution traces to automatically evolve the agent's prompt. We propose a Dual-Stream mechanism that balances tactical specificity (resolving immediate errors) with strategic generality (evolving long-term principles). Furthermore, we introduce Perspective-Driven Exploration to maximize strategy coverage, increasing the likelihood that the agent has the correct strategy for any given task. Experiments on the HLE benchmark show that SCOPE improves task success rates from 14.23\% to 38.64\% without human intervention. We make our code publicly available at https://github.com/JarvisPei/SCOPE.

</details>


### [136] [Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations](https://arxiv.org/abs/2512.15388)
*Reinhard Moratz,Niklas Daute,James Ondieki,Markus Kattenbeck,Mario Krajina,Ioannis Giannopoulos*

Main category: cs.AI

TL;DR: The paper focuses on enhancing LLMs' ability to give pedestrian route instructions using qualitative spatial relations.


<details>
  <summary>Details</summary>
Motivation: To improve the utility of LLMs in real-world applications like navigation by leveraging qualitative spatial relations.

Method: Utilizes qualitative spatial relations to refine the way LLMs generate pedestrian route instructions.

Result: Improved accuracy and clarity in route instructions provided by LLMs for pedestrians.

Conclusion: Qualitative spatial relations enhance LLMs' effectiveness in pedestrian navigation tasks.

Abstract: This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.

</details>


### [137] [Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat](https://arxiv.org/abs/2512.15435)
*Stefan Edelkamp*

Main category: cs.AI

TL;DR: The paper introduces a bootstrapping outer-learning framework to enhance early-game decision-making in card games like Skat by merging human expert data with AI-generated games.


<details>
  <summary>Details</summary>
Motivation: Early stages of card games are critical but rely on limited human expert data. The paper aims to improve prediction accuracy by expanding the dataset.

Method: Uses a bootstrapping outer-learning framework, merging human game data with AI-generated games, and implements perfect feature hash functions.

Result: Produces a self-improving card game engine, demonstrated in Skat, enhancing decision-making.

Conclusion: The automated approach effectively supports various game decisions by continuously improving knowledge during self-learning.

Abstract: In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.

</details>


### [138] [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)
*Jeongseok Kim,Kangjin Kim*

Main category: cs.AI

TL;DR: Proposes an integrated system combining MILP and ASP for efficient UAM vertiport scheduling, handling dynamic requirements and ambiguous human inputs via a three-valued logic and decision tree.


<details>
  <summary>Details</summary>
Motivation: Addresses the challenge of efficient vertiport scheduling in UAM due to restricted resources, dynamic operations, and vague human rescheduling requests.

Method: Uses Mixed Integer Linear Programming (MILP) and Answer Set Programming (ASP) integrated with a three-valued logic for ambiguous inputs and a decision tree.

Result: Develops a robust, explainable, and adaptive scheduling framework for UAM.

Conclusion: The integrated system effectively optimizes schedules while transparently supporting human inputs.

Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.

</details>


### [139] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math is a large-scale dataset for mathematical reasoning, outperforming existing datasets by integrating diverse problems and tools, and enabling efficient training.


<details>
  <summary>Details</summary>
Motivation: To address limitations in existing datasets by providing diverse reasoning styles and effective tool integration.

Method: Leveraging GPT-OSS-120B to create Nemotron-Math, combining curated and community-sourced problems, and using a bucketed strategy for efficient training.

Result: It outperforms OpenMathReasoning, improves robustness, and achieves 100% accuracy on AIME 2024 and 2025.

Conclusion: Nemotron-Math sets a new standard for mathematical reasoning datasets and training efficiency.

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [140] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song,Jieyu Lu,Yuanqi Du,Botao Yu,Thomas M. Pruyn,Yue Huang,Kehan Guo,Xiuzhe Luo,Yuanhao Qu,Yi Qu,Yinkai Wang,Haorui Wang,Jeff Guo,Jingru Gan,Parshin Shojaee,Di Luo,Andres M Bran,Gen Li,Qiyuan Zhao,Shao-Xiong Lennon Luo,Yuxuan Zhang,Xiang Zou,Wanru Zhao,Yifan F. Zhang,Wucheng Zhang,Shunan Zheng,Saiyang Zhang,Sartaaj Takrim Khan,Mahyar Rajabi-Kochi,Samantha Paradi-Maropakis,Tony Baltoiu,Fengyu Xie,Tianyang Chen,Kexin Huang,Weiliang Luo,Meijing Fang,Xin Yang,Lixue Cheng,Jiajun He,Soha Hassoun,Xiangliang Zhang,Wei Wang,Chandan K. Reddy,Chao Zhang,Zhiling Zheng,Mengdi Wang,Le Cong,Carla P. Gomes,Chang-Yu Hsieh,Aditya Nandy,Philippe Schwaller,Heather J. Kulik,Haojun Jia,Huan Sun,Seyed Mohamad Moosavi,Chenru Duan*

Main category: cs.AI

TL;DR: The paper introduces a scenario-grounded benchmark to evaluate LLMs in scientific discovery, revealing performance gaps and weaknesses despite their promise.


<details>
  <summary>Details</summary>
Motivation: Existing science benchmarks lack context for iterative reasoning and real-world scientific discovery processes.

Method: A two-phase SDE framework evaluates LLMs at question-level accuracy and project-level performance across biology, chemistry, materials, and physics.

Result: LLMs show consistent performance gaps, diminishing returns from scaling up, and shared weaknesses. They exhibit promise but are far from general scientific superintelligence.

Conclusion: The SDE framework provides a reproducible benchmark for improving LLMs' scientific discovery capabilities, emphasizing guided exploration and serendipity.

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


### [141] [A Decision-Theoretic Approach for Managing Misalignment](https://arxiv.org/abs/2512.15584)
*Daniel A. Herrmann,Abinav Chari,Isabelle Qian,Sree Sharvesh,B. A. Levinstein*

Main category: cs.AI

TL;DR: This paper introduces a decision-theoretic framework to determine when to delegate decisions to AI systems, balancing value alignment, epistemic accuracy, and reach under uncertainty.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the gap in determining when imperfect AI alignment is sufficient for delegation, moving beyond the focus on perfect alignment.

Method: The authors develop a formal framework to analyze the tradeoff between value misalignment, epistemic accuracy, and reach, accounting for the principal's uncertainty.

Result: The analysis distinguishes between universal delegation (requiring near-perfect alignment) and context-specific delegation, which can be optimal even with significant misalignment if the agent's accuracy or reach improves decision outcomes.

Conclusion: The paper provides a principled method for assessing when AI is aligned enough for delegation, emphasizing managing risks and rewards under uncertainty rather than perfect alignment.

Abstract: When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.

</details>


### [142] [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)
*Jiaqi Xu,Cuiling Lan,Xuejin Chen,Yan LU*

Main category: cs.AI

TL;DR: STC integrates reasoning and self-critique in LLMs, improving interpretability and accuracy through hybrid reinforcement learning.


<details>
  <summary>Details</summary>
Motivation: To mimic human critical thinking by combining reasoning and self-evaluation in LLMs, avoiding reliance on external verifiers.

Method: STC framework uses hybrid reinforcement learning to optimize reasoning and self-critique jointly.

Result: STC enhances reasoning quality and interpretability on mathematical benchmarks.

Conclusion: STC advances LLMs with built-in critical thinking, offering synchronized learning and better interpretability.

Abstract: Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

</details>


### [143] [Explaining the Reasoning of Large Language Models Using Attribution Graphs](https://arxiv.org/abs/2512.15663)
*Chase Walker,Rickard Ewetz*

Main category: cs.AI

TL;DR: The paper introduces CAGE, a framework for improving context attributions in LLMs by modeling inter-generational influences via an attribution graph, enhancing explanation faithfulness by up to 40%.


<details>
  <summary>Details</summary>
Motivation: To address the opacity of LLM reasoning and improve the completeness and faithfulness of explanations for their behavior.

Method: Proposes the CAGE framework, which constructs an attribution graph to quantify influences from prompts and prior generations while preserving causality and row stochasticity.

Result: CAGE improves context attribution faithfulness by an average of up to 40% across various models, datasets, and metrics.

Conclusion: CAGE provides a more accurate and comprehensive method for explaining LLM behavior by accounting for inter-generational influences, addressing limitations of current context attribution methods.

Abstract: Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

</details>


### [144] [Artism: AI-Driven Dual-Engine System for Art Generation and Critique](https://arxiv.org/abs/2512.15710)
*Shuai Liu,Yiqing Tian,Yang Chen,Mar Canet Sola*

Main category: cs.AI

TL;DR: Proposes a dual-engine AI method (AIDA and Ismism Machine) for multidimensional art evolution analysis using deep learning and multi-agent collaboration.


<details>
  <summary>Details</summary>
Motivation: To address complex art trajectory exploration and shift from unidirectional critique to interactive, reflexive practice.

Method: Utilizes deep learning and multi-agent collaboration via AIDA (artistic social network) and Ismism Machine (critical analysis).

Result: Enables multidimensional simulations of art history and conceptual innovation, applied in contemporary art studies.

Conclusion: Introduces AI-driven critical loops for computational art analysis, offering new methodological possibilities.

Abstract: This paper proposes a dual-engine AI architectural method designed to address the complex problem of exploring potential trajectories in the evolution of art. We present two interconnected components: AIDA (an artificial artist social network) and the Ismism Machine, a system for critical analysis. The core innovation lies in leveraging deep learning and multi-agent collaboration to enable multidimensional simulations of art historical developments and conceptual innovation patterns. The framework explores a shift from traditional unidirectional critique toward an intelligent, interactive mode of reflexive practice. We are currently applying this method in experimental studies on contemporary art concepts. This study introduces a general methodology based on AI-driven critical loops, offering new possibilities for computational analysis of art.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [145] [Epistemic diversity across language models mitigates knowledge collapse](https://arxiv.org/abs/2512.15011)
*Damian Hodel,Jevin D. West*

Main category: cs.LG

TL;DR: The paper investigates whether diversity among AI models can prevent knowledge collapse, finding that optimal diversity mitigates decay but excess harms performance.


<details>
  <summary>Details</summary>
Motivation: Concerns about AI-driven knowledge collapse prompted exploring ecosystem diversity inspired by ecology.

Method: Studied ecosystems of models trained on collective output, segmenting data across models and evaluating over ten iterations.

Result: Increased epistemic diversity mitigates collapse up to an optimal level; too much or too little harms performance.

Conclusion: Monitoring AI diversity and incentivizing domain-specific models is recommended.

Abstract: The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.

</details>


### [146] [LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts](https://arxiv.org/abs/2512.14706)
*Krunal Jesani,Dmitry Ignatov,Radu Timofte*

Main category: cs.LG

TL;DR: NN-Caption is an LLM-guided NAS pipeline that generates image-captioning models by combining CNN encoders with sequence decoders. It uses DeepSeek-R1-0528-Qwen3-8B, evaluates on MS COCO, and achieves promising results with challenges addressed through prompt rules.


<details>
  <summary>Details</summary>
Motivation: To reduce the need for human expertise or trial-and-error in neural architecture search (NAS) by leveraging LLMs to automate the design of image-captioning models.

Method: NN-Caption composes CNN encoders from LEMUR's classification backbones with sequence decoders (LSTM/GRU/Transformer) under a strict Net API, guided by the LLM DeepSeek-R1-0528-Qwen3-8B. It uses prompt templates and iterative code fixes.

Result: The LLM generated dozens of captioning models, with over half successfully trained. Results include BLEU-4 scores on MS COCO and analysis of training dynamics and success rates with varying input snippets.

Conclusion: The work demonstrates the promise of LLM-guided NAS, showcasing successful model generation and addressing challenges like code hallucinations. It contributes novel models to LEMUR for benchmarking and AutoML research.

Abstract: Neural architecture search (NAS) traditionally requires significant human expertise or automated trial-and-error to design deep learning models. We present NN-Caption, an LLM-guided neural architecture search pipeline that generates runnable image-captioning models by composing CNN encoders from LEMUR's classification backbones with sequence decoders (LSTM/GRU/Transformer) under a strict Net API. Using DeepSeek-R1-0528-Qwen3-8B as the primary generator, we present the prompt template and examples of generated architectures. We evaluate on MS COCO with BLEU-4. The LLM generated dozens of captioning models, with over half successfully trained and producing meaningful captions. We analyse the outcomes of using different numbers of input model snippets (5 vs. 10) in the prompt, finding a slight drop in success rate when providing more candidate components. We also report training dynamics (caption accuracy vs. epochs) and the highest BLEU-4 attained. Our results highlight the promise of LLM-guided NAS: the LLM not only proposes architectures but also suggests hyperparameters and training practices. We identify the challenges encountered (e.g., code hallucinations or API compliance issues) and detail how prompt rules and iterative code fixes addressed them. This work presents a pipeline that integrates prompt-based code generation with automatic evaluation, and adds dozens of novel captioning models to the open LEMUR dataset to facilitate reproducible benchmarking and downstream AutoML research.

</details>


### [147] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: AutoS autonomously selects relevant source samples and models for multi-domain adaptation, improving transfer learning performance.


<details>
  <summary>Details</summary>
Motivation: Address redundancy in multi-source domains to enhance transfer learning by selecting the most useful information.

Method: Uses a density-driven strategy for source selection and a pseudo-label enhancement module to reduce label noise.

Result: Outperforms existing methods on real-world datasets.

Conclusion: AutoS effectively selects transferable knowledge and improves target task performance.

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [148] [SepsisSuite: Beyond Risk Stratification -- A Comparative Analysis of Deep Fusion vs. Expert Stacking for Prescriptive Sepsis AI](https://arxiv.org/abs/2512.14712)
*Ryan Cartularo*

Main category: cs.LG

TL;DR: A comparison of fusion methods for sepsis prediction revealed that a leaner Context-Aware Mixture-of-Experts (MoE) architecture outperformed deep fusion, achieving SOTA performance.


<details>
  <summary>Details</summary>
Motivation: Conventional sepsis prediction models fail to integrate heterogeneous data effectively, necessitating better fusion methods.

Method: Compared End-to-End Deep Fusion and Context-Aware Stacking, ultimately designing SepsisLateFusion with orthogonal modality experts.

Result: SepsisLateFusion achieved 0.915 AUC for early prediction and reduced missed cases by 48%. A quad-modal ensemble excelled in antibiotic selection.

Conclusion: Leaner fusion methods like MoE outperform deep fusion, enabling timely sepsis intervention. SepsisSuite offers deployable solutions.

Abstract: Sepsis accounts for nearly 20% of global ICU admissions, yet conventional prediction models often fail to effectively integrate heterogeneous data streams, remaining either siloed by modality or reliant on brittle early fusion. In this work, we present a rigorous architectural comparison between End-to-End Deep Fusion and Context-Aware Stacking for sepsis tasks. We initially hypothesized that a novel Quad-Modal Hierarchical Gated Attention Network -- termed SepsisFusionFormer -- would resolve complex cross-modal interactions between vitals, text, and imaging. However, experiments on MIMIC-IV revealed that SepsisFusionFormer suffered from "attention starvation" in the small antibiotic cohort ($N \approx 2,100$), resulting in overfitting (AUC 0.66). This counterintuitive result informed the design of SepsisLateFusion, a "leaner" Context-Aware Mixture-of-Experts (MoE) architecture. By treating modalities as orthogonal experts -- the "Historian" (Static), the "Monitor" (Temporal), and the "Reader" (NLP) -- and dynamically gating them via a CatBoost meta-learner, we achieved State-of-the-Art (SOTA) performance: 0.915 AUC for prediction 4 hours prior to clinical onset. By calibrating the decision threshold for clinical safety, we reduced missed cases by 48% relative to the default operating point, thus opening a true preventative window for timely intervention over reactive alerts. Furthermore, for the novel prescriptive task of multi-class antibiotic selection, we demonstrate that a Quad-Modal Ensemble achieved the highest performance (0.72 AUC). These models are integrated into SepsisSuite, a deployment-ready Python framework for clinical decision support. SepsisSuite is available for free at: https://github.com/RyanCartularo/SepsisSuite-Info

</details>


### [149] [A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour](https://arxiv.org/abs/2512.14713)
*Georges Sfeir,Stephane Hess,Thomas O. Hancock,Filipe Rodrigues,Jamal Amani Rad,Michiel Bliemer,Matthew Beck,Fayyaz Khan*

Main category: cs.LG

TL;DR: The paper introduces a Latent Class Reinforcement Learning (LCRL) model to study evolving travel preferences across diverse travelers, identifying three distinct behavioral classes from driving simulator data.


<details>
  <summary>Details</summary>
Motivation: To address heterogeneity in traveler preferences and their evolution, capturing both learning processes and individual differences.

Method: Proposes LCRL model, applied to driving simulator data, with parameter estimation via Variational Bayes.

Result: Identifies three traveler classes with varying adaptive strategies: context-dependent exploitative, persistent exploitative, and exploratory with context-specific preferences.

Conclusion: The LCRL model effectively captures diverse preference evolution patterns, offering insights for tailored travel behavior analysis.

Abstract: Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.

</details>


### [150] [Improving Underwater Acoustic Classification Through Learnable Gabor Filter Convolution and Attention Mechanisms](https://arxiv.org/abs/2512.14714)
*Lucas Cesar Ferreira Domingos,Russell Brinkworth,Paulo Eduardo Santos,Karl Sammut*

Main category: cs.LG

TL;DR: GSE ResNeXt, a deep learning model combining Gabor filters with ResNeXt and attention mechanisms, outperforms baselines in underwater acoustic target classification, reducing training time and improving robustness despite environmental challenges.


<details>
  <summary>Details</summary>
Motivation: Accurate classification of underwater acoustic targets is vital for environmental and defense applications, but noise complexity and data limitations hinder performance.

Method: The paper proposes GSE ResNeXt, integrating learnable Gabor convolutional layers with ResNeXt and squeeze-and-excitation attention to enhance feature extraction and training stability.

Result: GSE ResNeXt outperforms Xception, ResNet, and MobileNetV2, reducing training time by 28% and handling environmental variability better.

Conclusion: Signal processing strategies like Gabor filters improve model reliability in data-limited scenarios, with future work needed to mitigate environmental impacts.

Abstract: Remotely detecting and classifying underwater acoustic targets is critical for environmental monitoring and defence. However, the complex nature of ship-radiated and environmental underwater noise poses significant challenges to accurate signal processing. While recent advancements in machine learning have improved classification accuracy, issues such as limited dataset availability and a lack of standardised experimentation hinder generalisation and robustness. This paper introduces GSE ResNeXt, a deep learning architecture integrating learnable Gabor convolutional layers with a ResNeXt backbone enhanced by squeeze-and-excitation attention mechanisms. The Gabor filters serve as two-dimensional adaptive band-pass filters, extending the feature channel representation. Its combination with channel attention improves training stability and convergence while enhancing the model's ability to extract discriminative features. The model is evaluated on three classification tasks of increasing complexity. In particular, the impact of temporal differences between the training and testing data is explored, revealing that the distance between the vessel and sensor significantly affects performance. Results show that, GSE ResNeXt consistently outperforms baseline models like Xception, ResNet, and MobileNetV2, in terms of classification performance. Regarding stability and convergence, the addition of Gabor convolutions in the initial layers of the model represents a 28% reduction in training time. These results emphasise the importance of signal processing strategies in improving the reliability and generalisation of models under different environmental conditions, especially in data-limited underwater acoustic classification scenarios. Future developments should focus on mitigating the impact of environmental factors on input signals.

</details>


### [151] [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)
*Zafaryab Haider,Md Hafizur Rahman,Shane Moeykens,Vijay Devabhaktuni,Prabuddha Chakraborty*

Main category: cs.LG

TL;DR: BLADE framework analyzes how bit flips in LLM weights alter semantic meaning in image captions while preserving grammar, using gradient-based sensitivity.


<details>
  <summary>Details</summary>
Motivation: Investigate how low-level bitwise perturbations in LLMs affect semantic meaning in generative tasks, unlike prior work focused on non-generative tasks.

Method: Develop BLADE, a differentiable fault analysis framework using gradient-based sensitivity to identify and refine semantically critical bits.

Result: Semantic drifts are predictable via gradients; bit-level faults can steer high-level semantics without disrupting syntax or fluency.

Conclusion: Bit-level perturbations reveal how meaning is encoded in LLMs, aiding robustness testing, adversarial defense, and explainable AI.

Abstract: Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.

</details>


### [152] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)
*Ziqian Bi,Danyang Zhang,Junhao Song,Chiung-Yi Tseng*

Main category: cs.LG

TL;DR: GPT-OSS-20B matches the accuracy of larger models while being more efficient, challenging the notion that bigger models always perform better in financial NLP tasks.


<details>
  <summary>Details</summary>
Motivation: To evaluate the performance and efficiency of GPT-OSS models in financial NLP tasks, addressing the need for sustainable and cost-effective LLM deployment.

Method: Comprehensive testing of GPT-OSS models (120B and 20B variants) against other LLMs on 10 financial NLP tasks using real-world datasets and novel efficiency metrics.

Result: GPT-OSS-20B achieves comparable accuracy (65.1% vs 66.5%) with superior efficiency (198.4 Token Efficiency Score, 159.80 tokens/sec), outperforming larger models like Qwen3-235B.

Conclusion: Smaller GPT-OSS models, through architectural innovations, can match larger competitors' performance with lower computational costs, offering practical advantages for financial applications.

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.

</details>


### [153] [SEED: Spectral Entropy-Guided Evaluation of SpatialTemporal Dependencies for Multivariate Time Series Forecasting](https://arxiv.org/abs/2512.14718)
*Feng Xiong,Zongxia Xie,Yanru Sun,Haoyu Wang,Jianhong Lin*

Main category: cs.LG

TL;DR: SEED is a Spectral Entropy-guided Evaluation framework addressing issues in multivariate time series forecasting by dynamically evaluating dependencies, preserving negative correlations, and enhancing temporal position awareness.


<details>
  <summary>Details</summary>
Motivation: Existing methods disrupt temporal self-dependencies, ignore negative correlations, and fail to account for temporal positions, limiting forecasting accuracy.

Method: SEED introduces a Dependency Evaluator, Spectral Entropy-based Fuser, Signed Graph Constructor, and Context Spatial Extractor to improve spatial-temporal dependency modeling.

Result: SEED achieves state-of-the-art performance across 12 real-world datasets, demonstrating its effectiveness and generality.

Conclusion: SEED effectively addresses key challenges in multivariate time series forecasting, outperforming existing methods.

Abstract: Effective multivariate time series forecasting often benefits from accurately modeling complex inter-variable dependencies. However, existing attention- or graph-based methods face three key issues: (a) strong temporal self-dependencies are often disrupted by irrelevant variables; (b) softmax normalization ignores and reverses negative correlations; (c) variables struggle to perceive their temporal positions. To address these, we propose \textbf{SEED}, a Spectral Entropy-guided Evaluation framework for spatial-temporal Dependency modeling. SEED introduces a Dependency Evaluator, a key innovation that leverages spectral entropy to dynamically provide a preliminary evaluation of the spatial and temporal dependencies of each variable, enabling the model to adaptively balance Channel Independence (CI) and Channel Dependence (CD) strategies. To account for temporal regularities originating from the influence of other variables rather than intrinsic dynamics, we propose Spectral Entropy-based Fuser to further refine the evaluated dependency weights, effectively separating this part. Moreover, to preserve negative correlations, we introduce a Signed Graph Constructor that enables signed edge weights, overcoming the limitations of softmax. Finally, to help variables perceive their temporal positions and thereby construct more comprehensive spatial features, we introduce the Context Spatial Extractor, which leverages local contextual windows to extract spatial features. Extensive experiments on 12 real-world datasets from various application domains demonstrate that SEED achieves state-of-the-art performance, validating its effectiveness and generality.

</details>


### [154] [Hybrid Attribution Priors for Explainable and Robust Model Training](https://arxiv.org/abs/2512.14719)
*Zhuoran Zhang,Feng Zhang,Shangyuan Li,Yang Shi,Yuanxing Zhang,Wei Chen,Tengjiao Wang,Kam-Fai Wong*

Main category: cs.LG

TL;DR: The paper introduces Class-Aware Attribution Prior (CAP) and CAP Hybrid to improve discriminative attribution priors in small language models, enhancing interpretability and robustness.


<details>
  <summary>Details</summary>
Motivation: The challenge of deriving general and reliable attribution priors in small language models (SLMs) for classification tasks, as current methods often focus on common keywords shared by similar classes, providing insufficient discriminative cues.

Method: The paper proposes CAP, a framework for extracting class-aware attribution priors, and CAP Hybrid, which combines CAP with existing methods to create a balanced supervisory signal. This alignment improves feature learning.

Result: Experiments in various scenarios (full-data, few-shot, adversarial) show the method consistently enhances interpretability and robustness.

Conclusion: CAP and CAP Hybrid effectively address the limitations of current attribution methods by improving discriminative attribution priors, leading to better model performance in diverse settings.

Abstract: Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.

</details>


### [155] [Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example](https://arxiv.org/abs/2512.14721)
*Arno Appenzeller,Nick Terzer,André Hohmeyer,Jan-Philipp Redlich,Sabine Luttmann,Friedrich Feuerhake,Nadine S. Schaadt,Timm Intemann,Sarah Teuber-Hanselmann,Stefan Nikolin,Joachim Weis,Klaus Kraywinkel,Pascal Birnstill*

Main category: cs.LG

TL;DR: The paper introduces an automated method to generate Synthea rules for creating synthetic medical data using cancer report statistics, validated with glioblastoma data.


<details>
  <summary>Details</summary>
Motivation: To simplify the complex process of rule creation for synthetic medical data generation, ensuring privacy compliance and reducing reliance on expert knowledge.

Method: Developed an approach to automatically generate Synthea rules from tabular cancer report data, demonstrated with glioblastoma.

Result: Synthetic data replicated disease courses and maintained statistical properties, showing potential for privacy-preserving research.

Conclusion: Synthetic data is promising for research but requires consideration of its limitations in medical interpretation.

Abstract: The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.

</details>


### [156] [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)
*Mohamed Malhou,Ludovic Perret,Kristin Lauter*

Main category: cs.LG

TL;DR: The paper improves Groebner bases computation using Hierarchical Attention Transformers (HATs) with tree-structured inductive bias, achieving significant computational savings and solving larger instances than previous work.


<details>
  <summary>Details</summary>
Motivation: To enhance the efficiency and scalability of Groebner bases computation for solving systems of multivariate polynomial equations by leveraging hierarchical relationships in the data.

Method: Utilizes Hierarchical Attention Transformers (HATs) with tree-structured inductive bias and curriculum learning to generalize to arbitrary depths and analyze computational costs.

Result: Achieves computational savings and successfully solves larger instances compared to conventional flat attention models and prior work.

Conclusion: The HAT-based approach significantly improves Groebner bases computation, demonstrating scalability and efficiency for complex algebraic systems.

Abstract: At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)

</details>


### [157] [Generative Urban Flow Modeling: From Geometry to Airflow with Graph Diffusion](https://arxiv.org/abs/2512.14725)
*Francisco Giral,Álvaro Manzano,Ignacio Gómez,Petros Koumoutsakos,Soledad Le Clainche*

Main category: cs.LG

TL;DR: A generative diffusion framework for urban wind flow modeling combines graph neural networks and diffusion modeling to simulate steady-state wind fields over unstructured meshes using only geometry data.


<details>
  <summary>Details</summary>
Motivation: Urban wind flow modeling is crucial for air quality and city planning, but current methods (low-order models and CFD simulations) struggle with complex geometries and computational costs.

Method: The proposed framework uses hierarchical graph neural networks and score-based diffusion modeling to generate accurate and diverse velocity fields without temporal rollouts or dense measurements.

Result: The model generalizes to unseen geometries, captures key flow structures like wakes and recirculation zones, and provides uncertainty-aware predictions. It performs well under mesh variations and different inference regimes.

Conclusion: This framework is a foundational step toward aiding urban planners in rapidly evaluating design decisions amid densification and climate uncertainty.

Abstract: Urban wind flow modeling and simulation play an important role in air quality assessment and sustainable city planning. A key challenge for modeling and simulation is handling the complex geometries of the urban landscape. Low order models are limited in capturing the effects of geometry, while high-fidelity Computational Fluid Dynamics (CFD) simulations are prohibitively expensive, especially across multiple geometries or wind conditions. Here, we propose a generative diffusion framework for synthesizing steady-state urban wind fields over unstructured meshes that requires only geometry information. The framework combines a hierarchical graph neural network with score-based diffusion modeling to generate accurate and diverse velocity fields without requiring temporal rollouts or dense measurements. Trained across multiple mesh slices and wind angles, the model generalizes to unseen geometries, recovers key flow structures such as wakes and recirculation zones, and offers uncertainty-aware predictions. Ablation studies confirm robustness to mesh variation and performance under different inference regimes. This work develops is the first step towards foundation models for the built environment that can help urban planners rapidly evaluate design decisions under densification and climate uncertainty.

</details>


### [158] [Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning](https://arxiv.org/abs/2512.14726)
*Abraham Itzhak Weinberg*

Main category: cs.LG

TL;DR: Quantum Decision Transformer (QDT) leverages quantum-inspired mechanisms to improve offline reinforcement learning, outperforming standard DTs by over 2,000% and demonstrating enhanced generalization and synergistic benefits.


<details>
  <summary>Details</summary>
Motivation: Existing Decision Transformer architectures struggle with long-horizon credit assignment and complex state-action dependencies in offline reinforcement learning.

Method: Introduces Quantum Decision Transformer (QDT) with Quantum-Inspired Attention (capturing non-local correlations) and Quantum Feedforward Networks (multi-path processing with learnable interference).

Result: Achieves over 2,000% performance improvement versus standard DTs, with superior generalization and strong synergistic effects between components.

Conclusion: Quantum-inspired design principles holistically co-designed offer key computational advantages, advancing transformer architectures for sequential decision-making and beyond.

Abstract: Offline reinforcement learning enables policy learning from pre-collected datasets without environment interaction, but existing Decision Transformer (DT) architectures struggle with long-horizon credit assignment and complex state-action dependencies. We introduce the Quantum Decision Transformer (QDT), a novel architecture incorporating quantum-inspired computational mechanisms to address these challenges. Our approach integrates two core components: Quantum-Inspired Attention with entanglement operations that capture non-local feature correlations, and Quantum Feedforward Networks with multi-path processing and learnable interference for adaptive computation. Through comprehensive experiments on continuous control tasks, we demonstrate over 2,000\% performance improvement compared to standard DTs, with superior generalization across varying data qualities. Critically, our ablation studies reveal strong synergistic effects between quantum-inspired components: neither alone achieves competitive performance, yet their combination produces dramatic improvements far exceeding individual contributions. This synergy demonstrates that effective quantum-inspired architecture design requires holistic co-design of interdependent mechanisms rather than modular component adoption. Our analysis identifies three key computational advantages: enhanced credit assignment through non-local correlations, implicit ensemble behavior via parallel processing, and adaptive resource allocation through learnable interference. These findings establish quantum-inspired design principles as a promising direction for advancing transformer architectures in sequential decision-making, with implications extending beyond reinforcement learning to neural architecture design more broadly.

</details>


### [159] [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Lisa Koch,Christian F. Baumgartner,Michael Muehlebach*

Main category: cs.LG

TL;DR: Conformal prediction (CP) provides statistical guarantees for uncertainty estimates in machine learning (ML), but its practical utility heavily depends on the size of the calibration set, especially in data-scarce medical domains.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the limitations of standard ML models in providing reliable uncertainty estimates for safe clinical decisions. It questions the practical utility of CP's statistical guarantees when calibration sets are small, a common issue in healthcare.

Method: The study critiques CP theory by analyzing its dependence on calibration set size. It includes an empirical demonstration on a medical image classification task to validate the critique.

Result: The results show that while CP's statistical guarantees hold for any calibration set size, the practical utility of these guarantees is significantly reduced with small calibration sets.

Conclusion: The paper concludes that CP's promise of reliable uncertainty estimates is limited in medical applications where large calibration sets are infeasible, highlighting a critical gap in current ML approaches for healthcare.

Abstract: Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.

</details>


### [160] [A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems](https://arxiv.org/abs/2512.14728)
*Jie He,Yong Qin,Jianyuan Guo,Xuan Sun,Xuanchuan Zheng*

Main category: cs.LG

TL;DR: A fully data-driven method using AFC and AVL data achieves high-precision urban rail transit trajectory inference with over 90% accuracy.


<details>
  <summary>Details</summary>
Motivation: To improve urban rail transit operation by refining individual travel trajectory inference.

Method: Uses spatio-temporal constraints for train alternative sets, KLEM for parameter estimation, and constructs travel trajectories.

Result: Achieves over 90% accuracy in trajectory inference during peak hours.

Conclusion: The approach enhances robustness and applicability without relying on external data.

Abstract: Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.

</details>


### [161] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: A geometric framework ensures policy-constrained semantic interpretation without hallucinated commitments, validated in financial data with zero errors.


<details>
  <summary>Details</summary>
Motivation: To prevent hallucinated commitments in high-stakes domains by enforcing policy constraints semantically.

Method: Semantic meaning is directional on a unit sphere; evidence is witness vectors, and interpretations are spherical convex regions. Policy constraints are priors on the same manifold. Interpretation is constrained optimization.

Result: Proves complexity bounds are optimal empirically; zero hallucinated approvals in financial data.

Conclusion: The framework effectively prevents hallucinated commitments, validated by optimal complexity and empirical results.

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [162] [INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT](https://arxiv.org/abs/2512.14732)
*Idan Tankel,Nir Mazor,Rafi Brada,Christina LeBedis,Guy ben-Yosef*

Main category: cs.LG

TL;DR: The paper introduces a framework using LLMs and VLMs to automate incidental findings detection in abdominal CT scans, improving accuracy and efficiency over manual methods.


<details>
  <summary>Details</summary>
Motivation: Manual inspection of incidental findings in CT scans is time-consuming and inconsistent, prompting the need for an automated solution.

Method: A planner-executor framework is used: an LLM generates Python scripts for checks, executed via VLMs, segmentation models, and image processing.

Result: The framework outperforms existing VLM-based methods in accuracy and efficiency on a CT abdominal benchmark for three organs.

Conclusion: Automating incidental findings detection with LLMs and VLMs enhances precision and efficiency in abdominal CT scans.

Abstract: Incidental findings in CT scans, though often benign, can have significant clinical implications and should be reported following established guidelines. Traditional manual inspection by radiologists is time-consuming and variable. This paper proposes a novel framework that leverages large language models (LLMs) and foundational vision-language models (VLMs) in a plan-and-execute agentic approach to improve the efficiency and precision of incidental findings detection, classification, and reporting for abdominal CT scans. Given medical guidelines for abdominal organs, the process of managing incidental findings is automated through a planner-executor framework. The planner, based on LLM, generates Python scripts using predefined base functions, while the executor runs these scripts to perform the necessary checks and detections, via VLMs, segmentation models, and image processing subroutines.
  We demonstrate the effectiveness of our approach through experiments on a CT abdominal benchmark for three organs, in a fully automatic end-to-end manner. Our results show that the proposed framework outperforms existing pure VLM-based approaches in terms of accuracy and efficiency.

</details>


### [163] [Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness](https://arxiv.org/abs/2512.14734)
*Qiang Chen,Venkatesh Ganapati Hegde,Hongfei Li*

Main category: cs.LG

TL;DR: Lightweight, model-agnostic method for intra-day personalization in video streaming improves engagement by 0.47% without model retraining.


<details>
  <summary>Details</summary>
Motivation: Batch-trained models in recommender systems fail to incorporate recent user actions, leading to stale recommendations.

Method: Selectively injects recent watch history at inference time to override stale user features.

Result: Statistically significant 0.47% increase in user engagement metrics.

Conclusion: Intra-day personalization is effective without requiring full real-time architectures.

Abstract: Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.

</details>


### [164] [NoveltyRank: Estimating Conceptual Novelty of AI Papers](https://arxiv.org/abs/2512.14738)
*Zhengxu Yan,Han Li,Yuming Feng*

Main category: cs.LG

TL;DR: A model to rank AI papers' conceptual novelty using title, abstract, and semantic similarity, with two task formulations (binary classification and pairwise novelty comparison).


<details>
  <summary>Details</summary>
Motivation: The surge in AI publications makes it hard for novel work to stand out; manual assessment is unstable and time-consuming.

Method: Evaluate novelty via title, abstract, and semantic similarity. Use Qwen3-4B-Instruct-2507 and SciBERT for binary classification and pairwise comparison, benchmarking against GPT-5.1.

Result: Implementation public on GitHub. Performance analysis of task formulations and modeling choices.

Conclusion: The system aids researchers and reviewers by providing scalable, data-driven novelty assessment.

Abstract: With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.

</details>


### [165] [Guided Discrete Diffusion for Constraint Satisfaction Problems](https://arxiv.org/abs/2512.14765)
*Justin Jung*

Main category: cs.LG

TL;DR: Proposes discrete diffusion guidance for solving CSPs like Sudoku without supervision.


<details>
  <summary>Details</summary>
Motivation: Aims to address constraint satisfaction problems using unsupervised methods.

Method: Uses discrete diffusion guidance tailored for CSPs.

Result: Effectively solves Sudoku puzzles without supervision.

Conclusion: Discrete diffusion guidance is viable for unsupervised CSP solutions.

Abstract: We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.

</details>


### [166] [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)
*Kornelius Raeth,Nicole Ludwig*

Main category: cs.LG

TL;DR: The paper introduces decision calibration as a new framework to evaluate weather forecasts based on their impact on decision-making, showing that traditional forecast-level evaluations don't always align with decision-level performance.


<details>
  <summary>Details</summary>
Motivation: Traditional weather forecast evaluations focus on statistical comparisons between forecasts and observations, but forecasts are ultimately used for decision-making. The paper aims to bridge this gap by evaluating forecasts from the decision-maker's perspective.

Method: The study employs decision calibration to assess forecast performance in terms of decision improvement. It compares Machine Learning and classical numerical weather prediction models across various weather-dependent tasks.

Result: Findings reveal that forecast-level performance doesn't reliably indicate decision-level performance. Differences in model effectiveness are sometimes only visible at the decision level, and model rankings vary across tasks.

Conclusion: Typical forecast evaluations are inadequate for selecting the best model for a specific decision task. Decision calibration provides a more practical and relevant assessment method for real-world applications.

Abstract: Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.

</details>


### [167] [Unreliable Uncertainty Estimates with Monte Carlo Dropout](https://arxiv.org/abs/2512.14851)
*Aslak Djupskås,Alexander Johannes Stasik,Signe Riemer-Sørensen*

Main category: cs.LG

TL;DR: MCD struggles to match true uncertainty accuracy compared to Bayesian methods like GP and BNN.


<details>
  <summary>Details</summary>
Motivation: Assess MCD's reliability in estimating uncertainty for machine learning models, especially in safety-critical domains.

Method: Empirical comparison of MCD with Gaussian Processes (GP) and Bayesian Neural Networks (BNN).

Result: MCD fails to accurately capture uncertainty, particularly in extrapolation/interpolation regions.

Conclusion: MCD's uncertainty estimates are less reliable than traditional Bayesian approaches.

Abstract: Reliable uncertainty estimation is crucial for machine learning models, especially in safety-critical domains. While exact Bayesian inference offers a principled approach, it is often computationally infeasible for deep neural networks. Monte Carlo dropout (MCD) was proposed as an efficient approximation to Bayesian inference in deep learning by applying neuron dropout at inference time \citep{gal2016dropout}. Hence, the method generates multiple sub-models yielding a distribution of predictions to estimate uncertainty. We empirically investigate its ability to capture true uncertainty and compare to Gaussian Processes (GP) and Bayesian Neural Networks (BNN). We find that MCD struggles to accurately reflect the underlying true uncertainty, particularly failing to capture increased uncertainty in extrapolation and interpolation regions as observed in Bayesian models. The findings suggest that uncertainty estimates from MCD, as implemented and evaluated in these experiments, is not as reliable as those from traditional Bayesian approaches for capturing epistemic and aleatoric uncertainty.

</details>


### [168] [How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal](https://arxiv.org/abs/2512.14873)
*Sam Jeong,Hae Yong Kim*

Main category: cs.LG

TL;DR: FAN improves neural networks by replacing some ReLU activations with sine functions, enhancing performance due to their non-zero derivative near zero, not periodicity. A new Dual-Activation Layer (DAL) is proposed, outperforming conventional activations.


<details>
  <summary>Details</summary>
Motivation: To understand why FAN improves performance and to develop a more efficient activation method based on these insights.

Method: Analyzed FAN's sine and cosine activations, identified sine's benefits, and introduced DAL to optimize gradients. Evaluated on noisy signals, MNIST, and ECG tasks.

Result: DAL models converge faster and achieve equal or higher accuracy than conventional activations in all tested tasks.

Conclusion: FAN's gains stem from sine's local gradient behavior, leading to DAL, a superior activation method for faster and more stable training.

Abstract: Fourier Analysis Network (FAN) was recently proposed as a simple way to improve neural network performance by replacing part of ReLU activations with sine and cosine functions. Although several studies have reported small but consistent gains across tasks, the underlying mechanism behind these improvements has remained unclear. In this work, we show that only the sine activation contributes positively to performance, whereas the cosine activation tends to be detrimental. Our analysis reveals that the improvement is not a consequence of the sine function's periodic nature; instead, it stems from the function's local behavior near x = 0, where its non-zero derivative mitigates the vanishing-gradient problem. We further show that FAN primarily alleviates the dying-ReLU problem, in which a neuron consistently receives negative inputs, produces zero gradients, and stops learning. Although modern ReLU-like activations, such as Leaky ReLU, GELU, and Swish, reduce ReLU's zero-gradient region, they still contain input domains where gradients remain significantly diminished, contributing to slower optimization and hindering rapid convergence. FAN addresses this limitation by introducing a more stable gradient pathway. This analysis shifts the understanding of FAN's benefits from a spectral interpretation to a concrete analysis of training dynamics, leading to the development of the Dual-Activation Layer (DAL), a more efficient convergence accelerator. We evaluate DAL on three tasks: classification of noisy sinusoidal signals versus pure noise, MNIST digit classification, and ECG-based biometric recognition. In all cases, DAL models converge faster and achieve equal or higher validation accuracy compared to models with conventional activations.

</details>


### [169] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: ERBP introduces an information-geometric framework to address model collapse in self-referential learning by stabilizing entropy dynamics, validated across diverse applications.


<details>
  <summary>Details</summary>
Motivation: To unify understanding of model collapse in self-referential learning and explain the effectiveness of existing ad~hoc fixes.

Method: Proposes Entropy-Reservoir Bregman Projection (ERBP), modeling the closed loop as stochastic Bregman projections and introducing an entropy reservoir for stabilization.

Result: ERBP provides theoretical conditions for collapse prevention, guarantees a non-trivial entropy floor, and validates predictions in experiments.

Conclusion: ERBP offers a unified, quantitative approach to stabilize self-referential learning by managing entropy flux.

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [170] [Task Matrices: Linear Maps for Cross-Model Finetuning Transfer](https://arxiv.org/abs/2512.14880)
*Darrin O' Brien,Dhikshith Gajulapalli,Eric Xia*

Main category: cs.LG

TL;DR: The paper examines linear encodings in vision and language models, introducing task matrices for adaptation. These matrices, tested across ten datasets, outperform linear probes and near finetuned performance, confirming cross-layer linear encodings exist and are generalizable.


<details>
  <summary>Details</summary>
Motivation: To investigate if linear encodings, observed in biased models, also exist in general adaptation regimes and validate their effectiveness.

Method: Introduces task matrices—a linear transformation from base to finetuned embedding states—and evaluates them across vision/text models and ten datasets.

Result: Task matrices surpass linear probes and approach finetuned performance, confirming cross-layer linear encodings. A data-based approximation proves efficient and generalizable.

Conclusion: The study confirms linear encodings exist broadly and introduces an efficient, generalizable method for leveraging them.

Abstract: Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.

</details>


### [171] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: OLR-WA is a new online linear regression model that performs comparably to batch regression and outperforms other online models, especially in handling data drift and confidence-based scenarios.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing online regression models in handling evolving data patterns (drift) and confidence-based scenarios, while maintaining competitive performance.

Method: Introduces OLR-WA, which uses weighted averaging to prioritize older, higher-confidence data points and handles drift effectively.

Result: OLR-WA achieves performance comparable to batch regression and outperforms other online models in convergence speed and robustness to drift.

Conclusion: OLR-WA is a versatile and effective solution for online linear regression tasks, excelling in dynamic and confidence-sensitive environments.

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [172] [Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections](https://arxiv.org/abs/2512.14895)
*Niklas Lauffer,Xiang Deng,Srivatsa Kundurthy,Brad Kenstler,Jeff Da*

Main category: cs.LG

TL;DR: The paper addresses covariate shift in multi-turn LM agent training by proposing on-policy expert corrections (OECs), a data generation method combining student and expert rollouts, showing improved performance in software engineering tasks.


<details>
  <summary>Details</summary>
Motivation: To overcome the limitations of imitation learning in multi-turn LM agents, particularly covariate shift, which reduces effectiveness as the student policy diverges from the expert.

Method: Introduces OECs: partially on-policy data generated by starting rollouts with a student model and switching to an expert mid-trajectory, tested in software engineering tasks.

Result: OEC trajectories show 14% and 13% relative improvement over traditional imitation learning for 7b and 32b models on SWE-bench verified.

Conclusion: Combining expert demonstrations with on-policy data is crucial for effective multi-turn LM agent training.

Abstract: A popular paradigm for training LM agents relies on imitation learning, fine-tuning on expert trajectories. However, we show that the off-policy nature of imitation learning for multi-turn LM agents suffers from the fundamental limitation known as covariate shift: as the student policy's behavior diverges from the expert's, it encounters states not present in the training data, reducing the effectiveness of fine-tuning. Taking inspiration from the classic DAgger algorithm, we propose a novel data generation methodology for addressing covariate shift for multi-turn LLM training. We introduce on-policy expert corrections (OECs), partially on-policy data generated by starting rollouts with a student model and then switching to an expert model part way through the trajectory. We explore the effectiveness of our data generation technique in the domain of software engineering (SWE) tasks, a multi-turn setting where LLM agents must interact with a development environment to fix software bugs. Our experiments compare OEC data against various other on-policy and imitation learning approaches on SWE agent problems and train models using a common rejection sampling (i.e., using environment reward) combined with supervised fine-tuning technique. Experiments find that OEC trajectories show a relative 14% and 13% improvement over traditional imitation learning in the 7b and 32b setting, respectively, on SWE-bench verified. Our results demonstrate the need for combining expert demonstrations with on-policy data for effective multi-turn LM agent training.

</details>


### [173] [ATLAS: Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs](https://arxiv.org/abs/2512.14908)
*Turja Kundu,Sanjukta Bhowmick*

Main category: cs.LG

TL;DR: ATLAS is a novel graph learning algorithm that improves GNN accuracy on heterophilic graphs and scalability by using multi-level topological information and MLPs, achieving significant performance gains.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of GNNs in handling heterophilic graphs and scalability issues due to iterative feature aggregation.

Method: Extracts topological information at multiple levels, concatenates community assignments to feature vectors, and applies MLPs for scalable learning without aggregation.

Result: Achieves up to 20% better accuracy over GCN for heterophilic graphs and 11% over MLP for homophilic graphs, while being scalable to large graphs.

Conclusion: ATLAS provides a scalable and accurate alternative to GNNs, with explainable graph learning through multi-resolution community features.

Abstract: We present ATLAS (Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs), a novel graph learning algorithm that addresses two important challenges in graph neural networks (GNNs). First, the accuracy of GNNs degrades when the graph is heterophilic. Second, iterative feature aggregation limits the scalability of GNNs to large graphs. We address these challenges by extracting topological information about graph communities at multiple levels of refinement, concatenating community assignments to the feature vector, and applying multilayer perceptrons (MLPs) to the resulting representation. This provides topological context about nodes and their neighborhoods without invoking aggregation. Because MLPs are typically more scalable than GNNs, our approach applies to large graphs without the need for sampling. Across a wide set of graphs, ATLAS achieves comparable accuracy to baseline methods, with gains as high as 20 percentage points over GCN for heterophilic graphs with negative structural bias and 11 percentage points over MLP for homophilic graphs. Furthermore, we show how multi-resolution community features systematically modulate performance in both homophilic and heterophilic settings, opening a principled path toward explainable graph learning.

</details>


### [174] [Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective](https://arxiv.org/abs/2512.14932)
*Daniel Gomes de Pinho Zanco,Leszek Szczecinski,Jacob Benesty,Eduardo Vinicius Kuhn*

Main category: cs.LG

TL;DR: Proposes a method to efficiently determine the regularization parameter for low-rank MMSE filters using Kronecker-product representation, linking it to rank selection.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the importance of choosing the right regularization parameter in low-rank settings, as it directly impacts performance.

Method: Uses a Kronecker-product representation to find the regularization parameter, emphasizing its connection to rank selection.

Result: Simulations validate the method, demonstrating significant performance improvements over common approaches.

Conclusion: Proper selection of the regularization parameter is crucial for low-rank MMSE filters, and the proposed method effectively addresses this.

Abstract: In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.

</details>


### [175] [Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise](https://arxiv.org/abs/2512.14967)
*Felipe J. P. Antunes,Yuri F. Saporito,Sebastian Jaimungal*

Main category: cs.LG

TL;DR: A new numerical method combining Picard iterations, elicitability, and deep learning solves MV-FBSDEs with common noise efficiently, avoiding nested Monte Carlo.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenges of solving MV-FBSDEs with common noise, avoiding costly nested Monte Carlo simulations.

Method: Combines Picard iterations, elicitability for path-wise loss functions, and deep learning (recurrent and feedforward neural networks) to approximate backward processes and conditional expectations.

Result: Validated on systemic risk and economic growth models, accurately recovering solutions and extending to quantile-mediated interactions.

Conclusion: The method is flexible and applicable to complex mean-field games without closed-form solutions.

Abstract: We present a novel numerical method for solving McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with common noise, combining Picard iterations, elicitability and deep learning. The key innovation involves elicitability to derive a path-wise loss function, enabling efficient training of neural networks to approximate both the backward process and the conditional expectations arising from common noise - without requiring computationally expensive nested Monte Carlo simulations. The mean-field interaction term is parameterized via a recurrent neural network trained to minimize an elicitable score, while the backward process is approximated through a feedforward network representing the decoupling field. We validate the algorithm on a systemic risk inter-bank borrowing and lending model, where analytical solutions exist, demonstrating accurate recovery of the true solution. We further extend the model to quantile-mediated interactions, showcasing the flexibility of the elicitability framework beyond conditional means or moments. Finally, we apply the method to a non-stationary Aiyagari--Bewley--Huggett economic growth model with endogenous interest rates, illustrating its applicability to complex mean-field games without closed-form solutions.

</details>


### [176] [Softly Constrained Denoisers for Diffusion Models](https://arxiv.org/abs/2512.14980)
*Victor M. Yeom Song,Severi Rissanen,Arno Solin,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: The paper introduces softly constrained denoisers to improve constraint compliance in diffusion models without biasing the data distribution.


<details>
  <summary>Details</summary>
Motivation: Diffusion models often fail to respect constraints in scientific applications, and existing methods bias the generative model.

Method: The authors integrate guidance-inspired adjustments into the denoiser itself, adding a soft inductive bias for constraint compliance.

Result: Softly constrained denoisers improve compliance while maintaining flexibility for misspecified constraints.

Conclusion: This approach effectively balances constraint adherence and model flexibility, addressing limitations of prior methods.

Abstract: Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.

</details>


### [177] [Prompt Repetition Improves Non-Reasoning LLMs](https://arxiv.org/abs/2512.14982)
*Yaniv Leviathan,Matan Kalman,Yossi Matias*

Main category: cs.LG

TL;DR: Repeating input prompts improves model performance without extra tokens or latency.


<details>
  <summary>Details</summary>
Motivation: To explore simple methods for enhancing model performance without additional computational costs.

Method: Repeating the input prompt in non-reasoning tasks.

Result: Notable performance improvement for models like Gemini, GPT, Claude, and Deepseek.

Conclusion: Prompt repetition is a cost-effective way to boost model performance.

Abstract: When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.

</details>


### [178] [Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes](https://arxiv.org/abs/2512.14991)
*Hanqing Jin,Renyuan Xu,Yanzhao Yang*

Main category: cs.LG

TL;DR: The paper proposes a model-based reinforcement learning algorithm for unbounded diffusion processes, using adaptive partitioning and ensuring efficient learning with theoretical regret bounds and practical validation.


<details>
  <summary>Details</summary>
Motivation: The study addresses reinforcement learning in continuous, high-dimensional domains like finance and economics, where unbounded state spaces and polynomially growing rewards pose challenges.

Method: The introduced algorithm adaptively partitions the state-action space, refining discretization based on estimation bias and statistical confidence, balancing exploration and approximation.

Result: Theoretical regret bounds are established, adapting to problem horizon, state dimension, reward growth, and a new zooming dimension concept. Practical effectiveness is shown via numerical experiments, including multi-asset portfolio selection.

Conclusion: The method extends reinforcement learning guarantees to unbounded diffusion problems, recovering bounded case results and demonstrating practical applicability.

Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

</details>


### [179] [DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding](https://arxiv.org/abs/2512.15000)
*Ruiyi Zhang,Peijia Qin,Qi Cao,Pengtao Xie*

Main category: cs.LG

TL;DR: DreamPRM-Code enhances LLMs for coding by treating functions as reasoning steps and using meta-learning to refine noisy labels, achieving a 80.9 pass@1 rate on LiveCodeBench.


<details>
  <summary>Details</summary>
Motivation: Current PRMs for coding are limited due to poor step decompositions and noisy labels from Monte-Carlo methods.

Method: DreamPRM-Code uses a Chain-of-Function strategy for modular code generation and a meta-learning correction mechanism to refine intermediate labels.

Result: Achieved state-of-the-art performance on LiveCodeBench with a 80.9 pass@1 rate, outperforming OpenAI o4-mini.

Conclusion: DreamPRM-Code successfully addresses PRM limitations in coding tasks, demonstrating superior performance.

Abstract: Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.

</details>


### [180] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: The paper introduces the Stock Pattern Assistant (SPA), a deterministic framework for analyzing historical price movements and linking them to public events, focusing on transparency and auditability rather than prediction or trading signals.


<details>
  <summary>Details</summary>
Motivation: Existing tools like technical indicators and predictive models lack transparency and fail to provide clear explanations, posing challenges for auditability.

Method: SPA extracts monotonic price runs, aligns them with public events using a symmetric correlation window, and generates factual explanations, using only daily OHLCV data and normalized event streams.

Result: SPA produces stable structural decompositions and contextual narratives across equities with varying volatility and sector characteristics, as demonstrated in evaluations of AAPL, NVDA, SCHW, and PGR.

Conclusion: SPA offers a transparent, reproducible method for analyzing historical price structures, enhancing workflows, risk reviews, and explainable-AI pipelines, without focusing on forecasting or trading signals.

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


### [181] [Spectral Representation-based Reinforcement Learning](https://arxiv.org/abs/2512.15036)
*Chenxiao Gao,Haotian Sun,Na Li,Dale Schuurmans,Bo Dai*

Main category: cs.LG

TL;DR: The paper proposes spectral representations derived from the spectral decomposition of transition operators to address challenges in RL, such as theoretical ambiguities and computational costs. It offers methods for constructing these representations and validates their effectiveness on real-world tasks.


<details>
  <summary>Details</summary>
Motivation: Reinforcement learning (RL) with function approximations faces issues like theoretical ambiguities, optimization instability, exploration difficulty, and high computational costs. The paper aims to solve these using spectral representations.

Method: The authors introduce spectral representations based on the spectral decomposition of transition operators. They provide methods to construct these representations for systems with latent variable or energy-based structures, leading to effective RL algorithms.

Result: The proposed spectral representation framework is validated on over 20 tasks from the DeepMind Control Suite, achieving performance comparable or superior to state-of-the-art baselines.

Conclusion: Spectral representations offer a theoretically grounded and practical solution to challenges in RL, with demonstrated effectiveness on complex tasks.

Abstract: In real-world applications with large state and action spaces, reinforcement learning (RL) typically employs function approximations to represent core components like the policies, value functions, and dynamics models. Although powerful approximations such as neural networks offer great expressiveness, they often present theoretical ambiguities, suffer from optimization instability and exploration difficulty, and incur substantial computational costs in practice. In this paper, we introduce the perspective of spectral representations as a solution to address these difficulties in RL. Stemming from the spectral decomposition of the transition operator, this framework yields an effective abstraction of the system dynamics for subsequent policy optimization while also providing a clear theoretical characterization. We reveal how to construct spectral representations for transition operators that possess latent variable structures or energy-based structures, which implies different learning methods to extract spectral representations from data. Notably, each of these learning methods realizes an effective RL algorithm under this framework. We also provably extend this spectral view to partially observable MDPs. Finally, we validate these algorithms on over 20 challenging tasks from the DeepMind Control Suite, where they achieve performances comparable or superior to current state-of-the-art model-free and model-based baselines.

</details>


### [182] [EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks](https://arxiv.org/abs/2512.15067)
*Zijiang Yan,Yixiang Huang,Jianhua Pei,Hina Tabassum,Luca Chiaraviglio*

Main category: cs.LG

TL;DR: EMFusion is a diffusion-based probabilistic forecasting framework for frequency-selective EMF levels, integrating contextual factors and uncertainty estimates, outperforming baselines.


<details>
  <summary>Details</summary>
Motivation: Existing EMF forecasting lacks multivariate approaches; EMFusion addresses this for proactive network planning and compliance.

Method: EMFusion uses a residual U-Net with cross-attention and imputation-based sampling for probabilistic forecasting with contextual integration.

Result: EMFusion improves CRPS by 23.85%, NRMSE by 13.93%, and reduces CRPS error by 22.47% over baselines.

Conclusion: EMFusion provides accurate, uncertainty-aware forecasts for EMF levels, aiding network planning and decision-making.

Abstract: The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wideband aggregate EMF data, frequency-selective multivariate forecasting is needed to capture the inter-operator and inter-frequency variations essential for proactive network planning. To this end, this paper introduces EMFusion, a conditional multivariate diffusion-based probabilistic forecasting framework that integrates diverse contextual factors (e.g., time of day, season, and holidays) while providing explicit uncertainty estimates. The proposed architecture features a residual U-Net backbone enhanced by a cross-attention mechanism that dynamically integrates external conditions to guide the generation process. Furthermore, EMFusion integrates an imputation-based sampling strategy that treats forecasting as a structural inpainting task, ensuring temporal coherence even with irregular measurements. Unlike standard point forecasters, EMFusion generates calibrated probabilistic prediction intervals directly from the learned conditional distribution, providing explicit uncertainty quantification essential for trustworthy decision-making. Numerical experiments conducted on frequency-selective EMF datasets demonstrate that EMFusion with the contextual information of working hours outperforms the baseline models with or without conditions. The EMFusion outperforms the best baseline by 23.85% in continuous ranked probability score (CRPS), 13.93% in normalized root mean square error, and reduces prediction CRPS error by 22.47%.

</details>


### [183] [The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems](https://arxiv.org/abs/2512.15068)
*Debu Sinha*

Main category: cs.LG

TL;DR: Retrieval-Augmented Generation (RAG) systems still hallucinate despite evidence grounding. Current detection methods using semantic similarity and NLI have flaws. Conformal prediction improves detection with guarantees, but embedding-based methods fail on real benchmarks. GPT-4 as a judge shows semantic illusions exist.


<details>
  <summary>Details</summary>
Motivation: To rigorously characterize limitations of current hallucination detection methods in RAG systems and propose solutions.

Method: Applied conformal prediction for hallucination detection, tested on synthetic and real benchmarks using embedding-based methods and GPT-4.

Result: Embedding-based methods had high false positive rates (up to 100%), while GPT-4 achieved low FPR (7%) on real benchmarks.

Conclusion: Embedding-based detection is insufficient for RAG deployment due to semantic illusions. GPT-4 shows reasoning can solve the task.

Abstract: Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the "semantic illusion": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.

</details>


### [184] [The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks](https://arxiv.org/abs/2512.15082)
*Wanfu Gao,Zebin He,Jun Gao*

Main category: cs.LG

TL;DR: FEAML is an automated feature engineering method for multi-label learning, leveraging LLMs' code generation and feedback mechanisms to improve feature quality and reduce redundancy.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-based feature engineering methods lack adaptability to multi-label tasks and fail to model complex label dependencies.

Method: FEAML uses LLMs guided by metadata and label co-occurrence matrices to generate features, evaluates them via accuracy and redundancy checks, and integrates feedback for iterative improvement.

Result: FEAML outperforms other feature engineering methods on various multi-label datasets.

Conclusion: FEAML provides an efficient, interpretable, and self-improving feature engineering approach for multi-label learning.

Abstract: Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

</details>


### [185] [Neural Modular Physics for Elastic Simulation](https://arxiv.org/abs/2512.15083)
*Yifei Li,Haixu Wu,Zeyi Xu,Tuur Stuyck,Wojciech Matusik*

Main category: cs.LG

TL;DR: The paper introduces Neural Modular Physics (NMP), a hybrid approach combining neural networks with traditional simulators for elastic simulation, enhancing interpretability, reliability, and generalization.


<details>
  <summary>Details</summary>
Motivation: Traditional neural simulators lose physical interpretability and reliability. NMP aims to bridge this gap by modularizing dynamics, inspired by classical simulators.

Method: NMP decomposes elastic dynamics into neural modules linked by physical quantities, enabling intermediate supervision and physical constraints.

Result: NMP shows better generalization, stability, and physical consistency than monolithic neural simulators and outperforms traditional simulators in unknown dynamics.

Conclusion: NMP successfully merges neural networks' approximation power with traditional simulators' interpretability, offering improved performance in elastic simulation.

Abstract: Learning-based methods have made significant progress in physics simulation, typically approximating dynamics with a monolithic end-to-end optimized neural network. Although these models offer an effective way to simulation, they may lose essential features compared to traditional numerical simulators, such as physical interpretability and reliability. Drawing inspiration from classical simulators that operate in a modular fashion, this paper presents Neural Modular Physics (NMP) for elastic simulation, which combines the approximation capacity of neural networks with the physical reliability of traditional simulators. Beyond the previous monolithic learning paradigm, NMP enables direct supervision of intermediate quantities and physical constraints by decomposing elastic dynamics into physically meaningful neural modules connected through intermediate physical quantities. With a specialized architecture and training strategy, our method transforms the numerical computation flow into a modular neural simulator, achieving improved physical consistency and generalizability. Experimentally, NMP demonstrates superior generalization to unseen initial conditions and resolutions, stable long-horizon simulation, better preservation of physical properties compared to other neural simulators, and greater feasibility in scenarios with unknown underlying dynamics than traditional simulators.

</details>


### [186] [PIP$^2$ Net: Physics-informed Partition Penalty Deep Operator Network](https://arxiv.org/abs/2512.15086)
*Hongjin Mi,Huiqiang Lun,Changhong Mou,Yeyu Zhang*

Main category: cs.LG

TL;DR: PIP$^{2}$ Net improves operator learning for PDEs with a simplified partition penalty, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Addressing instability and lack of physical structure in current operator learning methods like DeepONet and FNO.

Method: Developed PIP$^{2}$ Net with PoU-based regularization and a principled partition penalty.

Result: Consistently outperformed DeepONet, PI-DeepONet, and POU-DeepONet in accuracy and robustness.

Conclusion: PIP$^{2}$ Net enhances expressiveness and stability in operator learning for nonlinear PDEs.

Abstract: Operator learning has become a powerful tool for accelerating the solution of parameterized partial differential equations (PDEs), enabling rapid prediction of full spatiotemporal fields for new initial conditions or forcing functions. Existing architectures such as DeepONet and the Fourier Neural Operator (FNO) show strong empirical performance but often require large training datasets, lack explicit physical structure, and may suffer from instability in their trunk-network features, where mode imbalance or collapse can hinder accurate operator approximation. Motivated by the stability and locality of classical partition-of-unity (PoU) methods, we investigate PoU-based regularization techniques for operator learning and develop a revised formulation of the existing POU--PI--DeepONet framework. The resulting \emph{P}hysics-\emph{i}nformed \emph{P}artition \emph{P}enalty Deep Operator Network (PIP$^{2}$ Net) introduces a simplified and more principled partition penalty that improved the coordinated trunk outputs that leads to more expressiveness without sacrificing the flexibility of DeepONet. We evaluate PIP$^{2}$ Net on three nonlinear PDEs: the viscous Burgers equation, the Allen--Cahn equation, and a diffusion--reaction system. The results show that it consistently outperforms DeepONet, PI-DeepONet, and POU-DeepONet in prediction accuracy and robustness.

</details>


### [187] [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)
*Xianglin Wu,Chiheb Ben Hammouda,Cornelis W. Oosterlee*

Main category: cs.LG

TL;DR: SigMA, a neural architecture combining path signatures and multi-head attention, outperforms baselines in accuracy and robustness for parameter inference in fBm-driven SDEs.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of parameter estimation in non-Markovian systems like fractional Brownian motion-driven SDEs, which lack classical techniques.

Method: Proposes SigMA, integrating path signatures with multi-head self-attention, convolutional preprocessing, and a multilayer perceptron for feature encoding.

Result: SigMA outperforms CNN, LSTM, Transformer, and Deep Signature baselines in synthetic and real-world datasets (equity-index volatility and battery degradation).

Conclusion: Combining signatures with attention-based architectures offers an effective, scalable solution for parameter inference in rough or persistent stochastic systems.

Abstract: Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.

</details>


### [188] [Feature-Centric Unsupervised Node Representation Learning Without Homophily Assumption](https://arxiv.org/abs/2512.15112)
*Sunwoo Kim,Soo Yong Lee,Kyungho Kim,Hyunjin Hwang,Jaemin Yoo,Kijung Shin*

Main category: cs.LG

TL;DR: FUEL adaptively learns the degree of graph convolution usage in unsupervised node representation learning, enhancing intra-class similarity and inter-class separability by leveraging node features as proxies for classes.


<details>
  <summary>Details</summary>
Motivation: Excessive reliance on graph convolution can yield suboptimal embeddings in non-homophilic graphs, motivating the need for adaptive approaches in unsupervised settings.

Method: FUEL proposes an adaptive method to adjust graph convolution usage by treating node clusters (identified via features) as class proxies, enhancing embedding quality.

Result: Extensive experiments across 15 baselines and 14 datasets show FUEL achieves state-of-the-art performance, particularly in diverse homophily graphs.

Conclusion: FUEL effectively addresses the limitations of excessive graph convolution in unsupervised learning, demonstrating superior performance in downstream tasks.

Abstract: Unsupervised node representation learning aims to obtain meaningful node embeddings without relying on node labels. To achieve this, graph convolution, which aggregates information from neighboring nodes, is commonly employed to encode node features and graph topology. However, excessive reliance on graph convolution can be suboptimal-especially in non-homophilic graphs-since it may yield unduly similar embeddings for nodes that differ in their features or topological properties. As a result, adjusting the degree of graph convolution usage has been actively explored in supervised learning settings, whereas such approaches remain underexplored in unsupervised scenarios. To tackle this, we propose FUEL, which adaptively learns the adequate degree of graph convolution usage by aiming to enhance intra-class similarity and inter-class separability in the embedding space. Since classes are unknown, FUEL leverages node features to identify node clusters and treats these clusters as proxies for classes. Through extensive experiments using 15 baseline methods and 14 benchmark datasets, we demonstrate the effectiveness of FUEL in downstream tasks, achieving state-of-the-art performance across graphs with diverse levels of homophily.

</details>


### [189] [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)
*Runze Li,Hanchen Wang,Wenjie Zhang,Binghao Li,Yu Zhang,Xuemin Lin,Ying Zhang*

Main category: cs.LG

TL;DR: FADTI is a diffusion-based framework for multivariate time series imputation, incorporating frequency-aware features and outperforming existing methods, especially under high missing rates.


<details>
  <summary>Details</summary>
Motivation: Addressing the limitations of existing Transformer- and diffusion-based models in handling structured missing patterns and distribution shifts due to lack of explicit inductive biases and frequency awareness.

Method: FADTI introduces a learnable Fourier Bias Projection (FBP) module for frequency-informed feature modulation, combined with self-attention and gated convolution for temporal modeling.

Result: Experiments on multiple benchmarks, including a new biological dataset, show FADTI consistently outperforms state-of-the-art methods, particularly with high missing rates.

Conclusion: FADTI effectively incorporates frequency-domain inductive bias into generative imputation, improving generalization and performance.

Abstract: Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF

</details>


### [190] [Automatic Reward Shaping from Multi-Objective Human Heuristics](https://arxiv.org/abs/2512.15120)
*Yuqing Xie,Jiayu Chen,Wenhao Tang,Ya Zhang,Chao Yu,Yu Wang*

Main category: cs.LG

TL;DR: MORSE is a framework that automatically combines multiple heuristic rewards into a unified function for multi-objective reinforcement learning, using bi-level optimization and stochasticity for improved exploration and performance.


<details>
  <summary>Details</summary>
Motivation: The challenge lies in designing effective reward functions for multi-objective RL environments, which often require manual tuning. MORSE aims to automate this process.

Method: MORSE uses a bi-level optimization approach—training policies in the inner loop and updating reward functions in the outer loop—while injecting stochastic noise to avoid local minima.

Result: MORSE successfully balances multiple objectives in MuJoCo and Isaac Sim environments, matching performance of manually tuned rewards.

Conclusion: MORSE provides a scalable and effective solution for reward shaping in multi-objective RL without relying on manual tuning.

Abstract: Designing effective reward functions remains a central challenge in reinforcement learning, especially in multi-objective environments. In this work, we propose Multi-Objective Reward Shaping with Exploration (MORSE), a general framework that automatically combines multiple human-designed heuristic rewards into a unified reward function. MORSE formulates the shaping process as a bi-level optimization problem: the inner loop trains a policy to maximize the current shaped reward, while the outer loop updates the reward function to optimize task performance. To encourage exploration in the reward space and avoid suboptimal local minima, MORSE introduces stochasticity into the shaping process, injecting noise guided by task performance and the prediction error of a fixed, randomly initialized neural network. Experimental results in MuJoCo and Isaac Sim environments show that MORSE effectively balances multiple objectives across various robotic tasks, achieving task performance comparable to those obtained with manually tuned reward functions.

</details>


### [191] [TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training](https://arxiv.org/abs/2512.15123)
*Mukur Gupta,Niharika Gupta,Saifur Rahman,Shantanu Pal,Chandan Karmakar*

Main category: cs.LG

TL;DR: TrajSyn is a privacy-preserving framework for adversarial training in Federated Learning by synthesizing proxy datasets from client model updates, improving robustness without extra client compute.


<details>
  <summary>Details</summary>
Motivation: Addressing adversarial vulnerability in edge-deployed deep learning models, especially in FL settings where client-data privacy and limited compute are constraints.

Method: Proposes TrajSyn, a server-side adversarial training framework that synthesizes proxy datasets from client model updates without accessing raw data.

Result: Demonstrates consistent improvement in adversarial robustness on image classification benchmarks without additional client-side compute.

Conclusion: TrajSyn effectively enhances adversarial robustness in FL while preserving privacy and minimizing client compute burden.

Abstract: Deep learning models deployed on edge devices are increasingly used in safety-critical applications. However, their vulnerability to adversarial perturbations poses significant risks, especially in Federated Learning (FL) settings where identical models are distributed across thousands of clients. While adversarial training is a strong defense, it is difficult to apply in FL due to strict client-data privacy constraints and the limited compute available on edge devices. In this work, we introduce TrajSyn, a privacy-preserving framework that enables effective server-side adversarial training by synthesizing a proxy dataset from the trajectories of client model updates, without accessing raw client data. We show that TrajSyn consistently improves adversarial robustness on image classification benchmarks with no extra compute burden on the client device.

</details>


### [192] [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)
*Aaron Mueller,Andrew Lee,Shruti Joshi,Ekdeep Singh Lubana,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: The study evaluates the ability of featurization methods like sparse autoencoders (SAEs) and sparse probes to recover disentangled representations of concepts, finding that current methods struggle with independence and selectivity under increasing correlations.


<details>
  <summary>Details</summary>
Motivation: To assess whether common featurization methods can disentangle causally relevant concepts under realistic conditions where concepts are correlated, moving beyond isolated evaluations.

Method: The study introduces a multi-concept evaluation setting with controlled correlations between textual concepts (e.g., sentiment, domain, tense), analyzing performance as correlations increase. It also conducts steering experiments to test concept manipulability.

Result: Features exhibit a one-to-many relationship with concepts and lack independence or selectivity when steered, even when trained on uniform distributions. Correlational metrics for disentanglement are insufficient for establishing independence.

Conclusion: The findings highlight the need for compositional evaluations in interpretability research, as current methods fall short in achieving disentangled and independently manipulable concept representations.

Abstract: A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.

</details>


### [193] [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)
*Roland Baatz*

Main category: cs.LG

TL;DR: The study compares ML models for crop yield prediction in Germany, highlighting their poor temporal generalization and the unreliability of SHAP feature importance when models don't generalize. It calls for better validation and scrutiny of explainability methods.


<details>
  <summary>Details</summary>
Motivation: To assess the generalization and interpretability of ML models for crop yield prediction, especially focusing on their performance in unseen temporal conditions and the reliability of feature importance explanations.

Method: The study uses ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN) on a high-quality, long-term dataset from Germany's NUTS-3 regions, evaluating their performance on spatially split test sets and temporally independent validation years.

Result: Models perform well on spatial test sets but degrade in temporal validation. SHAP feature importance may appear credible even when models fail to generalize, exposing a vulnerability in explainability methods.

Conclusion: The study emphasizes the need for validation-aware interpretation, domain-aware validation, and hybrid modeling to ensure reliable ML predictions and explainability in agriculture and environmental systems.

Abstract: This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).
  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.
  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?

</details>


### [194] [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)
*Pablo Montaña-Fernández,Ines Ortega-Fernandez*

Main category: cs.LG

TL;DR: The paper introduces a gradient-based membership inference attack in federated learning, exploiting temporal gradient evolution across rounds. It also extends to attribute inference and evaluates its effectiveness on various datasets.


<details>
  <summary>Details</summary>
Motivation: To highlight vulnerabilities in federated learning, where model updates can leak sensitive information despite privacy improvements.

Method: Uses a shadow technique to analyze round-wise gradient patterns without accessing private data, targeting semi-honest and malicious adversaries.

Result: Strong attack performance on CIFAR-100 and Purchase100 for membership inference, and Breast Cancer Wisconsin for attribute inference.

Conclusion: Multi-round federated learning increases vulnerability, aggregators pose greater threats, and dataset complexity affects leakage.

Abstract: Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.

</details>


### [195] [Tracking Temporal Dynamics of Vector Sets with Gaussian Process](https://arxiv.org/abs/2512.15538)
*Taichi Aida,Mamoru Komachi,Toshinobu Ogiso,Hiroya Takamura,Daichi Mochihashi*

Main category: cs.LG

TL;DR: Proposes a novel method using infinite-dimensional Gaussian processes to model evolving sets of vectors, enabling interpretable and robust temporal analysis.


<details>
  <summary>Details</summary>
Motivation: Understanding the temporal evolution of vector sets (e.g., ecosystems, crime distributions, word embeddings) is challenging due to their complex, time-varying structures.

Method: Uses infinite-dimensional Gaussian processes approximated with Random Fourier Features to derive compact, comparable vector representations.

Result: Successfully tracks and visualizes temporal transitions in low-dimensional space, validated on sociological and linguistic data.

Conclusion: The method provides interpretable and robust representations for analyzing structural changes in temporally indexed vector sets across domains.

Abstract: Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.

</details>


### [196] [Understanding NTK Variance in Implicit Neural Representations](https://arxiv.org/abs/2512.15169)
*Chengguang Ou,Yixin Zhuang*

Main category: cs.LG

TL;DR: The paper analyzes how architectural choices in Implicit Neural Representations (INRs) affect Neural Tangent Kernel (NTK) conditioning, explaining how components like positional encoding and Hadamard modulation improve spectral bias and convergence.


<details>
  <summary>Details</summary>
Motivation: The study aims to clarify why INRs often converge slowly and fail to capture high-frequency details, linking these issues to NTK conditioning and architectural choices.

Method: The authors derive closed-form variance decompositions for common INR components (e.g., positional encoding, spherical normalization, Hadamard modulation) and analyze their impact on NTK eigenvalue variance.

Result: Experiments show that architectural improvements reduce NTK eigenvalue variance, leading to faster convergence and better reconstruction quality across tasks.

Conclusion: The work provides a unified framework explaining how diverse INR architectures mitigate spectral bias by optimizing NTK conditioning.

Abstract: Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.

</details>


### [197] [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)
*Zicong Cheng,Guo-Wei Yang,Jia Li,Zhijie Deng,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.LG

TL;DR: DEER introduces a diffusion-based speculative decoding framework to overcome limitations of autoregressive (AR) drafters, achieving longer draft acceptance lengths and higher speedups.


<details>
  <summary>Details</summary>
Motivation: Autoregressive decoding's latency and uncertainty accumulation limit efficiency in LLM-driven systems. Diffusion-based drafters offer parallel decoding and better alignment.

Method: DEER uses diffusion large language models (dLLMs) for drafting and AR models for verification, employing a two-stage training pipeline and single-step decoding for long drafts.

Result: DEER achieves draft acceptance lengths of up to 32 tokens (vs. 10 in EAGLE-3) and a 5.54x speedup on HumanEval (vs. 2.41x for EAGLE-3).

Conclusion: Diffusion-based drafters significantly improve speculative decoding efficiency, outperforming AR-based approaches.

Abstract: Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/

</details>


### [198] [Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT](https://arxiv.org/abs/2512.15206)
*Liyu Zhang,Yejia Liu,Kwun Ho Liu,Runxi Huang,Xiaomin Ouyang*

Main category: cs.LG

TL;DR: Chorus is a context-aware, data-free model customization approach that adapts models to unseen deployment conditions by learning and integrating robust context representations, outperforming baselines by up to 11.3%.


<details>
  <summary>Details</summary>
Motivation: Traditional domain adaptation methods often ignore or simplistically integrate context information, making them ineffective for dynamic IoT environments.

Method: Chorus learns context representations via cross-modal reconstruction, trains a gated head to balance sensor and context contributions, and uses a caching mechanism to reduce latency.

Result: Experiments show Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts while maintaining low latency on edge devices.

Conclusion: Chorus effectively addresses context shifts in IoT applications without requiring target-domain data, demonstrating superior performance and efficiency.

Abstract: In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.

</details>


### [199] [Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures](https://arxiv.org/abs/2512.15228)
*Songze Huo,Xiao-Ming Cao*

Main category: cs.LG

TL;DR: DBCata, a deep generative model, improves adsorption energy predictions by generating high-fidelity geometries without explicit energy/force data, outperforming current MLIP models and aiding catalyst screening.


<details>
  <summary>Details</summary>
Motivation: The limited distribution of training data from near-equilibrium structures in MLIPs leads to unreliable adsorption energy predictions, necessitating a more accurate method.

Method: DBCata combines a periodic Brownian-bridge framework with an equivariant graph neural network to model transitions between unrelaxed and DFT-relaxed structures.

Result: Achieves a DMAE of 0.035 Å, outperforming state-of-the-art models, and improves DFT accuracy within 0.1 eV in 94% of cases via outlier detection.

Conclusion: DBCata's performance enhances high-throughput screening for alloy catalysts, showcasing its potential in catalyst design.

Abstract: The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unreliable adsorption structures and consequent adsorption energy predictions. In this context, we present DBCata, a deep generative model that integrates a periodic Brownian-bridge framework with an equivariant graph neural network to establish a low-dimensional transition manifold between unrelaxed and DFT-relaxed structures, without requiring explicit energy or force information. Upon training, DBCata effectively generates high-fidelity adsorption geometries, achieving an interatomic distance mean absolute error (DMAE) of 0.035 \textÅ on the Catalysis-Hub dataset, which is nearly three times superior to that of the current state-of-the-art machine learning potential models. Moreover, the corresponding DFT accuracy can be improved within 0.1 eV in 94\% of instances by identifying and refining anomalous predictions through a hybrid chemical-heuristic and self-supervised outlier detection approach. We demonstrate that the remarkable performance of DBCata facilitates accelerated high-throughput computational screening for efficient alloy catalysts in the oxygen reduction reaction, highlighting the potential of DBCata as a powerful tool for catalyst design and optimisation.

</details>


### [200] [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)
*Elio Gruttadauria,Mathieu Fontaine,Jonathan Le Roux,Slim Essid*

Main category: cs.LG

TL;DR: O-EENC-SD is an efficient, hyperparameter-free online speaker diarization system leveraging EEND-EDA and a novel RNN-based stitching mechanism, showing competitive performance with low complexity.


<details>
  <summary>Details</summary>
Motivation: To address inefficiencies and hyperparameter reliance in current online speaker diarization methods, particularly in computational cost and clustering approaches.

Method: Develops an end-to-end system using EEND-EDA, introduces an RNN-based stitching mechanism and centroid refinement decoder, and validates through ablation studies.

Result: Competitive performance on CallHome dataset, offering a balance between diarization error rate (DER) and computational complexity.

Conclusion: O-EENC-SD provides an efficient and effective solution for online speaker diarization, outperforming existing methods in simplicity and computational efficiency.

Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

</details>


### [201] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: The paper introduces a method for integrating ECG and EEG signals using self-supervised pre-training and simple fusion, achieving near state-of-the-art performance in emotion recognition.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of multi-modal integration of physiological signals (ECG and EEG) due to limited labeled data and modality-specific differences.

Method: The method involves adapting the CBraMod encoder for ECG pre-training with a dual-masking strategy, pre-training a symmetric ECG encoder, and fusing representations via simple embedding concatenation.

Result: The approach achieves near state-of-the-art performance in emotion recognition tasks.

Conclusion: The results demonstrate the potential of foundation-model approaches for scalable and label-efficient solutions in healthcare and affective computing.

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [202] [Distillation-Guided Structural Transfer for Continual Learning Beyond Sparse Distributed Memory](https://arxiv.org/abs/2512.15267)
*Huiyan Xue,Xuming Ran,Yaxin Li,Qi Xu,Enhui Li,Yi Xu,Qiang Zhang*

Main category: cs.LG

TL;DR: The paper introduces Selective Subnetwork Distillation (SSD), a method for improving sparse neural systems in continual learning by selectively distilling knowledge within task-specific subnetworks, enhancing accuracy and retention.


<details>
  <summary>Details</summary>
Motivation: Sparse neural systems like SDMLPs are efficient for continual learning but suffer from rigid modularity, limiting cross-task knowledge reuse and degrading performance under high sparsity.

Method: SSD identifies frequently activated neurons and selectively distills knowledge within Top-K subnetworks and output logits, enabling structural realignment without replay or task labels.

Result: Experiments on Split CIFAR-10, CIFAR-100, and MNIST show that SSD improves accuracy, retention, and representation coverage in sparse continual learning.

Conclusion: SSD provides a structurally grounded solution for sparse continual learning by balancing modularity and knowledge reuse through selective distillation.

Abstract: Sparse neural systems are gaining traction for efficient continual learning due to their modularity and low interference. Architectures such as Sparse Distributed Memory Multi-Layer Perceptrons (SDMLP) construct task-specific subnetworks via Top-K activation and have shown resilience against catastrophic forgetting. However, their rigid modularity limits cross-task knowledge reuse and leads to performance degradation under high sparsity. We propose Selective Subnetwork Distillation (SSD), a structurally guided continual learning framework that treats distillation not as a regularizer but as a topology-aligned information conduit. SSD identifies neurons with high activation frequency and selectively distills knowledge within previous Top-K subnetworks and output logits, without requiring replay or task labels. This enables structural realignment while preserving sparse modularity. Experiments on Split CIFAR-10, CIFAR-100, and MNIST demonstrate that SSD improves accuracy, retention, and representation coverage, offering a structurally grounded solution for sparse continual learning.

</details>


### [203] [Topological Metric for Unsupervised Embedding Quality Evaluation](https://arxiv.org/abs/2512.15285)
*Aleksei Shestov,Anton Klenitskiy,Daria Denisova,Amurkhan Dzagkoev,Daniil Petrovich,Andrey Savchenko,Maksim Makarenko*

Main category: cs.LG

TL;DR: Proposes Persistence, a topology-aware metric for unsupervised evaluation of embeddings using persistent homology, outperforming existing methods in capturing geometric structure and correlating with downstream performance.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of evaluating embedding quality without labels, especially in unsupervised and self-supervised learning.

Method: Develops Persistence, a metric based on persistent homology, to quantify geometric and topological structure in embedding spaces.

Result: Persistence achieves top-tier correlations with downstream performance across diverse domains, outperforming existing unsupervised metrics.

Conclusion: Persistence provides a reliable, unsupervised solution for evaluating embedding quality and selecting models/hyperparameters.

Abstract: Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.

</details>


### [204] [Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions](https://arxiv.org/abs/2512.15286)
*Siva Sai,Ishika Goyal,Shubham Sharma,Sri Harshita Manuri,Vinay Chamola,Rajkumar Buyya*

Main category: cs.LG

TL;DR: Quantum Machine Learning (QML) offers improved solutions for cybersecurity tasks like intrusion detection and malware classification, surpassing classical methods.


<details>
  <summary>Details</summary>
Motivation: Classical machine learning fails against evolving cyber threats, prompting exploration of QML for better security solutions.

Method: Survey of QML techniques (QNNs, QSVMs, VQCs, QGANs) applied to cybersecurity tasks across supervised, unsupervised, and generative learning.

Result: QML enhances cybersecurity tasks but faces limitations needing further research.

Conclusion: QML shows promise in cybersecurity but requires addressing current limitations for broader application.

Abstract: The increasing number of cyber threats and rapidly evolving tactics, as well as the high volume of data in recent years, have caused classical machine learning, rules, and signature-based defence strategies to fail, rendering them unable to keep up. An alternative, Quantum Machine Learning (QML), has recently emerged, making use of computations based on quantum mechanics. It offers better encoding and processing of high-dimensional structures for certain problems. This survey provides a comprehensive overview of QML techniques relevant to the domain of security, such as Quantum Neural Networks (QNNs), Quantum Support Vector Machines (QSVMs), Variational Quantum Circuits (VQCs), and Quantum Generative Adversarial Networks (QGANs), and discusses the contributions of this paper in relation to existing research in the field and how it improves over them. It also maps these methods across supervised, unsupervised, and generative learning paradigms, and to core cybersecurity tasks, including intrusion and anomaly detection, malware and botnet classification, and encrypted-traffic analytics. It also discusses their application in the domain of cloud computing security, where QML can enhance secure and scalable operations. Many limitations of QML in the domain of cybersecurity have also been discussed, along with the directions for addressing them.

</details>


### [205] [Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference](https://arxiv.org/abs/2512.15335)
*Chenxiang Zhang,Tongxi Qu,Zhong Li,Tian Zhang,Jun Pang,Sjouke Mauw*

Main category: cs.LG

TL;DR: The paper investigates how quantization affects privacy leakage in deep neural networks, showing that lower precision reduces vulnerability to membership inference attacks, albeit with utility trade-offs.


<details>
  <summary>Details</summary>
Motivation: Existing privacy analyses focus on full-precision models, leaving a gap in understanding quantization's impact on privacy.

Method: Analyzed three PTQ algorithms (AdaRound, BRECQ, OBC) across multiple precision levels (4-bit, 2-bit, 1.58-bit) on CIFAR-10, CIFAR-100, and TinyImageNet datasets using membership inference attacks.

Result: Lower-precision PTQs reduce privacy leakage significantly (up to an order of magnitude) but decrease utility. Quantizing only the last layer at higher precision allows finer privacy-utility control.

Conclusion: Practitioners can use PTQ to balance efficiency, utility, and privacy, with lower precision offering improved privacy protection.

Abstract: Deep neural networks are widely deployed with quantization techniques to reduce memory and computational costs by lowering the numerical precision of their parameters. While quantization alters model parameters and their outputs, existing privacy analyses primarily focus on full-precision models, leaving a gap in understanding how bit-width reduction can affect privacy leakage. We present the first systematic study of the privacy-utility relationship in post-training quantization (PTQ), a versatile family of methods that can be applied to pretrained models without further training. Using membership inference attacks as our evaluation framework, we analyze three popular PTQ algorithms-AdaRound, BRECQ, and OBC-across multiple precision levels (4-bit, 2-bit, and 1.58-bit) on CIFAR-10, CIFAR-100, and TinyImageNet datasets. Our findings consistently show that low-precision PTQs can reduce privacy leakage. In particular, lower-precision models demonstrate up to an order of magnitude reduction in membership inference vulnerability compared to their full-precision counterparts, albeit at the cost of decreased utility. Additional ablation studies on the 1.58-bit quantization level show that quantizing only the last layer at higher precision enables fine-grained control over the privacy-utility trade-off. These results offer actionable insights for practitioners to balance efficiency, utility, and privacy protection in real-world deployments.

</details>


### [206] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: The paper introduces two phase-aware preprocessing methods for vibration signals in predictive maintenance, improving deep learning model performance by addressing random phase variations.


<details>
  <summary>Details</summary>
Motivation: Existing approaches discard phase or don't leverage it effectively in vibration signal analysis for predictive maintenance.

Method: Two preprocessing strategies are proposed: three-axis independent phase adjustment and single-axis reference phase adjustment. They are tested on a rotor dataset using six deep learning models.

Result: Both methods improve performance: the three-axis approach boosts accuracy consistently (+2.7%), while the single-axis method achieves up to 96.2% accuracy (+5.4%).

Conclusion: Phase alignment strategies are practical and scalable enhancements for predictive maintenance systems.

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [207] [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)
*Honey Singh Chauhan,Zahraa S. Abdallah*

Main category: cs.LG

TL;DR: Fusion-3 (F3), a lightweight framework combining Rocket, Sax, and Sfa representations, improves time series classification by selectively fusing representations based on dataset meta-features.


<details>
  <summary>Details</summary>
Motivation: To address the inconsistent performance of kernel-based methods like Rocket across different datasets by leveraging complementary representations.

Method: Introduces F3, which adaptively fuses Rocket, Sax, and Sfa representations. Uses meta-features to cluster datasets and identify regimes where fusion is beneficial.

Result: Fusion outperforms baselines in datasets with structured variability or rich frequency content. Provides consistent small improvements over Rocket on UCR datasets.

Conclusion: Selective fusion enhances kernel-based methods by correcting weaknesses in specific data regimes, offering interpretable and dependable improvements.

Abstract: Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.

</details>


### [208] [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)
*Julian Oelhaf,Mehran Pashaei,Georg Kordowich,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: The paper introduces a framework for evaluating ML model robustness in power system protection, using EMT simulations to test scenarios like sensor failures and communication losses. Results highlight FC's stability and FL's sensitivity to data degradation.


<details>
  <summary>Details</summary>
Motivation: The rise of renewable energy challenges traditional protection schemes, necessitating robust ML solutions for fault classification and localization in power systems.

Method: High-fidelity EMT simulations model sensor outages, reduced sampling rates, and transient communication losses to benchmark ML models under degraded conditions.

Result: Fault classification remains stable except for a 13% drop under single-phase loss, while fault localization is more sensitive, with voltage loss causing over 150% error increase.

Conclusion: The framework provides actionable insights for designing robustness-aware ML-assisted protection systems.

Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.
  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

</details>


### [209] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: EUBRL, a Bayesian RL algorithm, uses epistemic guidance for exploration, achieving optimal regret bounds and superior empirical performance in sparse-reward tasks.


<details>
  <summary>Details</summary>
Motivation: Addresses the exploration-exploitation dilemma in RL by leveraging epistemic uncertainty to reduce regret from estimation errors.

Method: Proposes the EUBRL algorithm, which uses Bayesian principles and adaptive epistemic guidance for exploration in infinite-horizon discounted MDPs.

Result: Establishes near-minimax-optimal regret and sample complexity guarantees; empirically shows better sample efficiency, scalability, and consistency.

Conclusion: EUBRL effectively balances exploration and exploitation, outperforming alternatives in challenging RL tasks.

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>


### [210] [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)
*Yeonwoo Cha,Semin Kim,Jinhyeon Kwon,Seunghoon Hong*

Main category: cs.LG

TL;DR: FlowBind is an efficient framework for any-to-any cross-modal generation, reducing data needs and computational costs while maintaining quality.


<details>
  <summary>Details</summary>
Motivation: Existing flow-based approaches face inefficiency due to large datasets, high computational costs, and complex training.

Method: FlowBind uses a shared latent space and modality-specific invertible flows, optimized jointly under a flow-matching objective.

Result: FlowBind achieves comparable quality with fewer parameters (up to 6x) and faster training (10x) than prior methods.

Conclusion: FlowBind offers a simpler, more efficient solution for cross-modal generation, validated across text, image, and audio.

Abstract: Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.

</details>


### [211] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada,Shu Tanaka*

Main category: cs.LG

TL;DR: The study examines min-max normalized eigenvalues in random matrices, evaluates their scaling law, and derives residual errors in matrix factorization, supported by numerical experiments.


<details>
  <summary>Details</summary>
Motivation: Understanding the statistical properties of normalized eigenvalues is crucial for data science applications where input data is often normalized.

Method: The study applies a previously proposed distribution for normalized eigenvalues, evaluates scaling laws, and derives residual errors in matrix factorization, verifying results numerically.

Result: Theoretical predictions about scaling laws and residual errors in matrix factorization are confirmed through numerical experiments.

Conclusion: The findings provide insights into the behavior of normalized eigenvalues in random matrices, with implications for data science and machine learning.

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [212] [FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments](https://arxiv.org/abs/2512.15430)
*Quanxi Zhou,Wencan Mao,Manabu Tsukada,John C. S. Lui,Yusheng Ji*

Main category: cs.LG

TL;DR: FM-EAC integrates MBRL and MFRL strengths for multi-task control, outperforming state-of-the-art methods in simulations and offering customizable sub-networks.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the limitation of ineffective transferability across tasks and scenarios in modern RL methods.

Method: FM-EAC combines MBRL and MFRL, using feature-based models and an enhanced actor-critic framework for planning, acting, and learning.

Result: Simulations show FM-EAC outperforms many MBRL and MFRL methods in urban and agricultural applications.

Conclusion: FM-EAC offers improved generalizability and customizable sub-networks, making it versatile for dynamic environments.

Abstract: Model-based reinforcement learning (MBRL) and model-free reinforcement learning (MFRL) evolve along distinct paths but converge in the design of Dyna-Q [1]. However, modern RL methods still struggle with effective transferability across tasks and scenarios. Motivated by this limitation, we propose a generalized algorithm, Feature Model-Based Enhanced Actor-Critic (FM-EAC), that integrates planning, acting, and learning for multi-task control in dynamic environments. FM-EAC combines the strengths of MBRL and MFRL and improves generalizability through the use of novel feature-based models and an enhanced actor-critic framework. Simulations in both urban and agricultural applications demonstrate that FM-EAC consistently outperforms many state-of-the-art MBRL and MFRL methods. More importantly, different sub-networks can be customized within FM-EAC according to user-specific requirements.

</details>


### [213] [Double Horizon Model-Based Policy Optimization](https://arxiv.org/abs/2512.15439)
*Akihiro Kubo,Paavo Parmas,Shin Ishii*

Main category: cs.LG

TL;DR: DHMBPO introduces a double-horizon approach (long DR and short TR) in MBRL to balance distribution shift, model bias, and gradient instability, outperforming existing methods in sample efficiency and runtime.


<details>
  <summary>Details</summary>
Motivation: Existing MBRL methods face dilemmas in choosing rollout lengths: longer rollouts mitigate distribution shift but increase model bias and gradient variance. Balancing these trade-offs is challenging.

Method: DHMBPO splits rollouts into a long 'distribution rollout' (DR) for on-policy samples and a short 'training rollout' (TR) for stable gradient estimation, optimizing both objectives separately.

Result: The double-horizon approach effectively balances trade-offs, achieving better performance in continuous-control benchmarks compared to existing MBRL methods.

Conclusion: DHMBPO successfully resolves the conflict between distribution shift and gradient stability, enhancing sample efficiency and reducing runtime in MBRL.

Abstract: Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long "distribution rollout" (DR) and a short "training rollout" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.

</details>


### [214] [Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting](https://arxiv.org/abs/2512.15442)
*Neeraj Sarna,Yuanyuan Li,Michael von Gablenz*

Main category: cs.LG

TL;DR: The paper explores using chain-of-thought and task instruction prompting, along with negative prompting and prompt re-writing, to reduce copyrighted content generation in text-to-image models.


<details>
  <summary>Details</summary>
Motivation: To mitigate copyright infringement risks posed by large-scale text-to-image models memorizing and reproducing copyrighted training data, potentially avoiding legal liabilities and financial losses.

Method: Combines chain-of-thought and task instruction prompting with negative prompting and prompt re-writing strategies. Evaluates generated images for similarity to copyrighted content and relevance to user input.

Result: Presents numerical experiments across various models, analyzing the effectiveness of the techniques relative to model complexity.

Conclusion: Provides insights into how combining these techniques can help reduce copyrighted content generation in text-to-image models.

Abstract: Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.

</details>


### [215] [From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning](https://arxiv.org/abs/2512.15460)
*Xiangrui Xu,Zhize Li,Yufei Han,Bin Wang,Jiqiang Liu,Wei Wang*

Main category: cs.LG

TL;DR: The paper introduces Invertibility Loss (InvLoss) to quantify the risk of Data Reconstruction Attacks (DRAs) in Federated Learning (FL) systems, provides a theoretical framework, and proposes practical defenses.


<details>
  <summary>Details</summary>
Motivation: To address the unresolved question of characterizing and assessing DRA risk in FL systems due to the lack of a theoretically-grounded quantification framework.

Method: Introduces InvLoss to measure DRA effectiveness, derives an upper bound, and explores its implications through spectral properties of Jacobian matrices, risk estimation (InvRE), and adaptive noise defenses.

Result: Demonstrates that DRA risk is governed by Jacobian matrix properties, offers a unified risk evaluation method (InvRE), and validates defenses that maintain accuracy while enhancing privacy.

Conclusion: The framework enables systematic DRA risk assessment and mitigation in FL systems, supported by experiments on real-world datasets.

Abstract: Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.

</details>


### [216] [Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance](https://arxiv.org/abs/2512.15469)
*Ioannis Kalogeropoulos,Giorgos Bouritsas,Yannis Panagakis*

Main category: cs.LG

TL;DR: A framework for editing neural networks efficiently to meet diverse requirements without sacrificing performance, using a graph metanetwork trained to balance utility and requirement satisfaction.


<details>
  <summary>Details</summary>
Motivation: Machine learning models in high-stakes settings must meet various requirements (e.g., fairness, compliance) beyond performance, but current methods (post-processing, re-training) often compromise performance or are inefficient.

Method: A data-driven framework where a graph metanetwork (itself an NN) is trained on NN populations to edit models in a single inference step, balancing requirement enforcement and utility preservation.

Result: Improved trade-offs between performance, requirement satisfaction, and efficiency for tasks like data minimization, bias mitigation, and weight pruning compared to existing methods.

Conclusion: The proposed framework offers a scalable and efficient solution for editing NNs to meet diverse requirements without significant performance loss.

Abstract: As machine learning models are increasingly deployed in high-stakes settings, e.g. as decision support systems in various societal sectors or in critical infrastructure, designers and auditors are facing the need to ensure that models satisfy a wider variety of requirements (e.g. compliance with regulations, fairness, computational constraints) beyond performance. Although most of them are the subject of ongoing studies, typical approaches face critical challenges: post-processing methods tend to compromise performance, which is often counteracted by fine-tuning or, worse, training from scratch, an often time-consuming or even unavailable strategy. This raises the following question: "Can we efficiently edit models to satisfy requirements, without sacrificing their utility?" In this work, we approach this with a unifying framework, in a data-driven manner, i.e. we learn to edit neural networks (NNs), where the editor is an NN itself - a graph metanetwork - and editing amounts to a single inference step. In particular, the metanetwork is trained on NN populations to minimise an objective consisting of two terms: the requirement to be enforced and the preservation of the NN's utility. We experiment with diverse tasks (the data minimisation principle, bias mitigation and weight pruning) improving the trade-offs between performance, requirement satisfaction and time efficiency compared to popular post-processing or re-training alternatives.

</details>


### [217] [Multi-stage Bayesian optimisation for dynamic decision-making in self-driving labs](https://arxiv.org/abs/2512.15483)
*Luca Torresi,Pascal Friederich*

Main category: cs.LG

TL;DR: The paper proposes an extension to Bayesian optimization for self-driving labs, enabling flexible multi-stage workflows and decision-making using intermediate proxy measurements, leading to faster and better solutions.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of standard Bayesian optimization in self-driving labs, which excludes real-time workflow adjustments and intermediate measurements.

Method: Introduces an extension to Bayesian optimization incorporating proxy measurements and flexible multi-stage workflows.

Result: Proxy measurements significantly improve solution speed and optimality compared to conventional methods.

Conclusion: The approach enhances realism in experimental workflows and facilitates integration of simulations and experiments in self-driving labs.

Abstract: Self-driving laboratories (SDLs) are combining recent technological advances in robotics, automation, and machine learning based data analysis and decision-making to perform autonomous experimentation toward human-directed goals without requiring any direct human intervention. SDLs are successfully used in materials science, chemistry, and beyond, to optimise processes, materials, and devices in a systematic and data-efficient way. At present, the most widely used algorithm to identify the most informative next experiment is Bayesian optimisation. While relatively simple to apply to a wide range of optimisation problems, standard Bayesian optimisation relies on a fixed experimental workflow with a clear set of optimisation parameters and one or more measurable objective functions. This excludes the possibility of making on-the-fly decisions about changes in the planned sequence of operations and including intermediate measurements in the decision-making process. Therefore, many real-world experiments need to be adapted and simplified to be converted to the common setting in self-driving labs. In this paper, we introduce an extension to Bayesian optimisation that allows flexible sampling of multi-stage workflows and makes optimal decisions based on intermediate observables, which we call proxy measurements. We systematically compare the advantage of taking into account proxy measurements over conventional Bayesian optimisation, in which only the final measurement is observed. We find that over a wide range of scenarios, proxy measurements yield a substantial improvement, both in the time to find good solutions and in the overall optimality of found solutions. This not only paves the way to use more complex and thus more realistic experimental workflows in autonomous labs but also to smoothly combine simulations and experiments in the next generation of SDLs.

</details>


### [218] [Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier](https://arxiv.org/abs/2512.15492)
*Adrián Detavernier,Jasper De Bock*

Main category: cs.LG

TL;DR: The paper compares Robustness Quantification (RQ) and Uncertainty Quantification (UQ) for classifier reliability, finding them complementary. A hybrid approach outperforms both, also assessing their relative importance.


<details>
  <summary>Details</summary>
Motivation: To evaluate the reliability of individual classifier predictions by comparing two distinct methods: RQ and UQ.

Method: Comparison of RQ and UQ on benchmark datasets, leading to a hybrid approach combining both.

Result: No clear winner between RQ and UQ; hybrid approach outperforms both, with insights into their relative importance.

Conclusion: RQ and UQ are complementary; combining them enhances reliability assessment.

Abstract: We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.

</details>


### [219] [Soft Geometric Inductive Bias for Object Centric Dynamics](https://arxiv.org/abs/2512.15493)
*Hampus Linander,Conor Heins,Alexander Tschantz,Marco Perin,Christopher Buckley*

Main category: cs.LG

TL;DR: Soft geometric inductive bias using geometric algebra neural networks improves physical fidelity in simulating 2D rigid body dynamics compared to non-equivariant models.


<details>
  <summary>Details</summary>
Motivation: Equivariance is valuable for learning physical dynamics but exact symmetry can degrade performance when broken. Soft geometric priors offer robustness.

Method: Object-centric world models built with geometric algebra neural networks, trained autoregressively for next-step predictions in simulated 2D rigid body environments.

Result: Better performance in long-horizon rollouts with higher physical fidelity compared to non-equivariant baselines.

Conclusion: Geometric algebra provides a balanced middle ground between structured physics and unstructured deep learning, enhancing sample-efficient dynamics modeling.

Abstract: Equivariance is a powerful prior for learning physical dynamics, yet exact group equivariance can degrade performance if the symmetries are broken. We propose object-centric world models built with geometric algebra neural networks, providing a soft geometric inductive bias. Our models are evaluated using simulated environments of 2d rigid body dynamics with static obstacles, where we train for next-step predictions autoregressively. For long-horizon rollouts we show that the soft inductive bias of our models results in better performance in terms of physical fidelity compared to non-equivariant baseline models. The approach complements recent soft-equivariance ideas and aligns with the view that simple, well-chosen priors can yield robust generalization. These results suggest that geometric algebra offers an effective middle ground between hand-crafted physics and unstructured deep nets, delivering sample-efficient dynamics models for multi-object scenes.

</details>


### [220] [Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation](https://arxiv.org/abs/2512.15574)
*Yuxin Cai,Yanyong Huang,Jinyuan Chang,Dongjie Wang,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: JUICE is a novel co-selection method that integrates missing data imputation and feature-instance co-selection in a unified framework for unlabeled incomplete multi-view data, leveraging cross-view interactions for better performance.


<details>
  <summary>Details</summary>
Motivation: Existing methods treat co-selection and missing data imputation separately, ignoring their interactions and complementary multi-view information, limiting effectiveness.

Method: JUICE jointly learns feature-instance co-selection and cross-view imputation by reconstructing incomplete multi-view data and refining imputation using cross-view neighborhood information.

Result: JUICE outperforms state-of-the-art methods in selecting representative features and instances.

Conclusion: JUICE successfully integrates imputation and co-selection, leveraging multi-view interactions for superior performance.

Abstract: Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.

</details>


### [221] [Corrective Diffusion Language Models](https://arxiv.org/abs/2512.15596)
*Shuibai Zhang,Fred Zhangzhi Peng,Yiheng Zhang,Jin Pan,Grigorios G. Chrysos*

Main category: cs.LG

TL;DR: The paper addresses the issue of diffusion language models struggling with iterative error correction due to unreliable token identification. It proposes a correction-oriented training approach to improve error-aware confidence and targeted refinement.


<details>
  <summary>Details</summary>
Motivation: Standard masked diffusion language models fail to reliably correct errors because they often cannot identify unreliable tokens, limiting their effectiveness in iterative refinement.

Method: The authors introduce a correction-oriented post-training principle that supervises visible incorrect tokens to enhance error-aware confidence and targeted refinement.

Result: Models trained with the new approach outperform standard MDLMs in correction scenarios and also improve completion performance, as demonstrated on code revision tasks.

Conclusion: The proposed method effectively enhances the corrective behavior of diffusion language models, making them more reliable for iterative error correction.

Abstract: Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.

</details>


### [222] [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)
*Alexandre Dussolle,Pietro Liò*

Main category: cs.LG

TL;DR: The paper introduces N-simplicial attention for higher-order interactions beyond pairwise similarity, adapting Rotary Position Embeddings (RoPE) and proposing cost-effective simplex selection. It also analyzes its smoothing properties and over-smoothing issues.


<details>
  <summary>Details</summary>
Motivation: To advance beyond existing graph message-passing mechanisms like GATs and Transformers by incorporating higher-order interactions and managing computational complexity.

Method: Introduces N-simplicial attention, adapts RoPE, and proposes simplex selection for computational efficiency. Analyzes smoothing via Lipschitz bounds and over-smoothing.

Result: Demonstrates potential improvements but highlights challenges like over-smoothing despite higher-order interactions.

Conclusion: N-simplicial attention offers a promising direction but requires careful handling of computational and smoothing trade-offs.

Abstract: Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.

</details>


### [223] [Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction](https://arxiv.org/abs/2512.15605)
*Mathieu Blondel,Michael E. Sander,Germain Vivier-Ardisson,Tianlin Liu,Vincent Roulet*

Main category: cs.LG

TL;DR: The paper unifies autoregressive models (ARMs) and energy-based models (EBMs) by establishing a bijection between them, linking their equivalence in supervised learning and analyzing EBM-to-ARM distillation.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between ARMs and EBMs, providing a unified theoretical framework to understand their roles in large language models and alignment.

Method: The study uses the chain rule of probability to establish a bijection between ARMs and EBMs, connects this to maximum entropy reinforcement learning, and derives equivalence in supervised learning and distillation.

Result: The paper shows a theoretical equivalence between ARMs and EBMs, providing error bounds for distillation and insights into ARMs' planning capabilities.

Conclusion: The unified view enhances understanding of ARMs and EBMs, revealing their equivalence and practical implications for model alignment and planning.

Abstract: Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.

</details>


### [224] [Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary](https://arxiv.org/abs/2512.15614)
*Xinshun Feng,Mingzhe Liu,Yi Qiao,Tongyu Zhu,Leilei Sun,Shuai Wang*

Main category: cs.LG

TL;DR: BEAT is a framework that tokenizes user-item behaviors into interpretable sequences, improving explainability and performance in recommendations.


<details>
  <summary>Details</summary>
Motivation: Existing methods rely on ID-based representations, limiting semantic understanding and applicability in open-ended scenarios.

Method: BEAT uses vector-quantized autoencoding to create behavior tokens and aligns them with language models via semantic supervision.

Result: BEAT enhances zero-shot recommendation performance and generates coherent explanations, capturing fine-grained semantics.

Conclusion: BEAT provides a transferable solution for integrating behavior patterns into language models, improving explainable recommendations.

Abstract: Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.

</details>


### [225] [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)
*Tianze Luo,Haotian Yuan,Zhuang Liu*

Main category: cs.LG

TL;DR: SoFlow introduces a framework for one-step generation by analyzing velocity-solution relationships in ODEs, using Flow Matching and solution consistency losses without Jacobian-vector products.


<details>
  <summary>Details</summary>
Motivation: Addressing efficiency issues in multi-step denoising processes of diffusion and Flow Matching models motivates research into few-step generation.

Method: Proposes Flow Matching and solution consistency losses to train models, avoiding Jacobian-vector product calculations.

Result: SoFlow achieves better FID-50K scores than MeanFlow on ImageNet 256x256 with the same DiT architecture and training epochs.

Conclusion: SoFlow offers efficient one-step generation with improved performance compared to existing methods.

Abstract: The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.

</details>


### [226] [A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks](https://arxiv.org/abs/2512.15685)
*Oleg Melnikov,Yurii Dorofieiev,Yurii Shakhnovskiy,Huy Truong,Victoria Degeler*

Main category: cs.LG

TL;DR: SICAMS detects, classifies, and localizes anomalies in water networks using multivariate statistics, achieving high sensitivity without needing a hydraulic model.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of anomaly detection and classification in water distribution networks efficiently and reliably.

Method: Uses SICAMS framework with whitening transformation, Hotelling's $T^2$ statistic, and heuristic algorithms for anomaly detection and classification.

Result: Demonstrated high sensitivity and reliability in leak detection using the BattLeDIM L-Town dataset, even under multiple leaks.

Conclusion: SICAMS is effective for real-world water network monitoring without requiring calibrated hydraulic models.

Abstract: This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall "health" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.

</details>


### [227] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2512.15687)
*Zhenwen Liang,Sidi Lu,Wenhao Yu,Kishan Panaganti,Yujun Zhou,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: G2RL introduces a gradient-guided reinforcement learning framework for large language models, aligning exploration with the model's update geometry, outperforming traditional methods in reasoning benchmarks.


<details>
  <summary>Details</summary>
Motivation: Current reinforcement learning exploration mechanisms for large language models are misaligned with how these models learn, relying on surface-level variation without ensuring meaningful gradient updates.

Method: G2RL uses the model's first-order update geometry to guide exploration, measuring trajectory novelty via gradient direction comparisons and rewarding updates that introduce novel directions while deemphasizing redundant ones.

Result: G2RL improves performance metrics (pass@1, maj@16, pass@k) across math and reasoning benchmarks on Qwen3 models, expanding exploration into orthogonal gradient directions while maintaining semantic coherence.

Conclusion: The policy's update space is a more effective basis for guiding exploration in large language model reinforcement learning, as demonstrated by G2RL's superior performance and alignment with optimization dynamics.

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

</details>


### [228] [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)
*Matin Mortaheb,Erciyes Karakaya,Sennur Ulukus*

Main category: cs.LG

TL;DR: Proposes a multi-modal semantic communication framework integrating text queries to guide information extraction, improving efficiency in complex scenes.


<details>
  <summary>Details</summary>
Motivation: Current transformer-based approaches lack explicit task guidance in complex scenes with multiple objects, reducing their effectiveness.

Method: Uses cross-modal attention to fuse visual features with language embeddings, generating relevance scores. Adaptive resolution transmission matches channel capacity.

Result: Enables efficient semantic communication by preserving task-critical information in bandwidth-constrained environments.

Conclusion: The framework offers flexible, goal-driven communication, addressing limitations of existing methods.

Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

</details>


### [229] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://arxiv.org/abs/2512.15699)
*Qiuyang Mang,Wenhao Chai,Zhifei Li,Huanzhi Mao,Shang Zhou,Alexander Du,Hanchen Li,Shu Liu,Edwin Chen,Yichuan Wang,Xieting Chu,Zerui Cheng,Yuan Xu,Tian Xia,Zirui Wang,Tianneng Shi,Jianzhu Yao,Yilong Zhao,Qizheng Zhang,Charlie Ruan,Zeyu Shen,Kaiyuan Liu,Runyuan He,Dong Xing,Zerui Li,Zirong Zeng,Yige Jiang,Lufeng Cheng,Ziyi Zhao,Youran Sun,Wesley Zheng,Meiyuwang Zhang,Ruyi Ji,Xuechang Tu,Zihan Zheng,Zexing Chen,Kangyang Zhou,Zhaozi Wang,Jingbang Chen,Aleksandra Korolova,Peter Henderson,Pramod Viswanath,Vijay Ganesh,Saining Xie,Zhuang Liu,Dawn Song,Sewon Min,Ion Stoica,Joseph E. Gonzalez,Jingbo Shang,Alvin Cheung*

Main category: cs.LG

TL;DR: FrontierCS is a benchmark of 156 challenging, open-ended CS problems with unknown optimal solutions, designed to evaluate models through executable programs. It highlights gaps between models and human experts.


<details>
  <summary>Details</summary>
Motivation: To address the lack of benchmarks focusing on problems without known optimal solutions but with objective evaluability, providing a tool to measure progress in frontier reasoning models.

Method: Design a benchmark with 156 diverse CS problems, including NP-hard algorithmic variants and research problems. Provide expert reference solutions and automatic evaluators.

Result: Models lag behind human experts and tend to generate workable code rather than high-quality solutions, even with increased reasoning budgets.

Conclusion: FrontierCS highlights the need for models to improve in discovering high-quality algorithms and designs, offering a benchmark for measuring progress in frontier CS problem-solving.

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

</details>


### [230] [Learning Model Parameter Dynamics in a Combination Therapy for Bladder Cancer from Sparse Biological Data](https://arxiv.org/abs/2512.15706)
*Kayode Olumoyin,Lamees El Naqa,Katarzyna Rejniak*

Main category: cs.LG

TL;DR: The paper proposes using physics-informed neural networks (PINNs) to model time-varying interactions in biological organisms, like bladder cancer tumors and immune cells, under limited data scenarios.


<details>
  <summary>Details</summary>
Motivation: Traditional models with fixed parameters fail to capture evolving dynamics in biological systems, especially in oncology where data is sparse.

Method: Employ physics-informed neural networks (PINNs) to predict subpopulation trajectories and learn time-varying interactions between cells.

Result: The approach is consistent with biological explanations of subpopulation trajectories and provides a framework for modeling evolving interactions under interventions.

Conclusion: PINNs offer a viable solution for learning dynamic interactions in biological systems with limited data and external interventions.

Abstract: In a mathematical model of interacting biological organisms, where external interventions may alter behavior over time, traditional models that assume fixed parameters usually do not capture the evolving dynamics. In oncology, this is further exacerbated by the fact that experimental data are often sparse and sometimes are composed of a few time points of tumor volume. In this paper, we propose to learn time-varying interactions between cells, such as those of bladder cancer tumors and immune cells, and their response to a combination of anticancer treatments in a limited data scenario. We employ the physics-informed neural network (PINN) approach to predict possible subpopulation trajectories at time points where no observed data are available. We demonstrate that our approach is consistent with the biological explanation of subpopulation trajectories. Our method provides a framework for learning evolving interactions among biological organisms when external interventions are applied to their environment.

</details>
